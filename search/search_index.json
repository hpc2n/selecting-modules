{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the course: Selecting software modules \u00b6 This NAISS course is given under under NAISS, by staff working at the branches located at UPPMAX, LUNARC, HPC2N, and Chalmers, and will cover clusters at those facilities as well as at NSC (Tetralith) and PDC (Dardel). This material Here you will find the content of the workshop \u201cLogin and selecting software modules\u201d Documentation about selecting modules at some of the Swedish HPC centres HPC2N: https://docs.hpc2n.umu.se/software/modules/ UPPMAX: https://docs.uppmax.uu.se/cluster_guides/modules/ LUNARC: https://lunarc-documentation.readthedocs.io/en/latest/manual/manual_modules/ PDC: https://support.pdc.kth.se/doc/basics/quickstart/#the-lmod-module-system NSC: https://www.nsc.liu.se/software/modules/ C3SE: https://www.c3se.chalmers.se/documentation/module_system/ Prerequisites Basic Linux If you lack Linux experience, please follow a tutorial before the course. This is from a recent NAISS course about basic Linux: Material: https://hpc2n.github.io/intro-linux/ Recordings from the course, on YouTube: https://www.youtube.com/playlist?list=PL6jMHLEmPVLzLr4i8ME2A-PUtawhkilbq Learning outcome What is the module system? Why do I want to use the module system? What happens when I load/unload modules? paths environment variables more? some talk about EasyBuild? Useful commands Load examples Compiler toolchains Cluster-specific approaches The course will show you how to find and load modules. While the modules may be somewhat differently named and have somewhat different versions depending on the system, the procedure and commands are the same. We will use Tetralith for those who do not have other access to a Swedish HPC system, and some examples will be shown for other centres. You should be able to code-along - with minor adjustments - regardless of which center you are at. Important info \u00b6 There is an \u201cimportant info\u201d page for this course, containing info on the course project, login info for Tetralith, etc. It can be found here: https://umeauniversity.sharepoint.com/:w:/s/HPC2N630/EaZrQ9E1noBCiSA6kmX09J4BoQTkNQTDYi8f9v2p4Jyobg?e=Zi6E8C There is a Q/A page for use during the lectures. Since the lectures are recorded, you may get recorded if you ask questions in the Zoom, but you can always write questions on the Q/A and get answers there. It also has the advantage that you can go back and look at the answers later. The Q/A page can be found here: https://umeauniversity.sharepoint.com/:w:/s/HPC2N630/EUDMEj8KmYtGkd2KoD-xHUcBFVqlryxHMa774ezkmGomjw?e=wuFaeh Evaluation survey \u00b6 Please help us making this course better by filling an evaluation survey after the course: https://forms.office.com/e/6htZfTRg1Z Preliminary schedule \u00b6 Time Topic Activity Teacher 10:00 Welcome+Syllabus Lecture All 10:10 The module system: overview Lecture+exercise BB 10:20 The module system: versions, loading, unloading, listing Lecture+type along+exercise BB 10:50 Break 11:00 Compiler toolchains Lecture+type along RP 11:15 Software modules Lecture+type along RP 11:45 Modules in batch scripts Lecture BB 11:55 Summary All 12:00 END Preparations \u00b6 In order to type along and do the exercises, please prepare your course environment now: 1. Login Login to the system you are using (Tetralith/Dardel, other Swedish HPC system) You will not need a graphical user interface for this course. Even so, if you do not have a favourite SSH client, we recomment using ThinLinc Connection info for some Swedish HPC systems - use the one you have access to: NSC SSH: ssh <user>@tetralith.nsc.liu.se ThinLinc: Server: tetralith.nsc.liu.se Username: <your-nsc-username> Password: <your-nsc-password> Note that you need to setup TFA to use NSC! HPC2N SSH: ssh <user>@kebnekaise.hpc2n.umu.se ThinLinc: Server: kebnekaise-tl.hpc2n.umu.se Username: <your-hpc2n-username> Password: <yout-hpc2n-password> ThinLinc Webaccess: Put https://kebnekaise-tl.hpc2n.umu.se:300/ in browser address bar Put <your-hpc2n-username> and <your-hpc2n-password> in th e login box that opens and click Login UPPMAX Rackham Pelle SSH: ssh <user>@rackham.uppmax.uu.se ThinLinc: Server: rackham-gui.uppmax.uu.se Username: <your-uppmax-username> Password: <your-uppmax-password> ThinLinc Webaccess: Put https://rackham-gui.uppmax.uu.se in browser address bar Put <your-uppmax-username> and <your-uppmax-password> in the login box that opens and click Login Note that you may have to setup <a href=\u201dhttps://docs.uppmax.uu.se/getting_started/get_uppmax_2fa/\u201d SSH: ssh <user>@pelle.uppmax.uu.se ThinLinc: Server: pelle-gui.uppmax.uu.se Username: <your-uppmax-username> Password: <your-uppmax-password> ThinLinc Webaccess not yet available: Note that you may have to setup TFA for Uppmax when using either of the ThinLinc connections. LUNARC SSH: ssh <user>@cosmos.lunarc.lu.se ThinLinc: Server: cosmos-dt.lunarc.lu.se Username: <your-lunarc-username> Password: <your-lunarc-password> Note that you need to setup TFA (PocketPass) to use LUNARC! PDC SSH: ssh <user>@dardel.pdc.kth.se ThinLinc: Server: dardel-vnc.pdc.kth.se Username: <your-pdc-username> Password: <your-pdc-password> Note that you need to setup SSH keys or kerberos in order to login to PDC! C3SE : SSH: ssh <user>@alvis1.c3se.chalmers.se or ssh <user>@alvis2.c3se.chalmers.se OpenOndemand portal: Put https://alvis.c3se.chalmers.se in browser address bar Put <your-c3se-username> and <your-c3se-password> in the login box Note that Alvis is accessible via SUNET networks (i.e. most Swedish university networks). If you are not on one of those networks you need to use a VPN - preferrably your own Swedish university VPN. If this is not possible, contact support@chalmers.se and ask to be added to the Chalmers\u2019s eduVPN. 2. Setup a working directory You will not need a lot of space for the exercises, so you can create the directory under your home directory. Create a directory to work in ( mkdir $HOME/selecting-modules ) and then switch to it ( cd $HOME/selecting-modules ) 3. Download the exercises wget https://github.com/hpc2n/selecting-modules/raw/refs/heads/main/exercises.tar.gz 4. Extract the exercises tar zxvf exercises.tar.gz 5. Enter the directory that was created cd exercises","title":"Home"},{"location":"#welcome__to__the__course__selecting__software__modules","text":"This NAISS course is given under under NAISS, by staff working at the branches located at UPPMAX, LUNARC, HPC2N, and Chalmers, and will cover clusters at those facilities as well as at NSC (Tetralith) and PDC (Dardel). This material Here you will find the content of the workshop \u201cLogin and selecting software modules\u201d Documentation about selecting modules at some of the Swedish HPC centres HPC2N: https://docs.hpc2n.umu.se/software/modules/ UPPMAX: https://docs.uppmax.uu.se/cluster_guides/modules/ LUNARC: https://lunarc-documentation.readthedocs.io/en/latest/manual/manual_modules/ PDC: https://support.pdc.kth.se/doc/basics/quickstart/#the-lmod-module-system NSC: https://www.nsc.liu.se/software/modules/ C3SE: https://www.c3se.chalmers.se/documentation/module_system/ Prerequisites Basic Linux If you lack Linux experience, please follow a tutorial before the course. This is from a recent NAISS course about basic Linux: Material: https://hpc2n.github.io/intro-linux/ Recordings from the course, on YouTube: https://www.youtube.com/playlist?list=PL6jMHLEmPVLzLr4i8ME2A-PUtawhkilbq Learning outcome What is the module system? Why do I want to use the module system? What happens when I load/unload modules? paths environment variables more? some talk about EasyBuild? Useful commands Load examples Compiler toolchains Cluster-specific approaches The course will show you how to find and load modules. While the modules may be somewhat differently named and have somewhat different versions depending on the system, the procedure and commands are the same. We will use Tetralith for those who do not have other access to a Swedish HPC system, and some examples will be shown for other centres. You should be able to code-along - with minor adjustments - regardless of which center you are at.","title":"Welcome to the course: Selecting software modules"},{"location":"#important__info","text":"There is an \u201cimportant info\u201d page for this course, containing info on the course project, login info for Tetralith, etc. It can be found here: https://umeauniversity.sharepoint.com/:w:/s/HPC2N630/EaZrQ9E1noBCiSA6kmX09J4BoQTkNQTDYi8f9v2p4Jyobg?e=Zi6E8C There is a Q/A page for use during the lectures. Since the lectures are recorded, you may get recorded if you ask questions in the Zoom, but you can always write questions on the Q/A and get answers there. It also has the advantage that you can go back and look at the answers later. The Q/A page can be found here: https://umeauniversity.sharepoint.com/:w:/s/HPC2N630/EUDMEj8KmYtGkd2KoD-xHUcBFVqlryxHMa774ezkmGomjw?e=wuFaeh","title":"Important info"},{"location":"#evaluation__survey","text":"Please help us making this course better by filling an evaluation survey after the course: https://forms.office.com/e/6htZfTRg1Z","title":"Evaluation survey"},{"location":"#preliminary__schedule","text":"Time Topic Activity Teacher 10:00 Welcome+Syllabus Lecture All 10:10 The module system: overview Lecture+exercise BB 10:20 The module system: versions, loading, unloading, listing Lecture+type along+exercise BB 10:50 Break 11:00 Compiler toolchains Lecture+type along RP 11:15 Software modules Lecture+type along RP 11:45 Modules in batch scripts Lecture BB 11:55 Summary All 12:00 END","title":"Preliminary schedule"},{"location":"#preparations","text":"In order to type along and do the exercises, please prepare your course environment now: 1. Login Login to the system you are using (Tetralith/Dardel, other Swedish HPC system) You will not need a graphical user interface for this course. Even so, if you do not have a favourite SSH client, we recomment using ThinLinc Connection info for some Swedish HPC systems - use the one you have access to: NSC SSH: ssh <user>@tetralith.nsc.liu.se ThinLinc: Server: tetralith.nsc.liu.se Username: <your-nsc-username> Password: <your-nsc-password> Note that you need to setup TFA to use NSC! HPC2N SSH: ssh <user>@kebnekaise.hpc2n.umu.se ThinLinc: Server: kebnekaise-tl.hpc2n.umu.se Username: <your-hpc2n-username> Password: <yout-hpc2n-password> ThinLinc Webaccess: Put https://kebnekaise-tl.hpc2n.umu.se:300/ in browser address bar Put <your-hpc2n-username> and <your-hpc2n-password> in th e login box that opens and click Login UPPMAX Rackham Pelle SSH: ssh <user>@rackham.uppmax.uu.se ThinLinc: Server: rackham-gui.uppmax.uu.se Username: <your-uppmax-username> Password: <your-uppmax-password> ThinLinc Webaccess: Put https://rackham-gui.uppmax.uu.se in browser address bar Put <your-uppmax-username> and <your-uppmax-password> in the login box that opens and click Login Note that you may have to setup <a href=\u201dhttps://docs.uppmax.uu.se/getting_started/get_uppmax_2fa/\u201d SSH: ssh <user>@pelle.uppmax.uu.se ThinLinc: Server: pelle-gui.uppmax.uu.se Username: <your-uppmax-username> Password: <your-uppmax-password> ThinLinc Webaccess not yet available: Note that you may have to setup TFA for Uppmax when using either of the ThinLinc connections. LUNARC SSH: ssh <user>@cosmos.lunarc.lu.se ThinLinc: Server: cosmos-dt.lunarc.lu.se Username: <your-lunarc-username> Password: <your-lunarc-password> Note that you need to setup TFA (PocketPass) to use LUNARC! PDC SSH: ssh <user>@dardel.pdc.kth.se ThinLinc: Server: dardel-vnc.pdc.kth.se Username: <your-pdc-username> Password: <your-pdc-password> Note that you need to setup SSH keys or kerberos in order to login to PDC! C3SE : SSH: ssh <user>@alvis1.c3se.chalmers.se or ssh <user>@alvis2.c3se.chalmers.se OpenOndemand portal: Put https://alvis.c3se.chalmers.se in browser address bar Put <your-c3se-username> and <your-c3se-password> in the login box Note that Alvis is accessible via SUNET networks (i.e. most Swedish university networks). If you are not on one of those networks you need to use a VPN - preferrably your own Swedish university VPN. If this is not possible, contact support@chalmers.se and ask to be added to the Chalmers\u2019s eduVPN. 2. Setup a working directory You will not need a lot of space for the exercises, so you can create the directory under your home directory. Create a directory to work in ( mkdir $HOME/selecting-modules ) and then switch to it ( cd $HOME/selecting-modules ) 3. Download the exercises wget https://github.com/hpc2n/selecting-modules/raw/refs/heads/main/exercises.tar.gz 4. Extract the exercises tar zxvf exercises.tar.gz 5. Enter the directory that was created cd exercises","title":"Preparations"},{"location":"advanced_module/","text":"Advanced section - modules \u00b6 buildenv - build environment \u00b6 Using a compiler toolchain by itself is possible but can require some manual work, figuring out which paths to add to -I or -L for including files and libraries, and similar. To make life as a software builder easier there is a special module available, buildenv . This is handled somewhat differently by different centres, with some including the buildenv module when you load a compiler toolchain and others requiring you to load it yourself after the toolchain. This module defines a large number of environment variables with the relevant settings for the used toolchain. Among other things it sets CC, CXX, F90, FC, MPICC, MPICXX, MPIF90, CFLAGS, FFLAGS, and much more. To see all of them, after loading a toolchain do: ml show buildenv To use the environment variables, load buildenv (if it is not included at your centre): ml buildenv Using the environment variable (prefaced with $) for linking is highly recommended! Example: Linking with LAPACK (gcc, C program) gcc -o PROGRAM PROGRAM.c -lflexiblas -lgfortran OR use the environment variable $LIBLAPACK (recommended, as it does not change with version and toolchain): gcc -o PROGRAM PROGRAM.c $LIBLAPACK Example: Loading buildenv after a toolchain (GCC) and using it In this example at HPC2N, we load buildenv for GCC/13.3.0 ml GCC/13.3.0 OpenMPI/5.0.3 ml buildenv/default-CUDA-12.6.0 Buildenv also load many of the same things as foss. This is what is now loaded: b-an01 [ ~ ] $ ml Currently Loaded Modules: 1 ) snicenvironment ( S ) 9 ) libxml2/2.12.7 17 ) UCC/1.3.0 25 ) GDRCopy/2.4.1 2 ) systemdefault ( S ) 10 ) libpciaccess/0.18.1 18 ) OpenMPI/5.0.3 26 ) UCX-CUDA/1.16.0-CUDA-12.6.0 3 ) GCCcore/13.3.0 11 ) hwloc/2.10.0 19 ) OpenBLAS/0.3.27 27 ) NCCL/2.22.3-CUDA-12.6.0 4 ) zlib/1.3.1 12 ) OpenSSL/3 20 ) FlexiBLAS/3.4.4 28 ) UCC-CUDA/1.3.0-CUDA-12.6.0 5 ) binutils/2.42 13 ) libevent/2.1.12 21 ) FFTW/3.3.10 29 ) buildenv/default-CUDA-12.6.0 6 ) GCC/13.3.0 14 ) UCX/1.16.0 22 ) FFTW.MPI/3.3.10 7 ) numactl/2.0.18 15 ) PMIx/5.0.2 23 ) ScaLAPACK/2.2.0-fb 8 ) XZ/5.4.5 16 ) PRRTE/3.0.5 24 ) CUDA/12.6.0 Where: S: Module is Sticky, requires --force to unload or purge You can now do ml show buildenv to get a list of the various available environment variables. In the below I have coloured some of the environment variables for LAPACK, ScaLAPACK, BLAS, FFTW. Example: Loading buildenv after a toolchain (foss) Since GCC and OpenMPI are part of foss, you can also just load foss before buildenv: ml foss/2024a ml buildenv/default you can also just load foss before buildenv: ml foss/2024a ml buildenv/default","title":"Advanced module commands"},{"location":"advanced_module/#advanced__section__-__modules","text":"","title":"Advanced section - modules"},{"location":"advanced_module/#buildenv__-__build__environment","text":"Using a compiler toolchain by itself is possible but can require some manual work, figuring out which paths to add to -I or -L for including files and libraries, and similar. To make life as a software builder easier there is a special module available, buildenv . This is handled somewhat differently by different centres, with some including the buildenv module when you load a compiler toolchain and others requiring you to load it yourself after the toolchain. This module defines a large number of environment variables with the relevant settings for the used toolchain. Among other things it sets CC, CXX, F90, FC, MPICC, MPICXX, MPIF90, CFLAGS, FFLAGS, and much more. To see all of them, after loading a toolchain do: ml show buildenv To use the environment variables, load buildenv (if it is not included at your centre): ml buildenv Using the environment variable (prefaced with $) for linking is highly recommended! Example: Linking with LAPACK (gcc, C program) gcc -o PROGRAM PROGRAM.c -lflexiblas -lgfortran OR use the environment variable $LIBLAPACK (recommended, as it does not change with version and toolchain): gcc -o PROGRAM PROGRAM.c $LIBLAPACK Example: Loading buildenv after a toolchain (GCC) and using it In this example at HPC2N, we load buildenv for GCC/13.3.0 ml GCC/13.3.0 OpenMPI/5.0.3 ml buildenv/default-CUDA-12.6.0 Buildenv also load many of the same things as foss. This is what is now loaded: b-an01 [ ~ ] $ ml Currently Loaded Modules: 1 ) snicenvironment ( S ) 9 ) libxml2/2.12.7 17 ) UCC/1.3.0 25 ) GDRCopy/2.4.1 2 ) systemdefault ( S ) 10 ) libpciaccess/0.18.1 18 ) OpenMPI/5.0.3 26 ) UCX-CUDA/1.16.0-CUDA-12.6.0 3 ) GCCcore/13.3.0 11 ) hwloc/2.10.0 19 ) OpenBLAS/0.3.27 27 ) NCCL/2.22.3-CUDA-12.6.0 4 ) zlib/1.3.1 12 ) OpenSSL/3 20 ) FlexiBLAS/3.4.4 28 ) UCC-CUDA/1.3.0-CUDA-12.6.0 5 ) binutils/2.42 13 ) libevent/2.1.12 21 ) FFTW/3.3.10 29 ) buildenv/default-CUDA-12.6.0 6 ) GCC/13.3.0 14 ) UCX/1.16.0 22 ) FFTW.MPI/3.3.10 7 ) numactl/2.0.18 15 ) PMIx/5.0.2 23 ) ScaLAPACK/2.2.0-fb 8 ) XZ/5.4.5 16 ) PRRTE/3.0.5 24 ) CUDA/12.6.0 Where: S: Module is Sticky, requires --force to unload or purge You can now do ml show buildenv to get a list of the various available environment variables. In the below I have coloured some of the environment variables for LAPACK, ScaLAPACK, BLAS, FFTW. Example: Loading buildenv after a toolchain (foss) Since GCC and OpenMPI are part of foss, you can also just load foss before buildenv: ml foss/2024a ml buildenv/default you can also just load foss before buildenv: ml foss/2024a ml buildenv/default","title":"buildenv - build environment"},{"location":"batch/","text":"Modules in batch scripts \u00b6 Objectives learn briefly about using modules in batch jobs learn about the difference between when it is a serial, MPI, and GPU job This section looks at how to use modules in batch scripts. This is done much the same as when you just load them on the command line. Note Any longer, parallel, heavy jobs should be run as a batch job in order not to overload the login node and make it slow/unusuable for everyone. When you write a batch script you have to load the modules you need to run the job , just as you would have otherwise. If the module has prerequisites, they have to be loaded before the module The modules you load need to be compatible with each other, just like when you load them on the command line. When you load modules inside a batch script, there are only really three different cases: serial jobs parallel/MPI jobs GPU jobs We will use Python and various Python package modules as an example. Note A batch job is submitted to the batch queue with sbatch <batchjob.sh> . Serial jobs \u00b6 Here you do not need MPI-enabled modules. If the module has both a GPU and a CPU version, you should load the CPU version. Example - serial job script The example Python script used here is mmmult.py . HPC2N UPPMAX LUNARC NSC PDC C3SE Short serial example for running on Kebnekaise. Loading SciPy-bundle/2023.07 and Python/3.11.3 #!/bin/bash #SBATCH -A hpc2nXXXX-YYY # Change to your own project ID #SBATCH --time=00:10:00 # Asking for 10 minutes #SBATCH -n 1 # Asking for 1 core # Purge the environment of any modules module purge > /dev/null 2 > & 1 # Load any modules you need, here for Python/3.11.3 and compatible SciPy-bundle module load GCC/12.3.0 Python/3.11.3 SciPy-bundle/2023.07 # Run your Python script python mmmult.py Short serial example script for Rackham. Loading Python 3.11.8. Numpy is preinstalled and does not need to be loaded. #!/bin/bash -l #SBATCH -A uppmaxXXXX-Y-ZZZ # Change to your own project ID #SBATCH --time=00:10:00 # Asking for 10 minutes #SBATCH -n 1 # Asking for 1 core # module purge is not recommended - if you do it you need to \"module load uppmax\" after # Load any modules you need, here Python 3.11.8. module load python/3.11.8 # On Rackham # module load Python/3.12.3-GCCcore-13.3.0 # On Pelle # Run your Python script python mmmult.py Short serial example for running on Cosmos. Loading SciPy-bundle/2023.11 and Python/3.11.5 #!/bin/bash #SBATCH -A luXXXX-Y-ZZ # Change to your own project ID #SBATCH --time=00:10:00 # Asking for 10 minutes #SBATCH -n 1 # Asking for 1 core # Purge the environment of any modules module purge > /dev/null 2 > & 1 # Load any modules you need, here for Python/3.11.5 and compatible SciPy-bundle module load GCC/13.2.0 Python/3.11.5 SciPy-bundle/2023.11 # Run your Python script python mmmult.py Short serial example for running on Tetralith. Loading SciPy-bundle/2022.05 and Python/3.10.4 #!/bin/bash #SBATCH -A naissXXXX-YY-ZZZ # Change to your own project ID #SBATCH --time=00:10:00 # Asking for 10 minutes #SBATCH -n 1 # Asking for 1 core # Purge the environment of any modules - here it is neither recommended or not module purge > /dev/null 2 > & 1 # Load any modules you need, here for Python/3.10.4 and compatible SciPy-bundle module load buildtool-easybuild/4.8.0-hpce082752a2 GCC/11.3.0 OpenMPI/4.1.4 Python/3.10.4 SciPy-bundle/2022.05 # Run your Python script python mmmult.py Short serial example for running on Dardel. Loading cray-python/3.11.7 #!/bin/bash #SBATCH -A naissXXXX-YY-ZZZ # Change to your own #SBATCH --time=00:10:00 # Asking for 10 minutes #SBATCH -n 1 # Asking for 1 core # At Dardel you always have to give the partition to run in # In this case it is the \"main\" partition #SBATCH -p main # WARNING! Do not do \"module purge\" here! # Load any modules you need, here for cray-python/3.11.7. module load cray-python/3.11.7 # Run your Python script python mmmult.py Short serial example for running on Alvis. Loading Python/3.11.5-GCCcore-13.2.0 and SciPy-bundle/2023.11-gfbf-2023b Note: on Alvis you must request a GPU regardless - it is only really for GPU jobs. Here I just ask for 1 T4 #!/bin/bash #SBATCH -A naissXXXX-YY-ZZZ # Change to your own #SBATCH --time=00:10:00 # Asking for 10 minutes #SBATCH -N 1 --gpus-per-node=T4:8 # 1 node with 8 Nvidia T4 GPUs #SBATCH -p alvis # Purge the environment of any modules module purge > /dev/null 2 > & 1 # Load any modules you need, here for Python/3.11.5-GCCcore-13.2.0 and SciPy-bundle/2023.11-gfbf-2023b module load Python/3.11.5-GCCcore-13.2.0 module load SciPy-bundle/2023.11-gfbf-2023b # Run your Python script python mmmult.py MPI jobs \u00b6 There is little difference between the job scripts for a serial job and an MPI job: you ask for more cores since you want to run more tasks you may need other modules that are parallelized versions of the software Continuing with a Python example Example - MPI job script Make sure you ask for enough tasks and your modules are for parallelized software. Here a program that needs mpi4py: integration2d_mpi.py . HPC2N UPPMAX (Pelle) UPPMAX (Rackham) LUNARC NSC PDC C3SE #!/bin/bash # The name of the account you are running in, mandatory. #SBATCH -A hpc2nXXXX-YYY # Request resources - here for eight MPI tasks #SBATCH -n 8 # Request runtime for the job (HHH:MM:SS) where 168 hours is the maximum at most centres. Here asking for 15 min. #SBATCH --time=00:15:00 # Clear the environment from any previously loaded modules module purge > /dev/null 2 > & 1 # Load the module environment suitable for the job, it could be more or # less, depending on other package needs. This is for a simple job needing # mpi4py. ml GCC/12.3.0 Python/3.11.3 SciPy-bundle/2023.07 OpenMPI/4.1.5 mpi4py/3.1.4 # And finally run the job - use srun for MPI jobs, but not for serial jobs srun ./integration2d_mpi.py #!/bin/bash # The name of the account you are running in, mandatory. #SBATCH -A uppmaxXXXX-Y-ZZZ # Request resources - here for eight MPI tasks #SBATCH -n 8 # Request runtime for the job (HHH:MM:SS) where 168 hours is the maximum at most centres. Here asking for 15 min. #SBATCH --time=00:15:00 ml purge # Load the module environment suitable for the job, it could be more or # less, depending on other package needs. This is for a simple job needing # mpi4py. module load mpi4py/3.1.5-gompi-2023b # You get GCC/13.2.0, OpenMPI/4.1.6-GCC-13.2.0 and Python/3.11.5-GCCcore-13.2.0 on the fly. # And finally run the job - use srun for MPI jobs, but not for serial jobs srun ./integration2d_mpi.py #!/bin/bash # The name of the account you are running in, mandatory. #SBATCH -A uppmaxXXXX-Y-ZZZ # Request resources - here for eight MPI tasks #SBATCH -n 8 # Request runtime for the job (HHH:MM:SS) where 168 hours is the maximum at most centres. Here asking for 15 min. #SBATCH --time=00:15:00 # Module purge is not recommended - if you do it you need to \"module load uppmax\" after # Load the module environment suitable for the job, it could be more or # less, depending on other package needs. This is for a simple job needing # mpi4py. # Here mpi4py are not installed and you need a virtual env. # The following steps would need to be done before submitting the job script: # module load python/3.11.8 python_ML_packages/3.11.8-cpu openmpi/4.1.5 # python -m venv mympi4py # source mympi4py/bin/activate # pip install mpi4py module load python/3.11.8 python_ML_packages/3.11.8-cpu openmpi/4.1.5 source mympi4py/bin/activate # And finally run the job - use srun for MPI jobs, but not for serial jobs srun ./integration2d_mpi.py #!/bin/bash # The name of the account you are running in, mandatory. #SBATCH -A luXXXX-Y-ZZ # Request resources - here for eight MPI tasks #SBATCH -n 8 # Request runtime for the job (HHH:MM:SS) where 168 hours is the maximum at most centres. Here asking for 15 min. #SBATCH --time=00:15:00 # Clear the environment from any previously loaded modules module purge > /dev/null 2 > & 1 # Load the module environment suitable for the job, it could be more or # less, depending on other package needs. This is for a simple job needing # mpi4py. ml GCC/13.2.0 Python/3.11.5 SciPy-bundle/2023.11 OpenMPI/4.1.6 mpi4py/3.1.5 # And finally run the job - use srun for MPI jobs, but not for serial jobs srun ./integration2d_mpi.py #!/bin/bash # The name of the account you are running in, mandatory. #SBATCH -A naissXXXX-YY-ZZZ # Request resources - here for eight MPI tasks #SBATCH -n 8 # Request runtime for the job (HHH:MM:SS) where 168 hours is the maximum at most centres. Here asking for 15 min. #SBATCH --time=00:15:00 # At NSC, module purge is safe and neither recommended nor not module purge > /dev/null 2 > & 1 # Load the module environment suitable for the job, it could be more or # less, depending on other package needs. This is for a simple job needing # mpi4py. ml buildtool-easybuild/4.8.0-hpce082752a2 GCC/11.3.0 OpenMPI/4.1.4 Python/3.10.4 SciPy-bundle/2022.05 # And finally run the job - use srun for MPI jobs, but not for serial jobs srun ./integration2d_mpi.py #!/bin/bash # The name of the account you are running in, mandatory. #SBATCH -A naissXXXX-YY-ZZZ #SBATCH -p shared # name of the queue # Request resources - here for eight MPI tasks #SBATCH -n 8 #SBATCH --cpus-per-task=1 # nr. of cores per-task # Request runtime for the job (HHH:MM:SS) where 168 hours is the maximum at most centres. Here asking for 15 min. #SBATCH --time=00:15:00 # WARNING! Do not do \"module purge\" here! # Load the module environment suitable for the job, it could be more or # less, depending on other package needs. This is for a simple job needing # mpi4py. ml cray-python/3.11.7 # And finally run the job - use srun for MPI jobs, but not for serial jobs srun ./integration2d_mpi.py Note: on Alvis you must request a GPU regardless - it is only really for GPU jobs. Here I just ask for 1 T4 #!/bin/bash # The name of the account you are running in, mandatory. #SBATCH -A naissXXXX-YY-ZZZ # Request resources - here for eight MPI tasks #SBATCH -n 8 #SBATCH -N 1 --gpus-per-node=T4:8 # 1 node with 8 Nvidia T4 GPUs #BATCH -p alvis # Request runtime for the job (HHH:MM:SS) where 168 hours is the maximum at most centres. Here asking for 15 min. #SBATCH --time=00:15:00 # Clear the environment from any previously loaded modules module purge > /dev/null 2 > & 1 # Load the module environment suitable for the job, it could be more or # less, depending on other package needs. This is for a simple job needing # mpi4py. ml Python/3.11.5-GCCcore-13.2.0 SciPy-bundle/2023.11-gfbf-2023b mpi4py/3.1.5-gompi-2023b # And finally run the job - use srun for MPI jobs, but not for serial jobs srun ./integration2d_mpi.py GPU jobs \u00b6 Here there are two things to pay attention to: The modules you load must be for software that is GPU-aware (and often compiled with CUDA as well). You need to ask for GPU resources in the batch script Example - GPU job script In this example we make a batch script for running a small Python GPU script called add-list.py . It needs \u201cnumba\u201d. HPC2N UPPMAX (Pelle) UPPMAX (Rackham) LUNARC NSC PDC C3SE At HPC2N there are many different types of GPU\u2019s with different amount of GPU cards. You can read more about that here: https://docs.hpc2n.umu.se/documentation/batchsystem/resources/ . #!/bin/bash # Remember to change this to your own project ID! #SBATCH -A hpc2nXXXX-YYY # HPC2N ID - change to your own # We are asking for 5 minutes #SBATCH --time=00:05:00 # Asking for one L40s GPU - see the link above for more options #SBATCH --gpus=1 #SBATCH -C l40s # Remove any loaded modules and load the ones we need module purge > /dev/null 2 > & 1 module load GCC/12.3.0 Python/3.11.3 OpenMPI/4.1.5 SciPy-bundle/2023.07 CUDA/12.1.1 numba/0.58.1 CUDA/12.1.1 # Run your Python script python add-list.py Warning Note that the numba installation, as of now, gives a segmentation fault for this exercise. We are troubleshooting until next time! Pelle has Nvidia L40s and H100 GPUs. Default is L40s and is reached by just stating -p gpu --gres=gpu . To reach one of very few large H100 state -p gpu --gpus=h100 . #!/bin/bash # Remember to change this to your own project ID! #SBATCH -A uppmaxXXXX-Y-ZZZ # We are asking for 10 minutes #SBATCH --time=00:10:00 # Asking for one GPU #SBATCH -p gpu #SBATCH --gres=gpu:1 module purge > /dev/null 2 > & 1 module load numba/0.60.0-foss-2024a # You get GCC/13.3.0 OpenMPI/5.0.3-GCC-13.3.0 Python/3.12.3-GCCcore-13.3.0 Python-bundle-PyPI/2024.06-GCCcore-13.3.0 and SciPy-bundle/2024.05-gfbf-2024a and more on the fly! # Run your Python script python add-list.py At UPPMAX the main thing to pay attention to is that the resource \u201cRackham\u201d does not have GPUs and the batch jobs needing that are therefore submitted to \u201cSnowy\u201d which does have GPUs. #!/bin/bash -l # -l is needed # Remember to change this to your own project ID! #SBATCH -A uppmaxXXXX-Y-ZZZ # We want to run on Snowy which has GPUs #SBATCH -M snowy # We are asking for 70 minutes. <= 60 min introduces as bug #SBATCH --time=01:10:00 # Asking for one GPU #SBATCH --gres=gpu:1 # If you remove any loaded modules with \"module purge\" you need # to load the module \"uppmax\" again. This is how it is done here. module purge > /dev/null 2 > & 1 module load uppmax # The Python package \"numba\" is included in the python_ML_packages which has both a _cpu and a _gpu version. module load python_ML_packages/3.11.8-gpu # Run your Python script python add-list.py LUNARC has Nvidia A100 GPUs. The modules are arranged as at HPC2N, with prerequisites, and with numba its own module #!/bin/bash Remember to change this to your own project ID! #SBATCH -A luXXXX-Y-ZZ We are asking for 5 minutes #SBATCH --time=00:05:00 #SBATCH --ntasks-per-node=1 Asking for one A100 GPU #SBATCH -p gpua100 #SBATCH --gres=gpu:1 Remove any loaded modules and load the ones we need module purge > /dev/null 2 > & 1 module load GCC/12.3.0 Python/3.11.3 OpenMPI/4.1.5 numba/0.58.1 SciPy-bundle/2023.07 CUDA/12.1.1 Run your Python script python add-list.py Tetralith has Nvidia T4 GPUs. #!/bin/bash # Remember to change this to your own project ID! #SBATCH -A naissXXXX-YY-ZZZ # We are asking for 5 minutes #SBATCH --time=00:05:00 # This is how you ask for a GPU at Tetralith - you need all three lines #SBATCH -n 1 #SBATCH -c 32 #SBATCH --gpus-per-task=1 # Remove any loaded modules and load the ones we need. This is safe here module purge > /dev/null 2 > & 1 # numba is not installed, but we need these in order to get the # prerequisites for an install in a virtual environment module load buildtool-easybuild/4.8.0-hpce082752a2 GCC/13.2.0 Python/3.11.5 SciPy-bundle/2023.11 JupyterLab/4.2.0 # Load a virtual environment where numba is installed # you can create it with the following steps BEFORE running the batch script: # ml buildtool-easybuild/4.8.0-hpce082752a2 GCC/13.2.0 Python/3.11.5 SciPy-bundle/2023.11 JupyterLab/4.2.0 # python -m venv mynumba # source mynumba/bin/activate # pip install numba # Then when you want to use it in the batch script, we include this source <path-to>/mynumba/bin/activate # Run your Python script python add-list.py Dardel has 4 AMD Instinct\u2122 MI250X \u00e1 2 GCDs per node. This is AMD GPUs and numba after version 0.53.1 only has compatibility with CUDA (Nvidia GPUs). The numba 0.53.1 version is too old to work with anything else installed. Thus, no numba example for PDC. You would have to use an example with hip instead and you would also need to install hip-python in a virtual environment to get any of it to work. If you want to ask for a GPU on Dardel, you add this to a batch script: #SBATCH -N 1 #SBATCH --ntasks-per-node=1 #SBATCH -p gpu There is some information about job scripts on Alvis here: https://www.c3se.chalmers.se/documentation/submitting_jobs/running_jobs/#writing-a-job-script On Alvis there are the following options on (Nvidia) GPUs to request and the lines to add in each case. So you would add ONE of these: #SBATCH --gpus-per-node=V100:1 # up to 4 #SBATCH --gpus-per-node=T4:1 # up to 8 #SBATCH --gpus-per-node=A40:1 # up to 4 #SBATCH --gpus-per-node=A100:1 # up to 4 #SBATCH --gpus-per-node=A100fat:1 # up to 4 This is the example script to run the numba example: #!/usr/bin/env bash # Change to your own job ID! The partition is alvis #SBATCH -A NAISSXXXX-Y-ZZ -p alvis #SBATCH -N 1 --gpus-per-node=T4:8 # 1 node with 8 Nvidia T4 GPUs #SBATCH -t 0-00:10:00 # module purge and then load the needed modules. numba at Alvis # automatically loads all the other needed modules (GCC, Python, # OpenMPI, SciPy-bundle, etc. so can be loaded directly module purge > /dev/null 2 > & 1 ml numba/0.58.1-foss-2023a # Run your Python script python add-list.py","title":"Modules in batch scripts"},{"location":"batch/#modules__in__batch__scripts","text":"Objectives learn briefly about using modules in batch jobs learn about the difference between when it is a serial, MPI, and GPU job This section looks at how to use modules in batch scripts. This is done much the same as when you just load them on the command line. Note Any longer, parallel, heavy jobs should be run as a batch job in order not to overload the login node and make it slow/unusuable for everyone. When you write a batch script you have to load the modules you need to run the job , just as you would have otherwise. If the module has prerequisites, they have to be loaded before the module The modules you load need to be compatible with each other, just like when you load them on the command line. When you load modules inside a batch script, there are only really three different cases: serial jobs parallel/MPI jobs GPU jobs We will use Python and various Python package modules as an example. Note A batch job is submitted to the batch queue with sbatch <batchjob.sh> .","title":"Modules in batch scripts"},{"location":"batch/#serial__jobs","text":"Here you do not need MPI-enabled modules. If the module has both a GPU and a CPU version, you should load the CPU version. Example - serial job script The example Python script used here is mmmult.py . HPC2N UPPMAX LUNARC NSC PDC C3SE Short serial example for running on Kebnekaise. Loading SciPy-bundle/2023.07 and Python/3.11.3 #!/bin/bash #SBATCH -A hpc2nXXXX-YYY # Change to your own project ID #SBATCH --time=00:10:00 # Asking for 10 minutes #SBATCH -n 1 # Asking for 1 core # Purge the environment of any modules module purge > /dev/null 2 > & 1 # Load any modules you need, here for Python/3.11.3 and compatible SciPy-bundle module load GCC/12.3.0 Python/3.11.3 SciPy-bundle/2023.07 # Run your Python script python mmmult.py Short serial example script for Rackham. Loading Python 3.11.8. Numpy is preinstalled and does not need to be loaded. #!/bin/bash -l #SBATCH -A uppmaxXXXX-Y-ZZZ # Change to your own project ID #SBATCH --time=00:10:00 # Asking for 10 minutes #SBATCH -n 1 # Asking for 1 core # module purge is not recommended - if you do it you need to \"module load uppmax\" after # Load any modules you need, here Python 3.11.8. module load python/3.11.8 # On Rackham # module load Python/3.12.3-GCCcore-13.3.0 # On Pelle # Run your Python script python mmmult.py Short serial example for running on Cosmos. Loading SciPy-bundle/2023.11 and Python/3.11.5 #!/bin/bash #SBATCH -A luXXXX-Y-ZZ # Change to your own project ID #SBATCH --time=00:10:00 # Asking for 10 minutes #SBATCH -n 1 # Asking for 1 core # Purge the environment of any modules module purge > /dev/null 2 > & 1 # Load any modules you need, here for Python/3.11.5 and compatible SciPy-bundle module load GCC/13.2.0 Python/3.11.5 SciPy-bundle/2023.11 # Run your Python script python mmmult.py Short serial example for running on Tetralith. Loading SciPy-bundle/2022.05 and Python/3.10.4 #!/bin/bash #SBATCH -A naissXXXX-YY-ZZZ # Change to your own project ID #SBATCH --time=00:10:00 # Asking for 10 minutes #SBATCH -n 1 # Asking for 1 core # Purge the environment of any modules - here it is neither recommended or not module purge > /dev/null 2 > & 1 # Load any modules you need, here for Python/3.10.4 and compatible SciPy-bundle module load buildtool-easybuild/4.8.0-hpce082752a2 GCC/11.3.0 OpenMPI/4.1.4 Python/3.10.4 SciPy-bundle/2022.05 # Run your Python script python mmmult.py Short serial example for running on Dardel. Loading cray-python/3.11.7 #!/bin/bash #SBATCH -A naissXXXX-YY-ZZZ # Change to your own #SBATCH --time=00:10:00 # Asking for 10 minutes #SBATCH -n 1 # Asking for 1 core # At Dardel you always have to give the partition to run in # In this case it is the \"main\" partition #SBATCH -p main # WARNING! Do not do \"module purge\" here! # Load any modules you need, here for cray-python/3.11.7. module load cray-python/3.11.7 # Run your Python script python mmmult.py Short serial example for running on Alvis. Loading Python/3.11.5-GCCcore-13.2.0 and SciPy-bundle/2023.11-gfbf-2023b Note: on Alvis you must request a GPU regardless - it is only really for GPU jobs. Here I just ask for 1 T4 #!/bin/bash #SBATCH -A naissXXXX-YY-ZZZ # Change to your own #SBATCH --time=00:10:00 # Asking for 10 minutes #SBATCH -N 1 --gpus-per-node=T4:8 # 1 node with 8 Nvidia T4 GPUs #SBATCH -p alvis # Purge the environment of any modules module purge > /dev/null 2 > & 1 # Load any modules you need, here for Python/3.11.5-GCCcore-13.2.0 and SciPy-bundle/2023.11-gfbf-2023b module load Python/3.11.5-GCCcore-13.2.0 module load SciPy-bundle/2023.11-gfbf-2023b # Run your Python script python mmmult.py","title":"Serial jobs"},{"location":"batch/#mpi__jobs","text":"There is little difference between the job scripts for a serial job and an MPI job: you ask for more cores since you want to run more tasks you may need other modules that are parallelized versions of the software Continuing with a Python example Example - MPI job script Make sure you ask for enough tasks and your modules are for parallelized software. Here a program that needs mpi4py: integration2d_mpi.py . HPC2N UPPMAX (Pelle) UPPMAX (Rackham) LUNARC NSC PDC C3SE #!/bin/bash # The name of the account you are running in, mandatory. #SBATCH -A hpc2nXXXX-YYY # Request resources - here for eight MPI tasks #SBATCH -n 8 # Request runtime for the job (HHH:MM:SS) where 168 hours is the maximum at most centres. Here asking for 15 min. #SBATCH --time=00:15:00 # Clear the environment from any previously loaded modules module purge > /dev/null 2 > & 1 # Load the module environment suitable for the job, it could be more or # less, depending on other package needs. This is for a simple job needing # mpi4py. ml GCC/12.3.0 Python/3.11.3 SciPy-bundle/2023.07 OpenMPI/4.1.5 mpi4py/3.1.4 # And finally run the job - use srun for MPI jobs, but not for serial jobs srun ./integration2d_mpi.py #!/bin/bash # The name of the account you are running in, mandatory. #SBATCH -A uppmaxXXXX-Y-ZZZ # Request resources - here for eight MPI tasks #SBATCH -n 8 # Request runtime for the job (HHH:MM:SS) where 168 hours is the maximum at most centres. Here asking for 15 min. #SBATCH --time=00:15:00 ml purge # Load the module environment suitable for the job, it could be more or # less, depending on other package needs. This is for a simple job needing # mpi4py. module load mpi4py/3.1.5-gompi-2023b # You get GCC/13.2.0, OpenMPI/4.1.6-GCC-13.2.0 and Python/3.11.5-GCCcore-13.2.0 on the fly. # And finally run the job - use srun for MPI jobs, but not for serial jobs srun ./integration2d_mpi.py #!/bin/bash # The name of the account you are running in, mandatory. #SBATCH -A uppmaxXXXX-Y-ZZZ # Request resources - here for eight MPI tasks #SBATCH -n 8 # Request runtime for the job (HHH:MM:SS) where 168 hours is the maximum at most centres. Here asking for 15 min. #SBATCH --time=00:15:00 # Module purge is not recommended - if you do it you need to \"module load uppmax\" after # Load the module environment suitable for the job, it could be more or # less, depending on other package needs. This is for a simple job needing # mpi4py. # Here mpi4py are not installed and you need a virtual env. # The following steps would need to be done before submitting the job script: # module load python/3.11.8 python_ML_packages/3.11.8-cpu openmpi/4.1.5 # python -m venv mympi4py # source mympi4py/bin/activate # pip install mpi4py module load python/3.11.8 python_ML_packages/3.11.8-cpu openmpi/4.1.5 source mympi4py/bin/activate # And finally run the job - use srun for MPI jobs, but not for serial jobs srun ./integration2d_mpi.py #!/bin/bash # The name of the account you are running in, mandatory. #SBATCH -A luXXXX-Y-ZZ # Request resources - here for eight MPI tasks #SBATCH -n 8 # Request runtime for the job (HHH:MM:SS) where 168 hours is the maximum at most centres. Here asking for 15 min. #SBATCH --time=00:15:00 # Clear the environment from any previously loaded modules module purge > /dev/null 2 > & 1 # Load the module environment suitable for the job, it could be more or # less, depending on other package needs. This is for a simple job needing # mpi4py. ml GCC/13.2.0 Python/3.11.5 SciPy-bundle/2023.11 OpenMPI/4.1.6 mpi4py/3.1.5 # And finally run the job - use srun for MPI jobs, but not for serial jobs srun ./integration2d_mpi.py #!/bin/bash # The name of the account you are running in, mandatory. #SBATCH -A naissXXXX-YY-ZZZ # Request resources - here for eight MPI tasks #SBATCH -n 8 # Request runtime for the job (HHH:MM:SS) where 168 hours is the maximum at most centres. Here asking for 15 min. #SBATCH --time=00:15:00 # At NSC, module purge is safe and neither recommended nor not module purge > /dev/null 2 > & 1 # Load the module environment suitable for the job, it could be more or # less, depending on other package needs. This is for a simple job needing # mpi4py. ml buildtool-easybuild/4.8.0-hpce082752a2 GCC/11.3.0 OpenMPI/4.1.4 Python/3.10.4 SciPy-bundle/2022.05 # And finally run the job - use srun for MPI jobs, but not for serial jobs srun ./integration2d_mpi.py #!/bin/bash # The name of the account you are running in, mandatory. #SBATCH -A naissXXXX-YY-ZZZ #SBATCH -p shared # name of the queue # Request resources - here for eight MPI tasks #SBATCH -n 8 #SBATCH --cpus-per-task=1 # nr. of cores per-task # Request runtime for the job (HHH:MM:SS) where 168 hours is the maximum at most centres. Here asking for 15 min. #SBATCH --time=00:15:00 # WARNING! Do not do \"module purge\" here! # Load the module environment suitable for the job, it could be more or # less, depending on other package needs. This is for a simple job needing # mpi4py. ml cray-python/3.11.7 # And finally run the job - use srun for MPI jobs, but not for serial jobs srun ./integration2d_mpi.py Note: on Alvis you must request a GPU regardless - it is only really for GPU jobs. Here I just ask for 1 T4 #!/bin/bash # The name of the account you are running in, mandatory. #SBATCH -A naissXXXX-YY-ZZZ # Request resources - here for eight MPI tasks #SBATCH -n 8 #SBATCH -N 1 --gpus-per-node=T4:8 # 1 node with 8 Nvidia T4 GPUs #BATCH -p alvis # Request runtime for the job (HHH:MM:SS) where 168 hours is the maximum at most centres. Here asking for 15 min. #SBATCH --time=00:15:00 # Clear the environment from any previously loaded modules module purge > /dev/null 2 > & 1 # Load the module environment suitable for the job, it could be more or # less, depending on other package needs. This is for a simple job needing # mpi4py. ml Python/3.11.5-GCCcore-13.2.0 SciPy-bundle/2023.11-gfbf-2023b mpi4py/3.1.5-gompi-2023b # And finally run the job - use srun for MPI jobs, but not for serial jobs srun ./integration2d_mpi.py","title":"MPI jobs"},{"location":"batch/#gpu__jobs","text":"Here there are two things to pay attention to: The modules you load must be for software that is GPU-aware (and often compiled with CUDA as well). You need to ask for GPU resources in the batch script Example - GPU job script In this example we make a batch script for running a small Python GPU script called add-list.py . It needs \u201cnumba\u201d. HPC2N UPPMAX (Pelle) UPPMAX (Rackham) LUNARC NSC PDC C3SE At HPC2N there are many different types of GPU\u2019s with different amount of GPU cards. You can read more about that here: https://docs.hpc2n.umu.se/documentation/batchsystem/resources/ . #!/bin/bash # Remember to change this to your own project ID! #SBATCH -A hpc2nXXXX-YYY # HPC2N ID - change to your own # We are asking for 5 minutes #SBATCH --time=00:05:00 # Asking for one L40s GPU - see the link above for more options #SBATCH --gpus=1 #SBATCH -C l40s # Remove any loaded modules and load the ones we need module purge > /dev/null 2 > & 1 module load GCC/12.3.0 Python/3.11.3 OpenMPI/4.1.5 SciPy-bundle/2023.07 CUDA/12.1.1 numba/0.58.1 CUDA/12.1.1 # Run your Python script python add-list.py Warning Note that the numba installation, as of now, gives a segmentation fault for this exercise. We are troubleshooting until next time! Pelle has Nvidia L40s and H100 GPUs. Default is L40s and is reached by just stating -p gpu --gres=gpu . To reach one of very few large H100 state -p gpu --gpus=h100 . #!/bin/bash # Remember to change this to your own project ID! #SBATCH -A uppmaxXXXX-Y-ZZZ # We are asking for 10 minutes #SBATCH --time=00:10:00 # Asking for one GPU #SBATCH -p gpu #SBATCH --gres=gpu:1 module purge > /dev/null 2 > & 1 module load numba/0.60.0-foss-2024a # You get GCC/13.3.0 OpenMPI/5.0.3-GCC-13.3.0 Python/3.12.3-GCCcore-13.3.0 Python-bundle-PyPI/2024.06-GCCcore-13.3.0 and SciPy-bundle/2024.05-gfbf-2024a and more on the fly! # Run your Python script python add-list.py At UPPMAX the main thing to pay attention to is that the resource \u201cRackham\u201d does not have GPUs and the batch jobs needing that are therefore submitted to \u201cSnowy\u201d which does have GPUs. #!/bin/bash -l # -l is needed # Remember to change this to your own project ID! #SBATCH -A uppmaxXXXX-Y-ZZZ # We want to run on Snowy which has GPUs #SBATCH -M snowy # We are asking for 70 minutes. <= 60 min introduces as bug #SBATCH --time=01:10:00 # Asking for one GPU #SBATCH --gres=gpu:1 # If you remove any loaded modules with \"module purge\" you need # to load the module \"uppmax\" again. This is how it is done here. module purge > /dev/null 2 > & 1 module load uppmax # The Python package \"numba\" is included in the python_ML_packages which has both a _cpu and a _gpu version. module load python_ML_packages/3.11.8-gpu # Run your Python script python add-list.py LUNARC has Nvidia A100 GPUs. The modules are arranged as at HPC2N, with prerequisites, and with numba its own module #!/bin/bash Remember to change this to your own project ID! #SBATCH -A luXXXX-Y-ZZ We are asking for 5 minutes #SBATCH --time=00:05:00 #SBATCH --ntasks-per-node=1 Asking for one A100 GPU #SBATCH -p gpua100 #SBATCH --gres=gpu:1 Remove any loaded modules and load the ones we need module purge > /dev/null 2 > & 1 module load GCC/12.3.0 Python/3.11.3 OpenMPI/4.1.5 numba/0.58.1 SciPy-bundle/2023.07 CUDA/12.1.1 Run your Python script python add-list.py Tetralith has Nvidia T4 GPUs. #!/bin/bash # Remember to change this to your own project ID! #SBATCH -A naissXXXX-YY-ZZZ # We are asking for 5 minutes #SBATCH --time=00:05:00 # This is how you ask for a GPU at Tetralith - you need all three lines #SBATCH -n 1 #SBATCH -c 32 #SBATCH --gpus-per-task=1 # Remove any loaded modules and load the ones we need. This is safe here module purge > /dev/null 2 > & 1 # numba is not installed, but we need these in order to get the # prerequisites for an install in a virtual environment module load buildtool-easybuild/4.8.0-hpce082752a2 GCC/13.2.0 Python/3.11.5 SciPy-bundle/2023.11 JupyterLab/4.2.0 # Load a virtual environment where numba is installed # you can create it with the following steps BEFORE running the batch script: # ml buildtool-easybuild/4.8.0-hpce082752a2 GCC/13.2.0 Python/3.11.5 SciPy-bundle/2023.11 JupyterLab/4.2.0 # python -m venv mynumba # source mynumba/bin/activate # pip install numba # Then when you want to use it in the batch script, we include this source <path-to>/mynumba/bin/activate # Run your Python script python add-list.py Dardel has 4 AMD Instinct\u2122 MI250X \u00e1 2 GCDs per node. This is AMD GPUs and numba after version 0.53.1 only has compatibility with CUDA (Nvidia GPUs). The numba 0.53.1 version is too old to work with anything else installed. Thus, no numba example for PDC. You would have to use an example with hip instead and you would also need to install hip-python in a virtual environment to get any of it to work. If you want to ask for a GPU on Dardel, you add this to a batch script: #SBATCH -N 1 #SBATCH --ntasks-per-node=1 #SBATCH -p gpu There is some information about job scripts on Alvis here: https://www.c3se.chalmers.se/documentation/submitting_jobs/running_jobs/#writing-a-job-script On Alvis there are the following options on (Nvidia) GPUs to request and the lines to add in each case. So you would add ONE of these: #SBATCH --gpus-per-node=V100:1 # up to 4 #SBATCH --gpus-per-node=T4:1 # up to 8 #SBATCH --gpus-per-node=A40:1 # up to 4 #SBATCH --gpus-per-node=A100:1 # up to 4 #SBATCH --gpus-per-node=A100fat:1 # up to 4 This is the example script to run the numba example: #!/usr/bin/env bash # Change to your own job ID! The partition is alvis #SBATCH -A NAISSXXXX-Y-ZZ -p alvis #SBATCH -N 1 --gpus-per-node=T4:8 # 1 node with 8 Nvidia T4 GPUs #SBATCH -t 0-00:10:00 # module purge and then load the needed modules. numba at Alvis # automatically loads all the other needed modules (GCC, Python, # OpenMPI, SciPy-bundle, etc. so can be loaded directly module purge > /dev/null 2 > & 1 ml numba/0.58.1-foss-2023a # Run your Python script python add-list.py","title":"GPU jobs"},{"location":"commands/","text":"Module system commands \u00b6 Objectives Find software module versions Load a module (with potential prerequisites): default (often not recommended!) a specific version of software Unload software modules, including specific versions Unload all software modules with module purge This should never be done at PDC! You can do this at UPPMAX, but load the uppmax module afterwards. List the loaded modules Get some information about a module ( module show and module help ) Learn about module collections to load/unload a bunch of modules ( module save <collection> and module restore <collection> ) In the previous section we saw how to find out which modules are available at a centre, including looking for a specific software module. Now it is time to learn more useful module commands! Finding software versions \u00b6 If you just load a module without specifying the version, you will (depending on centre) get the default version or an error. There are good reasons not to just load the default version, even when it is possible: The default version is often the newest one installed, which means the default changes the next time an even newer version is installed. This could break your code or at least give a different result, which is bad for resproducibility. Sometimes you actually need a specific version, which could differ from the one the centre has decided on as default. So how do you find out which versions are available for a specific software? Note This is done differently, depending on the center you are at: HPC2N, LUNARC, C3SE, PDC: module spider MODULE or ml spider MODULE UPPMAX, NSC, /C3SE): module avail MODULE or ml avail MODULE With module spider \u00b6 Recommended at HPC2N, LUNARC, C3SE, and PDC. Note The command to find the available versions for a software module named MODULE is: module spider MODULE or, in short form ml spider MODULE With module avail \u00b6 Recommended at UPPMAX and NSC. Note The command to find the available version for a software module named MODULE is: module avail MODULE or, in short form ml av MODULE Example \u00b6 Finding available versions of Python. Tip Type along! module spider HPC2N LUNARC C3SE module spider Python Click to show b-an01 [ ~ ] $ module spider Python -------------------------------------------------------------------------------------------------------------------- Python: -------------------------------------------------------------------------------------------------------------------- Description: Python is a programming language that lets you work more quickly and integrate your systems more effectively. Versions: Python/2.7.15 Python/2.7.16 Python/2.7.18-bare Python/2.7.18 Python/3.7.2 Python/3.7.4 Python/3.8.2 Python/3.8.6 Python/3.9.5-bare Python/3.9.5 Python/3.9.6-bare Python/3.9.6 Python/3.10.4-bare Python/3.10.4 Python/3.10.8-bare Python/3.10.8 Python/3.11.3 Python/3.11.5 Python/3.12.3 Other possible modules matches: Biopython Boost.Python Brotli-python GitPython IPython Python-bundle-PyPI bx-python flatbuffers-python ... -------------------------------------------------------------------------------------------------------------------- To find other possible module matches execute: $ module -r spider '.*Python.*' -------------------------------------------------------------------------------------------------------------------- For detailed information about a specific \"Python\" package ( including how to load the modules ) use the module ' s full name. Note that names that have a trailing ( E ) are extensions provided by other modules. For example: $ module spider Python/3.12.3 -------------------------------------------------------------------------------------------------------------------- module spider Python Click to show [ bbrydsoe@cosmos3 ~ ] $ module spider Python ---------------------------------------------------------------------------------------------------------------------------- Python: ---------------------------------------------------------------------------------------------------------------------------- Description: Python is a programming language that lets you work more quickly and integrate your systems more effectively. Versions: Python/2.7.18-bare Python/2.7.18 Python/3.8.6 Python/3.9.5-bare Python/3.9.5 Python/3.9.6-bare Python/3.9.6 Python/3.10.4-bare Python/3.10.4 Python/3.10.8-bare Python/3.10.8 Python/3.11.3 Python/3.11.5 Python/3.12.3 Other possible modules matches: Biopython GitPython IPython Python-bundle Python-bundle-PyPI bx-python flatbuffers-python graphviz-python ... ---------------------------------------------------------------------------------------------------------------------------- To find other possible module matches execute: $ module -r spider '.*Python.*' ---------------------------------------------------------------------------------------------------------------------------- For detailed information about a specific \"Python\" package ( including how to load the modules ) use the module ' s full name. Note that names that have a trailing ( E ) are extensions provided by other modules. For example: $ module spider Python/3.12.3 ---------------------------------------------------------------------------------------------------------------------------- module spider Python Click to show [ brydso@alvis1 ~ ] $ module spider Python ----------------------------------------------------------------------------------------------------------------------------- Python: ----------------------------------------------------------------------------------------------------------------------------- Description: Python is a programming language that lets you work more quickly and integrate your systems more effectively. Versions: Python/2.7.18-GCCcore-11.2.0-bare Python/2.7.18-GCCcore-11.3.0-bare Python/2.7.18-GCCcore-12.2.0-bare Python/3.9.5-GCCcore-10.3.0-bare Python/3.9.5-GCCcore-10.3.0 Python/3.9.6-GCCcore-11.2.0-bare Python/3.9.6-GCCcore-11.2.0 Python/3.10.4-GCCcore-11.3.0-bare Python/3.10.4-GCCcore-11.3.0 Python/3.10.8-GCCcore-12.2.0-bare Python/3.10.8-GCCcore-12.2.0 Python/3.11.3-GCCcore-12.3.0 Python/3.11.5-GCCcore-13.2.0 Python/3.12.3-GCCcore-13.3.0 Other possible modules matches: Biopython Boost.Python CUDA-Python GitPython IPython Python-bundle-PyPI flatbuffers-python meson-python ... ----------------------------------------------------------------------------------------------------------------------------- To find other possible module matches execute: $ module -r spider '.*Python.*' ----------------------------------------------------------------------------------------------------------------------------- For detailed information about a specific \"Python\" package ( including how to load the modules ) use the module ' s full name. Note that names that have a trailing ( E ) are extensions provided by other modules. For example: $ module spider Python/3.12.3-GCCcore-13.3.0 ----------------------------------------------------------------------------------------------------------------------------- module spider, mostly PDC module spider python Click to show - python bbrydsoe@login1:~> ml spider python ----------------------------------------------------------------------------------------------------------------------------- python: ----------------------------------------------------------------------------------------------------------------------------- Versions: python/2.7.6 python/2.7.9 python/2.7.11 python/2.7.15 python/3.3 python/3.3.1 python/3.4.3 python/3.5.0 python/3.6.0 python/3.6.8 python/3.7.2 python/3.8.7 python/3.9.5 python/3.9.6 python/3.10.8 python/3.11.4 python/3.11.6-gcc-oc3 python/3.11.6-gcc-qyw python/3.11.6-gcc-spv python/3.11.8 python/3.11.9-gcc-epm python/3.12.1 python/3.12.3 python/3.13.0-gcc-cgo Other possible modules matches: biopython cray-python dbus-python pdc-python py-meson-python py-python-dateutil python-2.7.18-gcc-11.2.0-namldiz python-3.8.12-gcc-11.2.0-nwj732o python-3.8.12-gcc-11.2.0-vhhulma ... ----------------------------------------------------------------------------------------------------------------------------- To find other possible module matches execute: $ module -r spider '.*python.*' ----------------------------------------------------------------------------------------------------------------------------- For detailed information about a specific \"python\" package ( including how to load the modules ) use the module ' s full name. Note that names that have a trailing ( E ) are extensions provided by other modules. For example: $ module spider python/3.13.0-gcc-cgo ----------------------------------------------------------------------------------------------------------------------------- Click to show - cray-python bbrydsoe@login1:~> module avail cray-python ------------------------------------ /opt/cray/pe/lmod/modulefiles/core ------------------------------------- cray-python/3.10.10 cray-python/3.11.5 ( D ) cray-python/3.11.7 Where: D: Default Module If the avail list is too long consider trying: \"module --default avail\" or \"ml -d av\" to just list the default modules. \"module overview\" or \"ml ov\" to display the number of modules for each name. Use \"module spider\" to find all possible modules and extensions. Use \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\" . module avail UPPMAX NSC C3SE module avail python Click to show [ bbrydsoe@rackham1 ~ ] $ module avail python --------------------------------- /sw/mf/rackham/applications ---------------------------------- python_GIS_packages/3.10.8 python_ML_packages/3.9.5-gpu wrf-python/1.3.1 python_ML_packages/3.9.5-cpu python_ML_packages/3.11.8-cpu ( D ) ----------------------------------- /sw/mf/rackham/compilers ----------------------------------- python/2.7.6 python/3.4.3 python/3.9.5 python3/3.6.0 python3/3.11.4 python/2.7.9 python/3.5.0 python/3.10.8 python3/3.6.8 python3/3.11.8 python/2.7.11 python/3.6.0 python/3.11.4 python3/3.7.2 python3/3.12.1 python/2.7.15 python/3.6.8 python/3.11.8 python3/3.8.7 python3/3.12.7 ( D ) python/3.3 python/3.7.2 python/3.12.1 python3/3.9.5 python/3.3.1 python/3.8.7 python/3.12.7 ( D ) python3/3.10.8 Where: D: Default Module Use \"module spider\" to find all possible modules and extensions. Use \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\" . Ignore the comment about using module spider ! module avail python Click to show [ x_birbr@tetralith3 ~ ] $ module avail python --------------------- /software/sse2/tetralith_el9/modules --------------------- ASE/3.22.1-hpc1-python ASE/3.23.0-hpc1-python GaussSum/3.0.2-Python-3.7.8-hpc1 NCL/6.6.2-hpc2-Python Pylint/3.2.5-hpc1-Python-3.11.5 Python/recommendation ( D ) Python/2.7.18-bare-hpc1-gcc-2022a-eb Python/3.10.4-bare-hpc1-gcc-2022a-eb Python/3.10.4-env-hpc1-gcc-2022a-eb Python/3.10.4-env-hpc2-gcc-2022a-eb Python/3.11.5-bare-hpc1-gcc-2023b-eb Python/3.11.5-env-hpc1-gcc-2023b-eb Where: D: Default Module module avail Python Click to show You will get output that includes what you look for, but also a lot of other output - and only if you use \u201cPython\u201d instead of \u201cpython\u201d [ brydso@alvis1 ~ ] $ module avail Python ------------------------------------------------------------------ /apps/Arch/fmodules/all ------------------------------------------------------------------ Biopython/1.79-foss-2021a Python/2.7.18-GCCcore-12.2.0-bare meson-python/0.18.0-GCCcore-14.2.0 ( D ) Biopython/1.79-foss-2021b Python/3.9.5-GCCcore-10.3.0-bare netcdf4-python/1.6.4-foss-2023a Biopython/1.79-foss-2022a Python/3.9.5-GCCcore-10.3.0 netcdf4-python/1.6.5-foss-2023b Biopython/1.83-foss-2023a ( D ) Python/3.9.6-GCCcore-11.2.0-bare netcdf4-python/1.7.1.post2-foss-2024a ( D ) Boost.Python/1.82.0-GCC-12.3.0 Python/3.9.6-GCCcore-11.2.0 openslide-python/1.1.2-GCCcore-10.3.0 CUDA-Python/12.1.0-gfbf-2023a-CUDA-12.1.1 Python/3.10.4-GCCcore-11.3.0-bare openslide-python/1.1.2-GCCcore-11.2.0 ( D ) CUDA-Python/12.6.2.post1-gfbf-2024a-CUDA-12.6.0 ( D ) Python/3.10.4-GCCcore-11.3.0 pkgconfig/1.5.4-GCCcore-10.3.0-python GitPython/3.1.27-GCCcore-11.3.0 Python/3.10.8-GCCcore-12.2.0-bare pkgconfig/1.5.5-GCCcore-11.2.0-python GitPython/3.1.40-GCCcore-12.3.0 ( D ) Python/3.10.8-GCCcore-12.2.0 pkgconfig/1.5.5-GCCcore-11.3.0-python IPython/7.25.0-GCCcore-10.3.0 Python/3.11.3-GCCcore-12.3.0 pkgconfig/1.5.5-GCCcore-12.2.0-python IPython/7.26.0-GCCcore-11.2.0 Python/3.11.5-GCCcore-13.2.0 pkgconfig/1.5.5-GCCcore-12.3.0-python ( D ) IPython/8.5.0-GCCcore-11.3.0 Python/3.12.3-GCCcore-13.3.0 protobuf-python/3.17.3-GCCcore-10.3.0 IPython/8.14.0-GCCcore-12.2.0 Python/3.13.1-GCCcore-14.2.0 protobuf-python/3.17.3-GCCcore-11.2.0 IPython/8.14.0-GCCcore-12.3.0 Python/3.13.5-GCCcore-14.3.0 ( D ) protobuf-python/3.19.4-GCCcore-11.3.0 IPython/8.17.2-GCCcore-13.2.0 Z3/4.12.2-GCCcore-12.3.0-Python-3.11.3 protobuf-python/4.23.0-GCCcore-12.2.0 IPython/8.28.0-GCCcore-13.3.0 flatbuffers-python/2.0-GCCcore-10.3.0 protobuf-python/4.24.0-GCCcore-12.3.0 IPython/9.3.0-GCCcore-14.2.0 ( D ) flatbuffers-python/2.0-GCCcore-11.2.0 protobuf-python/5.28.0-GCCcore-13.3.0 ( D ) Python-bundle-PyPI/2023.06-GCCcore-12.3.0 flatbuffers-python/2.0-GCCcore-11.3.0 python-mujoco/2.2.2-foss-2022a Python-bundle-PyPI/2023.10-GCCcore-13.2.0 flatbuffers-python/23.1.4-GCCcore-12.2.0 python-mujoco/3.1.4-foss-2023a ( D ) Python-bundle-PyPI/2024.06-GCCcore-13.3.0 flatbuffers-python/23.5.26-GCCcore-12.3.0 ( D ) python-xxhash/3.4.1-GCCcore-12.3.0 Python-bundle-PyPI/2025.04-GCCcore-14.2.0 ( D ) meson-python/0.13.2-GCCcore-12.3.0 spglib-python/1.16.1-foss-2021a Python/2.7.18-GCCcore-11.2.0-bare meson-python/0.15.0-GCCcore-13.2.0 spglib-python/2.0.0-foss-2022a Python/2.7.18-GCCcore-11.3.0-bare meson-python/0.16.0-GCCcore-13.3.0 spglib-python/2.1.0-gfbf-2023a ( D ) ... Exercise At your chosen centre, check the different output for module avail Python and module spider Python Do you get the same output for \u201cPython\u201d and \u201cpython\u201d? List loaded modules \u00b6 There is a very useful command to list which modules you have loaded. It is module list or, in short form ml Tip Try it now! With nothing loaded, only the \u201csticky\u201d modules are listed. They are modules that are needed for the environment to function correctly, so do not remove them! Load software module \u00b6 In order to load modules, we need to know how . This differs by center only inasmuch as some centers have prerequisites (usually compiler toolchains ) for most of the software modules. The centers that recommend module spider for finding the software modules generally have prerequisites (HPC2N, LUNARC, PDC - and sometimes C3SE), while those who recommend module avail generally do not (UPPMAX, NSC). Thus; if the centers suggests you do module spider you will need to check the required prerequisites to load. Prerequisites \u00b6 This is done with module spider <module>/<version> You can also do this at the centers recommending module avail , but that will generally just tell you the module can be loaded directly. Prerequisites At some centres it is common that modules have prerequisites (usually GCC, various libraries or something similar) while at other centres most modules can be loaded directly. HPC2N : most software modules have prerequisites (GCC/Intel, OpenMPI, \u2026), a few do not (MATLAB, \u2026) LUNARC : most software modules have prerequisites (GCC/Intel, OpenMPI, \u2026), a few do not (MATLAB, \u2026) UPPMAX : software modules can generally be loaded directly unless its is related to bioinformatics (then load bioinfo-tools first). New cluster Pelle does not require you to load bioinfo-tools !!! note - **On Pelle things are more like NSC, you may follow the examples for that cluster instead of Rackham** - Though, note that outputdetails will most probably be different on Pelle! NSC : software modules can generally be loaded directly PDC : most software modules have prerequisites (PDC which is a collection of compilers and libraries), a few do not (MATLAB, cray-modules, \u2026) C3SE : software modules can generally be loaded directly HPC2N UPPMAX NSC Example, finding out how to load Python, version 3.12.3 b-an01 [ ~ ] $ module spider Python/3.12.3 -------------------------------------------------------------------------------------------------------------------- Python: Python/3.12.3 -------------------------------------------------------------------------------------------------------------------- Description: Python is a programming language that lets you work more quickly and integrate your systems more effectively. You will need to load all module ( s ) on any one of the lines below before the \"Python/3.12.3\" module is available to load. GCCcore/13.3.0 This module provides the following extensions: flit_core/3.9.0 ( E ) , packaging/24.0 ( E ) , pip/24.0 ( E ) , setuptools/70.0.0 ( E ) , setuptools_scm/8.1.0 ( E ) , tomli/2.0.1 ( E ) , typing_extensions/4.11.0 ( E ) , wheel/0.43.0 ( E ) Help: Description =========== Python is a programming language that lets you work more quickly and integrate your systems more effectively. More information ================ - Homepage: https://python.org/ Included extensions =================== flit_core-3.9.0, packaging-24.0, pip-24.0, setuptools-70.0.0, setuptools_scm-8.1.0, tomli-2.0.1, typing_extensions-4.11.0, wheel-0.43.0 There are some things to pay attention to here: You are told the prerequisites are \u201cGCCcore/13.3.0\u201d (if you need OpenMPI or modules requiring it, it is better to load \u201cGCC/13.3.0\u201d as GCCcore is part of it) After loading that, you can load the module itself, \u201cPython/3.12.3\u201d You are told about the extensions that are included. Here, this would be the Python packages that are included, which is not very many. HPC2N and some of the other centres use separate modules or module bundles (SciPy-bundle for instance) for any extensions/packages that you might need. Example, Finding out how to load Python, version 3.11.8 (Rackham) On Pelle things are more like NSC, have a look there! [ bbrydsoe@rackham1 ~ ] $ ml avail python/3.11.8 ----------------------------------- /sw/mf/rackham/compilers ----------------------------------- python/3.11.8 Use \"module spider\" to find all possible modules and extensions. Use \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\" . This did not tell us much! Let us try module spider [ bbrydsoe@rackham1 ~ ] $ module spider python/3.11.8 -------------------------------------------------------------------------------------------- python: python/3.11.8 -------------------------------------------------------------------------------------------- This module can be loaded directly: module load python/3.11.8 Help: Python - use python/3.11.8 Version 3 .11.8 https://python.org This module was built with gcc/12.3.0 sqlite/3.34.0 Tcl-Tk/8.6.11 This module provides the executable names 'python' and 'python3' . Several additional python packages are also installed in this module. The complete list of packages in this module, produced using 'pip list' , is: Package Version ------------------------- --------------- anndata 0 .10.5.post1 anyio 4 .2.0 argon2-cffi 23 .1.0 argon2-cffi-bindings 21 .2.0 array_api_compat 1 .4.1 arrow 1 .3.0 asteval 0 .9.31 asttokens 2 .4.1 async-lru 2 .0.4 ... Here we learn: You can load \u201cpython/3.11.8\u201d directly It was built with \u201cgcc/12.3.0 sqlite/3.34.0 Tcl-Tk/8.6.11\u201d (might be useful for compatibility with other things). It lists all the extensions (here Python packages) loaded with it - and it is a lot, around 250 packages. Example, finding out how to load Python, version 3.11.5 [ x_birbr@tetralith3 ~ ] $ module avail Python/3.11.5 ------------------------------------------ /software/sse2/tetralith_el9/modules ------------------------------------------- Python/3.11.5-bare-hpc1-gcc-2023b-eb Python/3.11.5-env-hpc1-gcc-2023b-eb This was not so helpful. Let us try with \u201cmodule spider\u201d: [ x_birbr@tetralith3 ~ ] $ module spider Python/3.11.5 #################################################################################################################################### # NOTE: At NSC the output of 'module spider' is generally not helpful as all relevant software modules are shown by 'module avail' # # Some HPC centers hide software until the necessary dependencies have been loaded. NSC does not do that. # #################################################################################################################################### ----------------------------------------------------------------------------------------------------------------------- Python: Python/3.11.5 ----------------------------------------------------------------------------------------------------------------------- Description: Python is a programming language that lets you work more quickly and integrate your systems more effectively. You will need to load all module ( s ) on any one of the lines below before the \"Python/3.11.5\" module is available to load. buildtool-easybuild/.5.1.1-hpce5ba34320 GCCcore/13.2.0 buildtool-easybuild/4.8.0-hpce082752a2 GCCcore/13.2.0 buildtool-easybuild/4.9.4-hpc71cbb0050 GCCcore/13.2.0 Help: Description =========== Python is a programming language that lets you work more quickly and integrate your systems more effectively. More information ================ - Homepage: https://python.org/ Included extensions =================== flit_core-3.9.0, packaging-23.2, pip-23.2.1, setuptools-68.2.2, setuptools-scm-8.0.4, tomli-2.0.1, typing_extensions-4.8.0, wheel-0.41.2 Here we learn that there is a \u201cbare\u201d Python (like \u201cPython/3.11.5-bare-hpc1-gcc-2023b-eb\u201d) that you can load directly Otherwise, you need to load the prerequisites of a buildtool and a GCCcore first, before loading Python. That is knowledge that can be useful for finding compatibility with other software modules You also learn that there is a (small) number of extensions/packages with this Python Loading \u00b6 To load a software module, do: (if needed) module load <prerequisite>/<suitable version> module load <module>/<compatible version> and the versions you got from module spider . Again, ml load <module>/<version> can be used as a short form. When you have loaded the module, you can see that your list of loaded modules has changed. This is done with module list or ml . Hint Type along! Example, HPC2N Loading Python 3.12.3 and prerequisites, and checking before and after which modules are loaded. module list Click to show output! b-an01 [ ~ ] $ module list Currently Loaded Modules: 1 ) snicenvironment ( S ) 2 ) systemdefault ( S ) Where: S: Module is Sticky, requires --force to unload or purge module load GCCcore/13.3.0 Python/3.12.3 or load them on separate lines module load GCCcore/13.3.0 module load Python/3.12.3 What is the advantage to loading them one at a time? You can then easier find compatible modules that depend on that version, using module avail . Click to show output! b-an01 [ ~ ] $ module load GCCcore/13.3.0 Python/3.12.3 b-an01 [ ~ ] $ And now do module list again! Click to show output! b-an01 [ ~ ] $ module list Currently Loaded Modules: 1 ) snicenvironment ( S ) 4 ) zlib/1.3.1 7 ) ncurses/6.5 10 ) SQLite/3.45.3 13 ) OpenSSL/3 2 ) systemdefault ( S ) 5 ) binutils/2.42 8 ) libreadline/8.2 11 ) XZ/5.4.5 14 ) Python/3.12.3 3 ) GCCcore/13.3.0 6 ) bzip2/1.0.8 9 ) Tcl/8.6.14 12 ) libffi/3.4.5 Where: S: Module is Sticky, requires --force to unload or purge Example, NSC Loading Python version 3.11.5 (the module is called Python/3.11.5-env-hpc1-gcc-2023b-eb and can be loaded directly). Also do module list before and after! module list Click to show output! [ x_birbr@tetralith3 ~ ] $ module list Currently Loaded Modules: 1 ) hpc/.1.10.1 ( H,S ) Where: S: Module is Sticky, requires --force to unload or purge H: Hidden Module module load Python/3.11.5-env-hpc1-gcc-2023b-eb Click to show output! [ x_birbr@tetralith3 ~ ] $ module load Python/3.11.5-env-hpc1-gcc-2023b-eb [ x_birbr@tetralith3 ~ ] $ ml Click to show output! [ x_birbr@tetralith3 ~ ] $ ml Currently Loaded Modules: 1 ) hpc/.1.10.1 ( H,S ) 2 ) Python/3.11.5-env-hpc1-gcc-2023b-eb Where: S: Module is Sticky, requires --force to unload or purge H: Hidden Module Or load one of the Python modules with prerequisites: Click to show output! [ x_birbr@tetralith3 ~ ] $ ml buildtool-easybuild/4.8.0-hpce082752a2 GCCcore/13.2.0 Python/3.11.5 [ x_birbr@tetralith3 ~ ] $ Let us see the output of \u201cmodule list\u201d now: [ x_birbr@tetralith3 ~ ] $ module list Currently Loaded Modules: 1 ) hpc/.1.10.1 ( H,S ) 5 ) binutils/.2.40 ( H ) 9 ) Tcl/8.6.13 13 ) OpenSSL/1.1 2 ) buildtool-easybuild/4.8.0-hpce082752a2 6 ) bzip2/1.0.8 10 ) SQLite/3.43.1 14 ) Python/3.11.5 3 ) GCCcore/13.2.0 7 ) ncurses/6.4 11 ) XZ/5.4.4 4 ) zlib/.1.2.13 ( H ) 8 ) libreadline/8.2 12 ) libffi/3.4.4 Where: S: Module is Sticky, requires --force to unload or purge H: Hidden Module Important You can do several module load on the same line. Or you can do them one at a time, as you want. The modules have to be loaded in order! You cannot list the prerequisite after the module that needs it! One advantage to loading modules one at a time is that you can then find compatible modules that depend on that version easily. Example: you have loaded GCC/13.2.0 and Python/3.11.5 at HPC2N or LUNARC. You can now do ml av or module avail to see which versions of other modules you want to load, say SciPy-bundle , are compatible. If you know the name of the module you want, you can even start writing module load SciPy-bundle/ (for instance) and press TAB - the system will then autocomplete to the compatible one(s). Loading several modules \u00b6 There are situations where you need to load several modules, even at centres where there are no prerequisites. Example You need some Python packages not included in the base Python you loaded, for instance TensorFlow or maybe AlphaFold. You now need to load a version of that module which is compatible with the Python you want. HPC2N UPPMAX NSC Tensorflow needs Python and SciPy-bundle. SciPy-bundle also needs OpenMPI. TensorFlow loads Python and SciPy-bundle itself, but you need their prerequisites: b-an01 [ ~ ] $ module spider TensorFlow/2.15.1-CUDA-12.1.1 -------------------------------------------------------------------------------------------------------------------- TensorFlow: TensorFlow/2.15.1-CUDA-12.1.1 -------------------------------------------------------------------------------------------------------------------- Description: An open-source software library for Machine Intelligence You will need to load all module ( s ) on any one of the lines below before the \"TensorFlow/2.15.1-CUDA-12.1.1\" module is available to load. GCC/12.3.0 OpenMPI/4.1.5 This module provides the following extensions: absl-py/2.1.0 ( E ) , astor/0.8.1 ( E ) , astunparse/1.6.3 ( E ) , cachetools/5.3.3 ( E ) , google-auth-oauthlib/1.2.0 ( E ) , google-auth/2.29.0 ( E ) , google-pasta/0.2.0 ( E ) , gviz-api/1.10.0 ( E ) , keras/2.15.0 ( E ) , Markdown/3.6 ( E ) , oauthlib/3.2.2 ( E ) , pyasn1-modules/0.4.0 ( E ) , requests-oauthlib/2.0.0 ( E ) , rsa/4.9 ( E ) , tblib/3.0.0 ( E ) , tensorboard-data-server/0.7.2 ( E ) , tensorboard-plugin-profile/2.15.1 ( E ) , tensorboard/2.15.2 ( E ) , tensorflow-estimator/2.15.0 ( E ) , TensorFlow/2.15.1 ( E ) , termcolor/2.3.0 ( E ) , Werkzeug/3.0.2 ( E ) , wrapt/1.14.1 ( E ) b-an01 [ ~ ] $ module load GCC/12.3.0 OpenMPI/4.1.5 b-an01 [ ~ ] $ module load TensorFlow/2.15.1-CUDA-12.1.1 TensorFlow is included in the Python_ML_packages. Python gets loaded with the Python_ML_packages so nothing extra needs loading here [ bbrydsoe@rackham1 ~ ] $ ml spider python_ML_packages/3.11.8-cpu -------------------------------------------------------------------------------------------- python_ML_packages: python_ML_packages/3.11.8-cpu -------------------------------------------------------------------------------------------- This module can be loaded directly: module load python_ML_packages/3.11.8-cpu Help: python_ML_packages version 3 .11.8-cpu [ bbrydsoe@rackham1 ~ ] $ ml python_ML_packages/3.11.8-cpu [ bbrydsoe@rackham1 ~ ] $ However, if you for instance need Matlab together with Gurobi, then you need to load both modules: [ bbrydsoe@rackham1 ~ ] $ ml spider matlab/R2023b [ bbrydsoe@rackham1 ~ ] $ ml Gurobi/11.0.3 TensorFlow is not installed, so if you need that you would have to install it yourself in a Virtual environment. Let us assume we need \u201cpandas\u201d which is installed. It is included in SciPy-bundle, which pulls in Python and OpenMPI, but does have other prerequisites [ x_birbr@tetralith3 ~ ] $ ml spider SciPy-bundle/2023.11 #################################################################################################################################### # NOTE: At NSC the output of 'module spider' is generally not helpful as all relevant software modules are shown by 'module avail' # # Some HPC centers hide software until the necessary dependencies have been loaded. NSC does not do that. # #################################################################################################################################### ----------------------------------------------------------------------------------------------------------------------- SciPy-bundle: SciPy-bundle/2023.11 ----------------------------------------------------------------------------------------------------------------------- Description: Bundle of Python packages for scientific software You will need to load all module ( s ) on any one of the lines below before the \"SciPy-bundle/2023.11\" module is available to load. buildtool-easybuild/.5.1.1-hpce5ba34320 GCC/13.2.0 buildtool-easybuild/4.8.0-hpce082752a2 GCC/13.2.0 buildtool-easybuild/4.9.4-hpc71cbb0050 GCC/13.2.0 Help: Description =========== Bundle of Python packages for scientific software More information ================ - Homepage: https://python.org/ Included extensions =================== beniget-0.4.1, Bottleneck-1.3.7, deap-1.4.1, gast-0.5.4, mpmath-1.3.0, numexpr-2.8.7, numpy-1.26.2, pandas-2.1.3, ply-3.11, pythran-0.14.0, scipy-1.11.4, tzdata-2023.3, versioneer-0.29 [ x_birbr@tetralith3 ~ ] $ ml buildtool-easybuild/4.8.0-hpce082752a2 GCC/13.2.0 SciPy-bundle/2023.11 Another useful \u201csuper\u201d package at NSC is \u201cPython-bundle-PyPI/2023.10\u201d. Unload software modules \u00b6 Aside from module unload this section will also cover module purge ! Note Why would you want to unload a module? If you want to use a different version of a module, you need to unload the current one first If you need a different version of a dependent module, but it is not compatible with the current prerequisite you have loaded Modules can be unloaded with: module unload <MODULE> may or may not work module unload <MODULE>/<version> ml unload <MODULE>/<version> short form of the above module -<MODULE>/<version> ml -<MODULE>/<version> short form of the above ml -<MODULE>/<version> short form of the above Unloading a module will not unload the prerequisites . This is not usually a problem at the centres where there rarely are prerequisites (UPPMAX, NSC), but can be annoying at centres who usually have prerequisites for the modules (HPC2N, LUNARC, C3SE, PDC). However, there the easy solution is module purge (HPC2N, LUNARC, C3SE). The command module purge removes all the loaded modules, except the \u201csticky\u201d modules. It is recommended at HPC2N, LUNARC, and C3SE. Warning Do not use module purge at PDC! At PDC, there are a lot of necessary, \u201csystem-modules\u201d that are preloaded. When you do module purge they will also be unloaded and things may not work as it should! At UPPMAX (Rackham and Bianca, not Pelle), the system-module \u201cuppmax\u201d will get unloaded with module purge , but can easily be reloaded with module load uppmax . To see what the uppmax module does, do: ml show uppmax . It sets some environment variables and aliases. Unloading examples \u00b6 No prerequisites \u00b6 Unloading one module, with no prerequisites (for clarity, we also do module list before and after to show what is happening. Tip Type along! First load a suitable module for your center (with no prerequisites). Suggestions: HPC2N, LUNARC: GCC/12.3.0 UPPMAX: python/3.11.8 C3SE: Python/3.12.3-GCCcore-13.3.0 NSC: Python/3.11.5-env-hpc1-gcc-2023b-eb PDC: cray-python/3.11.5 HPC2N Check which modules are loaded (after loading GCC/12.3.0 earlier) b-an01 [ ~ ] $ module list Currently Loaded Modules: 1 ) snicenvironment ( S ) 3 ) GCCcore/12.3.0 5 ) binutils/2.40 2 ) systemdefault ( S ) 4 ) zlib/1.2.13 6 ) GCC/12.3.0 Where: S: Module is Sticky, requires --force to unload or purge b-an01 [ ~ ] $ Unload GCC/12.3.0 b-an01 [ ~ ] $ module unload GCC/12.3.0 b-an01 [ ~ ] $ Check which modules are loaded b-an01 [ ~ ] $ module list Currently Loaded Modules: 1 ) snicenvironment ( S ) 2 ) systemdefault ( S ) Where: S: Module is Sticky, requires --force to unload or purge NSC Check which modules are loaded (after loading Python/3.11.5-env-hpc1-gcc-2023b-eb earlier) [ x_birbr@tetralith3 ~ ] $ module list Currently Loaded Modules: 1 ) hpc/.1.10.1 ( H,S ) 2 ) Python/3.11.5-env-hpc1-gcc-2023b-eb Where: S: Module is Sticky, requires --force to unload or purge H: Hidden Module Unload Python/3.11.5-env-hpc1-gcc-2023b-eb [ x_birbr@tetralith3 ~ ] $ ml -Python/3.11.5-env-hpc1-gcc-2023b-eb [ x_birbr@tetralith3 ~ ] $ Check which modules are loaded [ x_birbr@tetralith3 ~ ] $ ml Currently Loaded Modules: 1 ) hpc/.1.10.1 ( H,S ) Where: S: Module is Sticky, requires --force to unload or purge H: Hidden Module Prerequisites \u00b6 Here we look at what happens when you unload something that has a prerequisite. Example, HPC2N LUNARC would be the same. Loading Python and prerequisites b-an01 [ ~ ] $ module load GCC/12.3.0 b-an01 [ ~ ] $ module load Python/3.11.3 Check loaded modules b-an01 [ ~ ] $ ml Currently Loaded Modules: 1 ) snicenvironment ( S ) 4 ) zlib/1.2.13 7 ) bzip2/1.0.8 10 ) Tcl/8.6.13 13 ) libffi/3.4.4 2 ) systemdefault ( S ) 5 ) binutils/2.40 8 ) ncurses/6.4 11 ) SQLite/3.42.0 14 ) OpenSSL/1.1 3 ) GCCcore/12.3.0 6 ) GCC/12.3.0 9 ) libreadline/8.2 12 ) XZ/5.4.2 15 ) Python/3.11.3 Where: S: Module is Sticky, requires --force to unload or purge Unload Python/3.11.3 b-an01 [ ~ ] $ ml unload Python/3.11.3 Check loaded modules b-an01 [ ~ ] $ ml Currently Loaded Modules: 1 ) snicenvironment ( S ) 3 ) GCCcore/12.3.0 5 ) binutils/2.40 2 ) systemdefault ( S ) 4 ) zlib/1.2.13 6 ) GCC/12.3.0 Where: S: Module is Sticky, requires --force to unload or purge Unload GCC/12.3.0 b-an01 [ ~ ] $ ml -GCC/12.3.0 Check loaded modules b-an01 [ ~ ] $ ml Currently Loaded Modules: 1 ) snicenvironment ( S ) 2 ) systemdefault ( S ) Where: S: Module is Sticky, requires --force to unload or purge What happens if you try and unload the prerequisite? Example, HPC2N b-an01 [ ~ ] $ ml GCC/12.3.0 Python/3.11.3 b-an01 [ ~ ] $ ml Currently Loaded Modules: 1 ) snicenvironment ( S ) 4 ) zlib/1.2.13 7 ) bzip2/1.0.8 10 ) Tcl/8.6.13 13 ) libffi/3.4.4 2 ) systemdefault ( S ) 5 ) binutils/2.40 8 ) ncurses/6.4 11 ) SQLite/3.42.0 14 ) OpenSSL/1.1 3 ) GCCcore/12.3.0 6 ) GCC/12.3.0 9 ) libreadline/8.2 12 ) XZ/5.4.2 15 ) Python/3.11.3 Where: S: Module is Sticky, requires --force to unload or purge b-an01 [ ~ ] $ ml -GCC/12.3.0 Inactive Modules: 1 ) OpenSSL/1.1 3 ) SQLite/3.42.0 5 ) XZ/5.4.2 7 ) libffi/3.4.4 2 ) Python/3.11.3 4 ) Tcl/8.6.13 6 ) bzip2/1.0.8 8 ) libreadline/8.2 Due to MODULEPATH changes, the following have been reloaded: 1 ) binutils/2.40 2 ) ncurses/6.4 3 ) zlib/1.2.13 module purge \u00b6 What about module purge ? Important At some centres, module purge is recommended and at some it is at least safe: HPC2N, LUNARC, NSC, C3SE HPC2N LUNARC C3SE NSC b-an01 [ ~ ] $ ml GCC/12.3.0 Python/3.11.3 b-an01 [ ~ ] $ ml Currently Loaded Modules: 1 ) snicenvironment ( S ) 4 ) zlib/1.2.13 7 ) bzip2/1.0.8 10 ) Tcl/8.6.13 13 ) libffi/3.4.4 2 ) systemdefault ( S ) 5 ) binutils/2.40 8 ) ncurses/6.4 11 ) SQLite/3.42.0 14 ) OpenSSL/1.1 3 ) GCCcore/12.3.0 6 ) GCC/12.3.0 9 ) libreadline/8.2 12 ) XZ/5.4.2 15 ) Python/3.11.3 Where: S: Module is Sticky, requires --force to unload or purge b-an01 [ ~ ] $ ml purge The following modules were not unloaded: ( Use \"module --force purge\" to unload all ) : 1 ) snicenvironment 2 ) systemdefault b-an01 [ ~ ] $ ml Currently Loaded Modules: 1 ) snicenvironment ( S ) 2 ) systemdefault ( S ) Where: S: Module is Sticky, requires --force to unload or purge All good! [ bbrydsoe@cosmos3 ~ ] $ ml GCC/12.3.0 Python/3.11.3 [ bbrydsoe@cosmos3 ~ ] $ ml Currently Loaded Modules: 1 ) SoftwareTree/Milan ( S ) 4 ) binutils/2.40 7 ) ncurses/6.4 10 ) SQLite/3.42.0 13 ) OpenSSL/1.1 2 ) GCCcore/12.3.0 5 ) GCC/12.3.0 8 ) libreadline/8.2 11 ) XZ/5.4.2 14 ) Python/3.11.3 3 ) zlib/1.2.13 6 ) bzip2/1.0.8 9 ) Tcl/8.6.13 12 ) libffi/3.4.4 Where: S: Module is Sticky, requires --force to unload or purge [ bbrydsoe@cosmos3 ~ ] $ ml purge The following modules were not unloaded: ( Use \"module --force purge\" to unload all ) : 1 ) SoftwareTree/Milan [ bbrydsoe@cosmos3 ~ ] $ ml Currently Loaded Modules: 1 ) SoftwareTree/Milan ( S ) Where: S: Module is Sticky, requires --force to unload or purge All good! [ brydso@alvis1 ~ ] $ ml No modules loaded [ brydso@alvis1 ~ ] $ ml Python/3.12.3-GCCcore-13.3.0 [ brydso@alvis1 ~ ] $ ml Currently Loaded Modules: 1 ) GCCcore/13.3.0 5 ) ncurses/6.5-GCCcore-13.3.0 9 ) XZ/5.4.5-GCCcore-13.3.0 2 ) zlib/1.3.1-GCCcore-13.3.0 6 ) libreadline/8.2-GCCcore-13.3.0 10 ) libffi/3.4.5-GCCcore-13.3.0 3 ) binutils/2.42-GCCcore-13.3.0 7 ) Tcl/8.6.14-GCCcore-13.3.0 11 ) OpenSSL/3 4 ) bzip2/1.0.8-GCCcore-13.3.0 8 ) SQLite/3.45.3-GCCcore-13.3.0 12 ) Python/3.12.3-GCCcore-13.3.0 [ brydso@alvis1 ~ ] $ ml purge [ brydso@alvis1 ~ ] $ ml No modules loaded All good! No modules before that got lost! [ x_birbr@tetralith3 ~ ] $ ml Python/3.11.5-env-hpc1-gcc-2023b-eb [ x_birbr@tetralith3 ~ ] $ ml Currently Loaded Modules: 1 ) hpc/.1.10.1 ( H,S ) 2 ) Python/3.11.5-env-hpc1-gcc-2023b-eb Where: S: Module is Sticky, requires --force to unload or purge H: Hidden Module [ x_birbr@tetralith3 ~ ] $ ml purge The following modules were not unloaded: ( Use \"module --force purge\" to unload all ) : 1 ) hpc/.1.10.1 [ x_birbr@tetralith3 ~ ] $ ml Currently Loaded Modules: 1 ) hpc/.1.10.1 ( H,S ) Where: S: Module is Sticky, requires --force to unload or purge H: Hidden Module All good! Important While at other centres, it is more or less problematic to use module purge : UPPMAX, PDC UPPMAX PDC [ bbrydsoe@rackham1 ~ ] $ ml python/3.11.8 [ bbrydsoe@rackham1 ~ ] $ ml Currently Loaded Modules: 1 ) uppmax 2 ) python/3.11.8 [ bbrydsoe@rackham1 ~ ] $ ml purge [ bbrydsoe@rackham1 ~ ] $ ml No modules loaded Warning! You need to reload \u201cuppmax\u201d module! module load uppmax if you are on Rackham/Bianca. New cluster Pelle has (as of today) no uppmax module bbrydsoe@login1:~> ml Currently Loaded Modules: 1 ) craype-x86-rome 6 ) cce/17.0.0 11 ) PrgEnv-cray/8.5.0 2 ) libfabric/1.20.1 7 ) craype/2.7.30 12 ) snic-env/1.0.0 3 ) craype-network-ofi 8 ) cray-dsmml/0.2.2 13 ) systemdefault/1.0.0 ( S ) 4 ) perftools-base/23.12.0 9 ) cray-mpich/8.1.28 5 ) xpmem/2.8.2-1.0_3.9__g84a27a5.shasta 10 ) cray-libsci/23.12.5 Where: S: Module is Sticky, requires --force to unload or purge bbrydsoe@login1:~> ml cray-python/3.11.5 bbrydsoe@login1:~> ml Currently Loaded Modules: 1 ) craype-x86-rome 6 ) cce/17.0.0 11 ) PrgEnv-cray/8.5.0 2 ) libfabric/1.20.1 7 ) craype/2.7.30 12 ) snic-env/1.0.0 3 ) craype-network-ofi 8 ) cray-dsmml/0.2.2 13 ) systemdefault/1.0.0 ( S ) 4 ) perftools-base/23.12.0 9 ) cray-mpich/8.1.28 14 ) cray-python/3.11.5 5 ) xpmem/2.8.2-1.0_3.9__g84a27a5.shasta 10 ) cray-libsci/23.12.5 Where: S: Module is Sticky, requires --force to unload or purge bbrydsoe@login1:~> ml purge The following modules were not unloaded: ( Use \"module --force purge\" to unload all ) : 1 ) systemdefault/1.0.0 bbrydsoe@login1:~> ml Currently Loaded Modules: 1 ) systemdefault/1.0.0 ( S ) Where: S: Module is Sticky, requires --force to unload or purge WARNING WARNING WARNING !!! Lots of modules got unloaded! Either logout and login again, or make sure you have saved a list of the system-modules so you can reload all of them (or use module collections - which we get to soon. Exercise Check how to load R at your centre. Pick a version. Does it have prerequisites at your centre? Load R for a specific version (but first load prerequisites if there are any). Run module list to see what modules got loaded. Was it more than you expected? Unload R (and prerequisites if there are any). See what happens. Do module list again. module show \u00b6 This command shows commands in the module file (MODULE) and can be used to list information about modules. at centres with a \u201cflat\u201d structure this can be used on all modules since there are no prerequisites: UPPMAX, NSC at centres with a \u201chierarchial\u201d structure this can only be used on the modules that are currently available to load (and can be seen with module avail ): HPC2N, LUNARC, C3SE, PDC Example, HPC2N Let us look at CUDA: b-an01 [ ~ ] $ ml show CUDA/12.6.0 ---------------------------------------------------------------------------------------------------------------------- /hpc2n/eb/modules/all/Core/CUDA/12.6.0.lua: ---------------------------------------------------------------------------------------------------------------------- help ([[ Description =========== CUDA ( formerly Compute Unified Device Architecture ) is a parallel computing platform and programming model created by NVIDIA and implemented by the graphics processing units ( GPUs ) that they produce. CUDA gives developers access to the virtual instruction set and memory of the parallel computational elements in CUDA GPUs. More information ================ - Homepage: https://developer.nvidia.com/cuda-toolkit ]]) whatis ( \"Description: CUDA (formerly Compute Unified Device Architecture) is a parallel computing platform and programming model created by NVIDIA and implemented by the graphics processing units (GPUs) that they produce. CUDA gives developers access to the virtual instruction set and memory of the parallel computational elements in CUDA GPUs.\" ) whatis ( \"Homepage: https://developer.nvidia.com/cuda-toolkit\" ) whatis ( \"URL: https://developer.nvidia.com/cuda-toolkit\" ) conflict ( \"CUDA\" ) prepend_path ( \"CMAKE_PREFIX_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0\" ) prepend_path ( \"CPATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/include\" ) prepend_path ( \"CPATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/extras/CUPTI/include\" ) prepend_path ( \"CPATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/nvvm/include\" ) prepend_path ( \"LD_LIBRARY_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/lib\" ) prepend_path ( \"LD_LIBRARY_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/extras/CUPTI/lib64\" ) prepend_path ( \"LD_LIBRARY_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/nvvm/lib64\" ) prepend_path ( \"LIBRARY_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/lib\" ) prepend_path ( \"LIBRARY_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/extras/CUPTI/lib64\" ) prepend_path ( \"LIBRARY_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/nvvm/lib64\" ) prepend_path ( \"LIBRARY_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/stubs/lib64\" ) prepend_path ( \"PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/bin\" ) prepend_path ( \"PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/nvvm/bin\" ) prepend_path ( \"PKG_CONFIG_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/pkgconfig\" ) prepend_path ( \"XDG_DATA_DIRS\" , \"/hpc2n/eb/software/CUDA/12.6.0/share\" ) setenv ( \"EBROOTCUDA\" , \"/hpc2n/eb/software/CUDA/12.6.0\" ) setenv ( \"EBVERSIONCUDA\" , \"12.6.0\" ) setenv ( \"EBDEVELCUDA\" , \"/hpc2n/eb/software/CUDA/12.6.0/easybuild/Core-CUDA-12.6.0-easybuild-devel\" ) setenv ( \"CUDA_HOME\" , \"/hpc2n/eb/software/CUDA/12.6.0\" ) setenv ( \"CUDA_ROOT\" , \"/hpc2n/eb/software/CUDA/12.6.0\" ) setenv ( \"CUDA_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0\" ) buildenv The most useful usage of module show is with the buildenv module. If you load a \u201ccompiler toolchain\u201d (see next section) and then the \u201cbuildenv\u201d module, you can do module show buildenv to see all the various useful environment variables that can now be accessed for linking with when you are building something. If you want to read more about this, you can check the buildenv - build environment section under \u201cEXTRA\u201d -> \u201cAdvanced module commands\u201d. module help \u00b6 This command prints the list of possible commands and can also be used to get the help message from module(s). at centres with a \u201cflat\u201d structure this can be used on all modules since there are no prerequisites: UPPMAX, NSC at centres with a \u201chierarchial\u201d structure this can only be used on the modules that are currently available to load (and can be seen with module avail ): HPC2N, LUNARC, C3SE, PDC Example, HPC2N Let us look at CUDA: b-an01 [ ~ ] $ module help CUDA/12.6.0 ----------------------------------------- Module Specific Help for \"CUDA/12.6.0\" ----------------------------------------- Description =========== CUDA ( formerly Compute Unified Device Architecture ) is a parallel computing platform and programming model created by NVIDIA and implemented by the graphics processing units ( GPUs ) that they produce. CUDA gives developers access to the virtual instruction set and memory of the parallel computational elements in CUDA GPUs. More information ================ - Homepage: https://developer.nvidia.com/cuda-toolkit module save/restore \u00b6 Module collections are used to load/unload a bunch of modules: module save <collection> and module restore <collection> . This can be useful if you often need to load the same several modules in specific versions, for instance. Creating a module collection \u00b6 Load the modules you need. Save the collection (you can name it as you want, here MYMODULES): module save MYMODULES Example Assuming we need pandas and matplotlib at HPC2N (very similar to LUNARC): Load the modules b-an01 [ ~ ] $ module load GCC/12.3.0 b-an01 [ ~ ] $ module load Python/3.11.3 b-an01 [ ~odule load OpenMPI/4.1.5 b-an01 [ ~ ] $ module load SciPy-bundle/2023.07 b-an01 [ ~ ] $ module load matplotlib/3.7.2 Save to a collection (here, \u201cmypython\u201d) b-an01 [ ~ ] $ module save mypython Saved current collection of modules to: \"mypython\" b-an01 [ ~ ] $ Then, maybe later you find you also need mpi4py so you load it and add it to the collection: b-an01 [ ~ ] $ ml mpi4py/3.1.4 b-an01 [ ~ ] $ module save mypython Saved current collection of modules to: \"mypython\" b-an01 [ ~ ] $ After you have been logged out and in again, or maybe unloaded/purged the modules, you can then restore it again: b-an01 [ ~ ] $ module restore mypython Restoring modules from user ' s mypython b-an01 [ ~ ] $ Warning If you are working on PDC\u2019s cluster Dardel, and are used to the command module purge then this is a good way of restoring the system-modules: Immediately after logging in (before loading or unloading anything) create a collection: module save pdcsystem (name as you want) Then, after you have done module purge , just do module restore pdcsystem and you are back to the correct system setup. Workflow - module collections \u00b6 Create a module collection Work with it Possibly unload all modules and load different ones to work with Then later restore the module collection again and keep working Possibly add more modules and save them to the collection Each time you have logged out and are logging in again, you can easily restore the modules you need Much safer than having it in your .bashrc since that is something easily forgotten about and then when you suddenly need to work with different modules or different versions, maybe months later, you are wondering why it is not working as it should and the reason is that you have auto-loaded things in your .bashrc ! Exercise Try loading some modules create a module collection do module list to see what you have unload the modules check with module list restore the module collection check with module list Hints \u00b6 Note How would you find, for instance, installed Python package modules for a specific Python version? Important At centres with prerequisites, you need to load, say, GCC instead of GCCcore in order to be able to access, for instance, SciPy-bundle!!! You also need to load a compatible OpenMPI in order to be sure to get all available installed Python package modules. Example, HPC2N (Very similar to LUNARC) First load the Python module and prerequisites, and OpenMPI b-an01 [ ~ ] $ module load GCC/12.3.0 b-an01 [ ~ ] $ module load Python/3.11.3 b-an01 [ ~ ] $ module load OpenMPI/4.1.5 Then you can check what Python package modules are installed (scroll down a bit): b-an01 [ ~ ] $ module avail ... ----------------------- This is a list of module extensions \"module --nx avail ...\" to not show. ------------------------ ( E ) fontBitstreamVera ( E ) ADGofTest ( E ) fontLiberation ( E ) AICcmodavg ( E ) fontawesome ( E ) ALDEx2 ( E ) fontquiver ( E ) ALL ( E ) fonttools ( E ) AMAPVox ( E ) forcats ( E ) ANCOMBC ( E ) foreach ( E ) ATACseqQC ( E ) forecast ( E ) AUC ( E ) foreign ( E ) AUCell ( E ) formatR ( E ) Aerial-Gym-Simulator ( E ) formula.tools ( E ) AgiMicroRna ( E ) formulaic ( E ) AlgDesign ( E ) fossil ( E ) Algorithm::Dependency ( E ) fpc ( E ) Algorithm::Diff ( E ) fpp ( E ) Alien::Base ( E ) fracdiff ( E ) Alien::Build::Plugin::Download::GitLab ( E ) fresh ( E ) Alien::Libxml2 ( E ) frozenlist ( E ) AlphaFold ( E ) fs ( E ) AlphaPulldown ( E ) fsc.export ( E ) ... The \u201cmodule extensions\u201d are things that are available as part of a modules. Sometimes several for each module. You can see for instance \u201cforeach\u201d R package is available (the list has everything available, not just Python packages). You can then do module spider foreach to see versions and then module spider foreach/1.5.2 to see where you find that extension. If you keep going further down on the list you got with \u201cmodule avail\u201d then you see that \u201cmpi4py\u201d is available and that \u201cpandas\u201d is available. Let us see how to load these. Doing b-an01 [ ~ ] $ module avail mpi4py tells us it can be loaded directly Doing b-an01 [ ~ ] $ module avail pandas gives some conflicting answer, so we try with module spider pandas and then module spider pandas/version to learn that it is part of SciPy-bundle. We can then load SciPy-bundle directly and get \u201cpandas\u201d available. Note Of course, you can always try doing module spider <software or package> and module avail <software or package> directly to see if you are lucky and get the name it is called. Summary \u00b6 Note We learned about the following commands: load unload purge show help save/restore","title":"Module system commands"},{"location":"commands/#module__system__commands","text":"Objectives Find software module versions Load a module (with potential prerequisites): default (often not recommended!) a specific version of software Unload software modules, including specific versions Unload all software modules with module purge This should never be done at PDC! You can do this at UPPMAX, but load the uppmax module afterwards. List the loaded modules Get some information about a module ( module show and module help ) Learn about module collections to load/unload a bunch of modules ( module save <collection> and module restore <collection> ) In the previous section we saw how to find out which modules are available at a centre, including looking for a specific software module. Now it is time to learn more useful module commands!","title":"Module system commands"},{"location":"commands/#finding__software__versions","text":"If you just load a module without specifying the version, you will (depending on centre) get the default version or an error. There are good reasons not to just load the default version, even when it is possible: The default version is often the newest one installed, which means the default changes the next time an even newer version is installed. This could break your code or at least give a different result, which is bad for resproducibility. Sometimes you actually need a specific version, which could differ from the one the centre has decided on as default. So how do you find out which versions are available for a specific software? Note This is done differently, depending on the center you are at: HPC2N, LUNARC, C3SE, PDC: module spider MODULE or ml spider MODULE UPPMAX, NSC, /C3SE): module avail MODULE or ml avail MODULE","title":"Finding software versions"},{"location":"commands/#with__module__spider","text":"Recommended at HPC2N, LUNARC, C3SE, and PDC. Note The command to find the available versions for a software module named MODULE is: module spider MODULE or, in short form ml spider MODULE","title":"With module spider"},{"location":"commands/#with__module__avail","text":"Recommended at UPPMAX and NSC. Note The command to find the available version for a software module named MODULE is: module avail MODULE or, in short form ml av MODULE","title":"With module avail"},{"location":"commands/#example","text":"Finding available versions of Python. Tip Type along! module spider HPC2N LUNARC C3SE module spider Python Click to show b-an01 [ ~ ] $ module spider Python -------------------------------------------------------------------------------------------------------------------- Python: -------------------------------------------------------------------------------------------------------------------- Description: Python is a programming language that lets you work more quickly and integrate your systems more effectively. Versions: Python/2.7.15 Python/2.7.16 Python/2.7.18-bare Python/2.7.18 Python/3.7.2 Python/3.7.4 Python/3.8.2 Python/3.8.6 Python/3.9.5-bare Python/3.9.5 Python/3.9.6-bare Python/3.9.6 Python/3.10.4-bare Python/3.10.4 Python/3.10.8-bare Python/3.10.8 Python/3.11.3 Python/3.11.5 Python/3.12.3 Other possible modules matches: Biopython Boost.Python Brotli-python GitPython IPython Python-bundle-PyPI bx-python flatbuffers-python ... -------------------------------------------------------------------------------------------------------------------- To find other possible module matches execute: $ module -r spider '.*Python.*' -------------------------------------------------------------------------------------------------------------------- For detailed information about a specific \"Python\" package ( including how to load the modules ) use the module ' s full name. Note that names that have a trailing ( E ) are extensions provided by other modules. For example: $ module spider Python/3.12.3 -------------------------------------------------------------------------------------------------------------------- module spider Python Click to show [ bbrydsoe@cosmos3 ~ ] $ module spider Python ---------------------------------------------------------------------------------------------------------------------------- Python: ---------------------------------------------------------------------------------------------------------------------------- Description: Python is a programming language that lets you work more quickly and integrate your systems more effectively. Versions: Python/2.7.18-bare Python/2.7.18 Python/3.8.6 Python/3.9.5-bare Python/3.9.5 Python/3.9.6-bare Python/3.9.6 Python/3.10.4-bare Python/3.10.4 Python/3.10.8-bare Python/3.10.8 Python/3.11.3 Python/3.11.5 Python/3.12.3 Other possible modules matches: Biopython GitPython IPython Python-bundle Python-bundle-PyPI bx-python flatbuffers-python graphviz-python ... ---------------------------------------------------------------------------------------------------------------------------- To find other possible module matches execute: $ module -r spider '.*Python.*' ---------------------------------------------------------------------------------------------------------------------------- For detailed information about a specific \"Python\" package ( including how to load the modules ) use the module ' s full name. Note that names that have a trailing ( E ) are extensions provided by other modules. For example: $ module spider Python/3.12.3 ---------------------------------------------------------------------------------------------------------------------------- module spider Python Click to show [ brydso@alvis1 ~ ] $ module spider Python ----------------------------------------------------------------------------------------------------------------------------- Python: ----------------------------------------------------------------------------------------------------------------------------- Description: Python is a programming language that lets you work more quickly and integrate your systems more effectively. Versions: Python/2.7.18-GCCcore-11.2.0-bare Python/2.7.18-GCCcore-11.3.0-bare Python/2.7.18-GCCcore-12.2.0-bare Python/3.9.5-GCCcore-10.3.0-bare Python/3.9.5-GCCcore-10.3.0 Python/3.9.6-GCCcore-11.2.0-bare Python/3.9.6-GCCcore-11.2.0 Python/3.10.4-GCCcore-11.3.0-bare Python/3.10.4-GCCcore-11.3.0 Python/3.10.8-GCCcore-12.2.0-bare Python/3.10.8-GCCcore-12.2.0 Python/3.11.3-GCCcore-12.3.0 Python/3.11.5-GCCcore-13.2.0 Python/3.12.3-GCCcore-13.3.0 Other possible modules matches: Biopython Boost.Python CUDA-Python GitPython IPython Python-bundle-PyPI flatbuffers-python meson-python ... ----------------------------------------------------------------------------------------------------------------------------- To find other possible module matches execute: $ module -r spider '.*Python.*' ----------------------------------------------------------------------------------------------------------------------------- For detailed information about a specific \"Python\" package ( including how to load the modules ) use the module ' s full name. Note that names that have a trailing ( E ) are extensions provided by other modules. For example: $ module spider Python/3.12.3-GCCcore-13.3.0 ----------------------------------------------------------------------------------------------------------------------------- module spider, mostly PDC module spider python Click to show - python bbrydsoe@login1:~> ml spider python ----------------------------------------------------------------------------------------------------------------------------- python: ----------------------------------------------------------------------------------------------------------------------------- Versions: python/2.7.6 python/2.7.9 python/2.7.11 python/2.7.15 python/3.3 python/3.3.1 python/3.4.3 python/3.5.0 python/3.6.0 python/3.6.8 python/3.7.2 python/3.8.7 python/3.9.5 python/3.9.6 python/3.10.8 python/3.11.4 python/3.11.6-gcc-oc3 python/3.11.6-gcc-qyw python/3.11.6-gcc-spv python/3.11.8 python/3.11.9-gcc-epm python/3.12.1 python/3.12.3 python/3.13.0-gcc-cgo Other possible modules matches: biopython cray-python dbus-python pdc-python py-meson-python py-python-dateutil python-2.7.18-gcc-11.2.0-namldiz python-3.8.12-gcc-11.2.0-nwj732o python-3.8.12-gcc-11.2.0-vhhulma ... ----------------------------------------------------------------------------------------------------------------------------- To find other possible module matches execute: $ module -r spider '.*python.*' ----------------------------------------------------------------------------------------------------------------------------- For detailed information about a specific \"python\" package ( including how to load the modules ) use the module ' s full name. Note that names that have a trailing ( E ) are extensions provided by other modules. For example: $ module spider python/3.13.0-gcc-cgo ----------------------------------------------------------------------------------------------------------------------------- Click to show - cray-python bbrydsoe@login1:~> module avail cray-python ------------------------------------ /opt/cray/pe/lmod/modulefiles/core ------------------------------------- cray-python/3.10.10 cray-python/3.11.5 ( D ) cray-python/3.11.7 Where: D: Default Module If the avail list is too long consider trying: \"module --default avail\" or \"ml -d av\" to just list the default modules. \"module overview\" or \"ml ov\" to display the number of modules for each name. Use \"module spider\" to find all possible modules and extensions. Use \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\" . module avail UPPMAX NSC C3SE module avail python Click to show [ bbrydsoe@rackham1 ~ ] $ module avail python --------------------------------- /sw/mf/rackham/applications ---------------------------------- python_GIS_packages/3.10.8 python_ML_packages/3.9.5-gpu wrf-python/1.3.1 python_ML_packages/3.9.5-cpu python_ML_packages/3.11.8-cpu ( D ) ----------------------------------- /sw/mf/rackham/compilers ----------------------------------- python/2.7.6 python/3.4.3 python/3.9.5 python3/3.6.0 python3/3.11.4 python/2.7.9 python/3.5.0 python/3.10.8 python3/3.6.8 python3/3.11.8 python/2.7.11 python/3.6.0 python/3.11.4 python3/3.7.2 python3/3.12.1 python/2.7.15 python/3.6.8 python/3.11.8 python3/3.8.7 python3/3.12.7 ( D ) python/3.3 python/3.7.2 python/3.12.1 python3/3.9.5 python/3.3.1 python/3.8.7 python/3.12.7 ( D ) python3/3.10.8 Where: D: Default Module Use \"module spider\" to find all possible modules and extensions. Use \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\" . Ignore the comment about using module spider ! module avail python Click to show [ x_birbr@tetralith3 ~ ] $ module avail python --------------------- /software/sse2/tetralith_el9/modules --------------------- ASE/3.22.1-hpc1-python ASE/3.23.0-hpc1-python GaussSum/3.0.2-Python-3.7.8-hpc1 NCL/6.6.2-hpc2-Python Pylint/3.2.5-hpc1-Python-3.11.5 Python/recommendation ( D ) Python/2.7.18-bare-hpc1-gcc-2022a-eb Python/3.10.4-bare-hpc1-gcc-2022a-eb Python/3.10.4-env-hpc1-gcc-2022a-eb Python/3.10.4-env-hpc2-gcc-2022a-eb Python/3.11.5-bare-hpc1-gcc-2023b-eb Python/3.11.5-env-hpc1-gcc-2023b-eb Where: D: Default Module module avail Python Click to show You will get output that includes what you look for, but also a lot of other output - and only if you use \u201cPython\u201d instead of \u201cpython\u201d [ brydso@alvis1 ~ ] $ module avail Python ------------------------------------------------------------------ /apps/Arch/fmodules/all ------------------------------------------------------------------ Biopython/1.79-foss-2021a Python/2.7.18-GCCcore-12.2.0-bare meson-python/0.18.0-GCCcore-14.2.0 ( D ) Biopython/1.79-foss-2021b Python/3.9.5-GCCcore-10.3.0-bare netcdf4-python/1.6.4-foss-2023a Biopython/1.79-foss-2022a Python/3.9.5-GCCcore-10.3.0 netcdf4-python/1.6.5-foss-2023b Biopython/1.83-foss-2023a ( D ) Python/3.9.6-GCCcore-11.2.0-bare netcdf4-python/1.7.1.post2-foss-2024a ( D ) Boost.Python/1.82.0-GCC-12.3.0 Python/3.9.6-GCCcore-11.2.0 openslide-python/1.1.2-GCCcore-10.3.0 CUDA-Python/12.1.0-gfbf-2023a-CUDA-12.1.1 Python/3.10.4-GCCcore-11.3.0-bare openslide-python/1.1.2-GCCcore-11.2.0 ( D ) CUDA-Python/12.6.2.post1-gfbf-2024a-CUDA-12.6.0 ( D ) Python/3.10.4-GCCcore-11.3.0 pkgconfig/1.5.4-GCCcore-10.3.0-python GitPython/3.1.27-GCCcore-11.3.0 Python/3.10.8-GCCcore-12.2.0-bare pkgconfig/1.5.5-GCCcore-11.2.0-python GitPython/3.1.40-GCCcore-12.3.0 ( D ) Python/3.10.8-GCCcore-12.2.0 pkgconfig/1.5.5-GCCcore-11.3.0-python IPython/7.25.0-GCCcore-10.3.0 Python/3.11.3-GCCcore-12.3.0 pkgconfig/1.5.5-GCCcore-12.2.0-python IPython/7.26.0-GCCcore-11.2.0 Python/3.11.5-GCCcore-13.2.0 pkgconfig/1.5.5-GCCcore-12.3.0-python ( D ) IPython/8.5.0-GCCcore-11.3.0 Python/3.12.3-GCCcore-13.3.0 protobuf-python/3.17.3-GCCcore-10.3.0 IPython/8.14.0-GCCcore-12.2.0 Python/3.13.1-GCCcore-14.2.0 protobuf-python/3.17.3-GCCcore-11.2.0 IPython/8.14.0-GCCcore-12.3.0 Python/3.13.5-GCCcore-14.3.0 ( D ) protobuf-python/3.19.4-GCCcore-11.3.0 IPython/8.17.2-GCCcore-13.2.0 Z3/4.12.2-GCCcore-12.3.0-Python-3.11.3 protobuf-python/4.23.0-GCCcore-12.2.0 IPython/8.28.0-GCCcore-13.3.0 flatbuffers-python/2.0-GCCcore-10.3.0 protobuf-python/4.24.0-GCCcore-12.3.0 IPython/9.3.0-GCCcore-14.2.0 ( D ) flatbuffers-python/2.0-GCCcore-11.2.0 protobuf-python/5.28.0-GCCcore-13.3.0 ( D ) Python-bundle-PyPI/2023.06-GCCcore-12.3.0 flatbuffers-python/2.0-GCCcore-11.3.0 python-mujoco/2.2.2-foss-2022a Python-bundle-PyPI/2023.10-GCCcore-13.2.0 flatbuffers-python/23.1.4-GCCcore-12.2.0 python-mujoco/3.1.4-foss-2023a ( D ) Python-bundle-PyPI/2024.06-GCCcore-13.3.0 flatbuffers-python/23.5.26-GCCcore-12.3.0 ( D ) python-xxhash/3.4.1-GCCcore-12.3.0 Python-bundle-PyPI/2025.04-GCCcore-14.2.0 ( D ) meson-python/0.13.2-GCCcore-12.3.0 spglib-python/1.16.1-foss-2021a Python/2.7.18-GCCcore-11.2.0-bare meson-python/0.15.0-GCCcore-13.2.0 spglib-python/2.0.0-foss-2022a Python/2.7.18-GCCcore-11.3.0-bare meson-python/0.16.0-GCCcore-13.3.0 spglib-python/2.1.0-gfbf-2023a ( D ) ... Exercise At your chosen centre, check the different output for module avail Python and module spider Python Do you get the same output for \u201cPython\u201d and \u201cpython\u201d?","title":"Example"},{"location":"commands/#list__loaded__modules","text":"There is a very useful command to list which modules you have loaded. It is module list or, in short form ml Tip Try it now! With nothing loaded, only the \u201csticky\u201d modules are listed. They are modules that are needed for the environment to function correctly, so do not remove them!","title":"List loaded modules"},{"location":"commands/#load__software__module","text":"In order to load modules, we need to know how . This differs by center only inasmuch as some centers have prerequisites (usually compiler toolchains ) for most of the software modules. The centers that recommend module spider for finding the software modules generally have prerequisites (HPC2N, LUNARC, PDC - and sometimes C3SE), while those who recommend module avail generally do not (UPPMAX, NSC). Thus; if the centers suggests you do module spider you will need to check the required prerequisites to load.","title":"Load software module"},{"location":"commands/#prerequisites","text":"This is done with module spider <module>/<version> You can also do this at the centers recommending module avail , but that will generally just tell you the module can be loaded directly. Prerequisites At some centres it is common that modules have prerequisites (usually GCC, various libraries or something similar) while at other centres most modules can be loaded directly. HPC2N : most software modules have prerequisites (GCC/Intel, OpenMPI, \u2026), a few do not (MATLAB, \u2026) LUNARC : most software modules have prerequisites (GCC/Intel, OpenMPI, \u2026), a few do not (MATLAB, \u2026) UPPMAX : software modules can generally be loaded directly unless its is related to bioinformatics (then load bioinfo-tools first). New cluster Pelle does not require you to load bioinfo-tools !!! note - **On Pelle things are more like NSC, you may follow the examples for that cluster instead of Rackham** - Though, note that outputdetails will most probably be different on Pelle! NSC : software modules can generally be loaded directly PDC : most software modules have prerequisites (PDC which is a collection of compilers and libraries), a few do not (MATLAB, cray-modules, \u2026) C3SE : software modules can generally be loaded directly HPC2N UPPMAX NSC Example, finding out how to load Python, version 3.12.3 b-an01 [ ~ ] $ module spider Python/3.12.3 -------------------------------------------------------------------------------------------------------------------- Python: Python/3.12.3 -------------------------------------------------------------------------------------------------------------------- Description: Python is a programming language that lets you work more quickly and integrate your systems more effectively. You will need to load all module ( s ) on any one of the lines below before the \"Python/3.12.3\" module is available to load. GCCcore/13.3.0 This module provides the following extensions: flit_core/3.9.0 ( E ) , packaging/24.0 ( E ) , pip/24.0 ( E ) , setuptools/70.0.0 ( E ) , setuptools_scm/8.1.0 ( E ) , tomli/2.0.1 ( E ) , typing_extensions/4.11.0 ( E ) , wheel/0.43.0 ( E ) Help: Description =========== Python is a programming language that lets you work more quickly and integrate your systems more effectively. More information ================ - Homepage: https://python.org/ Included extensions =================== flit_core-3.9.0, packaging-24.0, pip-24.0, setuptools-70.0.0, setuptools_scm-8.1.0, tomli-2.0.1, typing_extensions-4.11.0, wheel-0.43.0 There are some things to pay attention to here: You are told the prerequisites are \u201cGCCcore/13.3.0\u201d (if you need OpenMPI or modules requiring it, it is better to load \u201cGCC/13.3.0\u201d as GCCcore is part of it) After loading that, you can load the module itself, \u201cPython/3.12.3\u201d You are told about the extensions that are included. Here, this would be the Python packages that are included, which is not very many. HPC2N and some of the other centres use separate modules or module bundles (SciPy-bundle for instance) for any extensions/packages that you might need. Example, Finding out how to load Python, version 3.11.8 (Rackham) On Pelle things are more like NSC, have a look there! [ bbrydsoe@rackham1 ~ ] $ ml avail python/3.11.8 ----------------------------------- /sw/mf/rackham/compilers ----------------------------------- python/3.11.8 Use \"module spider\" to find all possible modules and extensions. Use \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\" . This did not tell us much! Let us try module spider [ bbrydsoe@rackham1 ~ ] $ module spider python/3.11.8 -------------------------------------------------------------------------------------------- python: python/3.11.8 -------------------------------------------------------------------------------------------- This module can be loaded directly: module load python/3.11.8 Help: Python - use python/3.11.8 Version 3 .11.8 https://python.org This module was built with gcc/12.3.0 sqlite/3.34.0 Tcl-Tk/8.6.11 This module provides the executable names 'python' and 'python3' . Several additional python packages are also installed in this module. The complete list of packages in this module, produced using 'pip list' , is: Package Version ------------------------- --------------- anndata 0 .10.5.post1 anyio 4 .2.0 argon2-cffi 23 .1.0 argon2-cffi-bindings 21 .2.0 array_api_compat 1 .4.1 arrow 1 .3.0 asteval 0 .9.31 asttokens 2 .4.1 async-lru 2 .0.4 ... Here we learn: You can load \u201cpython/3.11.8\u201d directly It was built with \u201cgcc/12.3.0 sqlite/3.34.0 Tcl-Tk/8.6.11\u201d (might be useful for compatibility with other things). It lists all the extensions (here Python packages) loaded with it - and it is a lot, around 250 packages. Example, finding out how to load Python, version 3.11.5 [ x_birbr@tetralith3 ~ ] $ module avail Python/3.11.5 ------------------------------------------ /software/sse2/tetralith_el9/modules ------------------------------------------- Python/3.11.5-bare-hpc1-gcc-2023b-eb Python/3.11.5-env-hpc1-gcc-2023b-eb This was not so helpful. Let us try with \u201cmodule spider\u201d: [ x_birbr@tetralith3 ~ ] $ module spider Python/3.11.5 #################################################################################################################################### # NOTE: At NSC the output of 'module spider' is generally not helpful as all relevant software modules are shown by 'module avail' # # Some HPC centers hide software until the necessary dependencies have been loaded. NSC does not do that. # #################################################################################################################################### ----------------------------------------------------------------------------------------------------------------------- Python: Python/3.11.5 ----------------------------------------------------------------------------------------------------------------------- Description: Python is a programming language that lets you work more quickly and integrate your systems more effectively. You will need to load all module ( s ) on any one of the lines below before the \"Python/3.11.5\" module is available to load. buildtool-easybuild/.5.1.1-hpce5ba34320 GCCcore/13.2.0 buildtool-easybuild/4.8.0-hpce082752a2 GCCcore/13.2.0 buildtool-easybuild/4.9.4-hpc71cbb0050 GCCcore/13.2.0 Help: Description =========== Python is a programming language that lets you work more quickly and integrate your systems more effectively. More information ================ - Homepage: https://python.org/ Included extensions =================== flit_core-3.9.0, packaging-23.2, pip-23.2.1, setuptools-68.2.2, setuptools-scm-8.0.4, tomli-2.0.1, typing_extensions-4.8.0, wheel-0.41.2 Here we learn that there is a \u201cbare\u201d Python (like \u201cPython/3.11.5-bare-hpc1-gcc-2023b-eb\u201d) that you can load directly Otherwise, you need to load the prerequisites of a buildtool and a GCCcore first, before loading Python. That is knowledge that can be useful for finding compatibility with other software modules You also learn that there is a (small) number of extensions/packages with this Python","title":"Prerequisites"},{"location":"commands/#loading","text":"To load a software module, do: (if needed) module load <prerequisite>/<suitable version> module load <module>/<compatible version> and the versions you got from module spider . Again, ml load <module>/<version> can be used as a short form. When you have loaded the module, you can see that your list of loaded modules has changed. This is done with module list or ml . Hint Type along! Example, HPC2N Loading Python 3.12.3 and prerequisites, and checking before and after which modules are loaded. module list Click to show output! b-an01 [ ~ ] $ module list Currently Loaded Modules: 1 ) snicenvironment ( S ) 2 ) systemdefault ( S ) Where: S: Module is Sticky, requires --force to unload or purge module load GCCcore/13.3.0 Python/3.12.3 or load them on separate lines module load GCCcore/13.3.0 module load Python/3.12.3 What is the advantage to loading them one at a time? You can then easier find compatible modules that depend on that version, using module avail . Click to show output! b-an01 [ ~ ] $ module load GCCcore/13.3.0 Python/3.12.3 b-an01 [ ~ ] $ And now do module list again! Click to show output! b-an01 [ ~ ] $ module list Currently Loaded Modules: 1 ) snicenvironment ( S ) 4 ) zlib/1.3.1 7 ) ncurses/6.5 10 ) SQLite/3.45.3 13 ) OpenSSL/3 2 ) systemdefault ( S ) 5 ) binutils/2.42 8 ) libreadline/8.2 11 ) XZ/5.4.5 14 ) Python/3.12.3 3 ) GCCcore/13.3.0 6 ) bzip2/1.0.8 9 ) Tcl/8.6.14 12 ) libffi/3.4.5 Where: S: Module is Sticky, requires --force to unload or purge Example, NSC Loading Python version 3.11.5 (the module is called Python/3.11.5-env-hpc1-gcc-2023b-eb and can be loaded directly). Also do module list before and after! module list Click to show output! [ x_birbr@tetralith3 ~ ] $ module list Currently Loaded Modules: 1 ) hpc/.1.10.1 ( H,S ) Where: S: Module is Sticky, requires --force to unload or purge H: Hidden Module module load Python/3.11.5-env-hpc1-gcc-2023b-eb Click to show output! [ x_birbr@tetralith3 ~ ] $ module load Python/3.11.5-env-hpc1-gcc-2023b-eb [ x_birbr@tetralith3 ~ ] $ ml Click to show output! [ x_birbr@tetralith3 ~ ] $ ml Currently Loaded Modules: 1 ) hpc/.1.10.1 ( H,S ) 2 ) Python/3.11.5-env-hpc1-gcc-2023b-eb Where: S: Module is Sticky, requires --force to unload or purge H: Hidden Module Or load one of the Python modules with prerequisites: Click to show output! [ x_birbr@tetralith3 ~ ] $ ml buildtool-easybuild/4.8.0-hpce082752a2 GCCcore/13.2.0 Python/3.11.5 [ x_birbr@tetralith3 ~ ] $ Let us see the output of \u201cmodule list\u201d now: [ x_birbr@tetralith3 ~ ] $ module list Currently Loaded Modules: 1 ) hpc/.1.10.1 ( H,S ) 5 ) binutils/.2.40 ( H ) 9 ) Tcl/8.6.13 13 ) OpenSSL/1.1 2 ) buildtool-easybuild/4.8.0-hpce082752a2 6 ) bzip2/1.0.8 10 ) SQLite/3.43.1 14 ) Python/3.11.5 3 ) GCCcore/13.2.0 7 ) ncurses/6.4 11 ) XZ/5.4.4 4 ) zlib/.1.2.13 ( H ) 8 ) libreadline/8.2 12 ) libffi/3.4.4 Where: S: Module is Sticky, requires --force to unload or purge H: Hidden Module Important You can do several module load on the same line. Or you can do them one at a time, as you want. The modules have to be loaded in order! You cannot list the prerequisite after the module that needs it! One advantage to loading modules one at a time is that you can then find compatible modules that depend on that version easily. Example: you have loaded GCC/13.2.0 and Python/3.11.5 at HPC2N or LUNARC. You can now do ml av or module avail to see which versions of other modules you want to load, say SciPy-bundle , are compatible. If you know the name of the module you want, you can even start writing module load SciPy-bundle/ (for instance) and press TAB - the system will then autocomplete to the compatible one(s).","title":"Loading"},{"location":"commands/#loading__several__modules","text":"There are situations where you need to load several modules, even at centres where there are no prerequisites. Example You need some Python packages not included in the base Python you loaded, for instance TensorFlow or maybe AlphaFold. You now need to load a version of that module which is compatible with the Python you want. HPC2N UPPMAX NSC Tensorflow needs Python and SciPy-bundle. SciPy-bundle also needs OpenMPI. TensorFlow loads Python and SciPy-bundle itself, but you need their prerequisites: b-an01 [ ~ ] $ module spider TensorFlow/2.15.1-CUDA-12.1.1 -------------------------------------------------------------------------------------------------------------------- TensorFlow: TensorFlow/2.15.1-CUDA-12.1.1 -------------------------------------------------------------------------------------------------------------------- Description: An open-source software library for Machine Intelligence You will need to load all module ( s ) on any one of the lines below before the \"TensorFlow/2.15.1-CUDA-12.1.1\" module is available to load. GCC/12.3.0 OpenMPI/4.1.5 This module provides the following extensions: absl-py/2.1.0 ( E ) , astor/0.8.1 ( E ) , astunparse/1.6.3 ( E ) , cachetools/5.3.3 ( E ) , google-auth-oauthlib/1.2.0 ( E ) , google-auth/2.29.0 ( E ) , google-pasta/0.2.0 ( E ) , gviz-api/1.10.0 ( E ) , keras/2.15.0 ( E ) , Markdown/3.6 ( E ) , oauthlib/3.2.2 ( E ) , pyasn1-modules/0.4.0 ( E ) , requests-oauthlib/2.0.0 ( E ) , rsa/4.9 ( E ) , tblib/3.0.0 ( E ) , tensorboard-data-server/0.7.2 ( E ) , tensorboard-plugin-profile/2.15.1 ( E ) , tensorboard/2.15.2 ( E ) , tensorflow-estimator/2.15.0 ( E ) , TensorFlow/2.15.1 ( E ) , termcolor/2.3.0 ( E ) , Werkzeug/3.0.2 ( E ) , wrapt/1.14.1 ( E ) b-an01 [ ~ ] $ module load GCC/12.3.0 OpenMPI/4.1.5 b-an01 [ ~ ] $ module load TensorFlow/2.15.1-CUDA-12.1.1 TensorFlow is included in the Python_ML_packages. Python gets loaded with the Python_ML_packages so nothing extra needs loading here [ bbrydsoe@rackham1 ~ ] $ ml spider python_ML_packages/3.11.8-cpu -------------------------------------------------------------------------------------------- python_ML_packages: python_ML_packages/3.11.8-cpu -------------------------------------------------------------------------------------------- This module can be loaded directly: module load python_ML_packages/3.11.8-cpu Help: python_ML_packages version 3 .11.8-cpu [ bbrydsoe@rackham1 ~ ] $ ml python_ML_packages/3.11.8-cpu [ bbrydsoe@rackham1 ~ ] $ However, if you for instance need Matlab together with Gurobi, then you need to load both modules: [ bbrydsoe@rackham1 ~ ] $ ml spider matlab/R2023b [ bbrydsoe@rackham1 ~ ] $ ml Gurobi/11.0.3 TensorFlow is not installed, so if you need that you would have to install it yourself in a Virtual environment. Let us assume we need \u201cpandas\u201d which is installed. It is included in SciPy-bundle, which pulls in Python and OpenMPI, but does have other prerequisites [ x_birbr@tetralith3 ~ ] $ ml spider SciPy-bundle/2023.11 #################################################################################################################################### # NOTE: At NSC the output of 'module spider' is generally not helpful as all relevant software modules are shown by 'module avail' # # Some HPC centers hide software until the necessary dependencies have been loaded. NSC does not do that. # #################################################################################################################################### ----------------------------------------------------------------------------------------------------------------------- SciPy-bundle: SciPy-bundle/2023.11 ----------------------------------------------------------------------------------------------------------------------- Description: Bundle of Python packages for scientific software You will need to load all module ( s ) on any one of the lines below before the \"SciPy-bundle/2023.11\" module is available to load. buildtool-easybuild/.5.1.1-hpce5ba34320 GCC/13.2.0 buildtool-easybuild/4.8.0-hpce082752a2 GCC/13.2.0 buildtool-easybuild/4.9.4-hpc71cbb0050 GCC/13.2.0 Help: Description =========== Bundle of Python packages for scientific software More information ================ - Homepage: https://python.org/ Included extensions =================== beniget-0.4.1, Bottleneck-1.3.7, deap-1.4.1, gast-0.5.4, mpmath-1.3.0, numexpr-2.8.7, numpy-1.26.2, pandas-2.1.3, ply-3.11, pythran-0.14.0, scipy-1.11.4, tzdata-2023.3, versioneer-0.29 [ x_birbr@tetralith3 ~ ] $ ml buildtool-easybuild/4.8.0-hpce082752a2 GCC/13.2.0 SciPy-bundle/2023.11 Another useful \u201csuper\u201d package at NSC is \u201cPython-bundle-PyPI/2023.10\u201d.","title":"Loading several modules"},{"location":"commands/#unload__software__modules","text":"Aside from module unload this section will also cover module purge ! Note Why would you want to unload a module? If you want to use a different version of a module, you need to unload the current one first If you need a different version of a dependent module, but it is not compatible with the current prerequisite you have loaded Modules can be unloaded with: module unload <MODULE> may or may not work module unload <MODULE>/<version> ml unload <MODULE>/<version> short form of the above module -<MODULE>/<version> ml -<MODULE>/<version> short form of the above ml -<MODULE>/<version> short form of the above Unloading a module will not unload the prerequisites . This is not usually a problem at the centres where there rarely are prerequisites (UPPMAX, NSC), but can be annoying at centres who usually have prerequisites for the modules (HPC2N, LUNARC, C3SE, PDC). However, there the easy solution is module purge (HPC2N, LUNARC, C3SE). The command module purge removes all the loaded modules, except the \u201csticky\u201d modules. It is recommended at HPC2N, LUNARC, and C3SE. Warning Do not use module purge at PDC! At PDC, there are a lot of necessary, \u201csystem-modules\u201d that are preloaded. When you do module purge they will also be unloaded and things may not work as it should! At UPPMAX (Rackham and Bianca, not Pelle), the system-module \u201cuppmax\u201d will get unloaded with module purge , but can easily be reloaded with module load uppmax . To see what the uppmax module does, do: ml show uppmax . It sets some environment variables and aliases.","title":"Unload software modules"},{"location":"commands/#unloading__examples","text":"","title":"Unloading examples"},{"location":"commands/#no__prerequisites","text":"Unloading one module, with no prerequisites (for clarity, we also do module list before and after to show what is happening. Tip Type along! First load a suitable module for your center (with no prerequisites). Suggestions: HPC2N, LUNARC: GCC/12.3.0 UPPMAX: python/3.11.8 C3SE: Python/3.12.3-GCCcore-13.3.0 NSC: Python/3.11.5-env-hpc1-gcc-2023b-eb PDC: cray-python/3.11.5 HPC2N Check which modules are loaded (after loading GCC/12.3.0 earlier) b-an01 [ ~ ] $ module list Currently Loaded Modules: 1 ) snicenvironment ( S ) 3 ) GCCcore/12.3.0 5 ) binutils/2.40 2 ) systemdefault ( S ) 4 ) zlib/1.2.13 6 ) GCC/12.3.0 Where: S: Module is Sticky, requires --force to unload or purge b-an01 [ ~ ] $ Unload GCC/12.3.0 b-an01 [ ~ ] $ module unload GCC/12.3.0 b-an01 [ ~ ] $ Check which modules are loaded b-an01 [ ~ ] $ module list Currently Loaded Modules: 1 ) snicenvironment ( S ) 2 ) systemdefault ( S ) Where: S: Module is Sticky, requires --force to unload or purge NSC Check which modules are loaded (after loading Python/3.11.5-env-hpc1-gcc-2023b-eb earlier) [ x_birbr@tetralith3 ~ ] $ module list Currently Loaded Modules: 1 ) hpc/.1.10.1 ( H,S ) 2 ) Python/3.11.5-env-hpc1-gcc-2023b-eb Where: S: Module is Sticky, requires --force to unload or purge H: Hidden Module Unload Python/3.11.5-env-hpc1-gcc-2023b-eb [ x_birbr@tetralith3 ~ ] $ ml -Python/3.11.5-env-hpc1-gcc-2023b-eb [ x_birbr@tetralith3 ~ ] $ Check which modules are loaded [ x_birbr@tetralith3 ~ ] $ ml Currently Loaded Modules: 1 ) hpc/.1.10.1 ( H,S ) Where: S: Module is Sticky, requires --force to unload or purge H: Hidden Module","title":"No prerequisites"},{"location":"commands/#prerequisites_1","text":"Here we look at what happens when you unload something that has a prerequisite. Example, HPC2N LUNARC would be the same. Loading Python and prerequisites b-an01 [ ~ ] $ module load GCC/12.3.0 b-an01 [ ~ ] $ module load Python/3.11.3 Check loaded modules b-an01 [ ~ ] $ ml Currently Loaded Modules: 1 ) snicenvironment ( S ) 4 ) zlib/1.2.13 7 ) bzip2/1.0.8 10 ) Tcl/8.6.13 13 ) libffi/3.4.4 2 ) systemdefault ( S ) 5 ) binutils/2.40 8 ) ncurses/6.4 11 ) SQLite/3.42.0 14 ) OpenSSL/1.1 3 ) GCCcore/12.3.0 6 ) GCC/12.3.0 9 ) libreadline/8.2 12 ) XZ/5.4.2 15 ) Python/3.11.3 Where: S: Module is Sticky, requires --force to unload or purge Unload Python/3.11.3 b-an01 [ ~ ] $ ml unload Python/3.11.3 Check loaded modules b-an01 [ ~ ] $ ml Currently Loaded Modules: 1 ) snicenvironment ( S ) 3 ) GCCcore/12.3.0 5 ) binutils/2.40 2 ) systemdefault ( S ) 4 ) zlib/1.2.13 6 ) GCC/12.3.0 Where: S: Module is Sticky, requires --force to unload or purge Unload GCC/12.3.0 b-an01 [ ~ ] $ ml -GCC/12.3.0 Check loaded modules b-an01 [ ~ ] $ ml Currently Loaded Modules: 1 ) snicenvironment ( S ) 2 ) systemdefault ( S ) Where: S: Module is Sticky, requires --force to unload or purge What happens if you try and unload the prerequisite? Example, HPC2N b-an01 [ ~ ] $ ml GCC/12.3.0 Python/3.11.3 b-an01 [ ~ ] $ ml Currently Loaded Modules: 1 ) snicenvironment ( S ) 4 ) zlib/1.2.13 7 ) bzip2/1.0.8 10 ) Tcl/8.6.13 13 ) libffi/3.4.4 2 ) systemdefault ( S ) 5 ) binutils/2.40 8 ) ncurses/6.4 11 ) SQLite/3.42.0 14 ) OpenSSL/1.1 3 ) GCCcore/12.3.0 6 ) GCC/12.3.0 9 ) libreadline/8.2 12 ) XZ/5.4.2 15 ) Python/3.11.3 Where: S: Module is Sticky, requires --force to unload or purge b-an01 [ ~ ] $ ml -GCC/12.3.0 Inactive Modules: 1 ) OpenSSL/1.1 3 ) SQLite/3.42.0 5 ) XZ/5.4.2 7 ) libffi/3.4.4 2 ) Python/3.11.3 4 ) Tcl/8.6.13 6 ) bzip2/1.0.8 8 ) libreadline/8.2 Due to MODULEPATH changes, the following have been reloaded: 1 ) binutils/2.40 2 ) ncurses/6.4 3 ) zlib/1.2.13","title":"Prerequisites"},{"location":"commands/#module__purge","text":"What about module purge ? Important At some centres, module purge is recommended and at some it is at least safe: HPC2N, LUNARC, NSC, C3SE HPC2N LUNARC C3SE NSC b-an01 [ ~ ] $ ml GCC/12.3.0 Python/3.11.3 b-an01 [ ~ ] $ ml Currently Loaded Modules: 1 ) snicenvironment ( S ) 4 ) zlib/1.2.13 7 ) bzip2/1.0.8 10 ) Tcl/8.6.13 13 ) libffi/3.4.4 2 ) systemdefault ( S ) 5 ) binutils/2.40 8 ) ncurses/6.4 11 ) SQLite/3.42.0 14 ) OpenSSL/1.1 3 ) GCCcore/12.3.0 6 ) GCC/12.3.0 9 ) libreadline/8.2 12 ) XZ/5.4.2 15 ) Python/3.11.3 Where: S: Module is Sticky, requires --force to unload or purge b-an01 [ ~ ] $ ml purge The following modules were not unloaded: ( Use \"module --force purge\" to unload all ) : 1 ) snicenvironment 2 ) systemdefault b-an01 [ ~ ] $ ml Currently Loaded Modules: 1 ) snicenvironment ( S ) 2 ) systemdefault ( S ) Where: S: Module is Sticky, requires --force to unload or purge All good! [ bbrydsoe@cosmos3 ~ ] $ ml GCC/12.3.0 Python/3.11.3 [ bbrydsoe@cosmos3 ~ ] $ ml Currently Loaded Modules: 1 ) SoftwareTree/Milan ( S ) 4 ) binutils/2.40 7 ) ncurses/6.4 10 ) SQLite/3.42.0 13 ) OpenSSL/1.1 2 ) GCCcore/12.3.0 5 ) GCC/12.3.0 8 ) libreadline/8.2 11 ) XZ/5.4.2 14 ) Python/3.11.3 3 ) zlib/1.2.13 6 ) bzip2/1.0.8 9 ) Tcl/8.6.13 12 ) libffi/3.4.4 Where: S: Module is Sticky, requires --force to unload or purge [ bbrydsoe@cosmos3 ~ ] $ ml purge The following modules were not unloaded: ( Use \"module --force purge\" to unload all ) : 1 ) SoftwareTree/Milan [ bbrydsoe@cosmos3 ~ ] $ ml Currently Loaded Modules: 1 ) SoftwareTree/Milan ( S ) Where: S: Module is Sticky, requires --force to unload or purge All good! [ brydso@alvis1 ~ ] $ ml No modules loaded [ brydso@alvis1 ~ ] $ ml Python/3.12.3-GCCcore-13.3.0 [ brydso@alvis1 ~ ] $ ml Currently Loaded Modules: 1 ) GCCcore/13.3.0 5 ) ncurses/6.5-GCCcore-13.3.0 9 ) XZ/5.4.5-GCCcore-13.3.0 2 ) zlib/1.3.1-GCCcore-13.3.0 6 ) libreadline/8.2-GCCcore-13.3.0 10 ) libffi/3.4.5-GCCcore-13.3.0 3 ) binutils/2.42-GCCcore-13.3.0 7 ) Tcl/8.6.14-GCCcore-13.3.0 11 ) OpenSSL/3 4 ) bzip2/1.0.8-GCCcore-13.3.0 8 ) SQLite/3.45.3-GCCcore-13.3.0 12 ) Python/3.12.3-GCCcore-13.3.0 [ brydso@alvis1 ~ ] $ ml purge [ brydso@alvis1 ~ ] $ ml No modules loaded All good! No modules before that got lost! [ x_birbr@tetralith3 ~ ] $ ml Python/3.11.5-env-hpc1-gcc-2023b-eb [ x_birbr@tetralith3 ~ ] $ ml Currently Loaded Modules: 1 ) hpc/.1.10.1 ( H,S ) 2 ) Python/3.11.5-env-hpc1-gcc-2023b-eb Where: S: Module is Sticky, requires --force to unload or purge H: Hidden Module [ x_birbr@tetralith3 ~ ] $ ml purge The following modules were not unloaded: ( Use \"module --force purge\" to unload all ) : 1 ) hpc/.1.10.1 [ x_birbr@tetralith3 ~ ] $ ml Currently Loaded Modules: 1 ) hpc/.1.10.1 ( H,S ) Where: S: Module is Sticky, requires --force to unload or purge H: Hidden Module All good! Important While at other centres, it is more or less problematic to use module purge : UPPMAX, PDC UPPMAX PDC [ bbrydsoe@rackham1 ~ ] $ ml python/3.11.8 [ bbrydsoe@rackham1 ~ ] $ ml Currently Loaded Modules: 1 ) uppmax 2 ) python/3.11.8 [ bbrydsoe@rackham1 ~ ] $ ml purge [ bbrydsoe@rackham1 ~ ] $ ml No modules loaded Warning! You need to reload \u201cuppmax\u201d module! module load uppmax if you are on Rackham/Bianca. New cluster Pelle has (as of today) no uppmax module bbrydsoe@login1:~> ml Currently Loaded Modules: 1 ) craype-x86-rome 6 ) cce/17.0.0 11 ) PrgEnv-cray/8.5.0 2 ) libfabric/1.20.1 7 ) craype/2.7.30 12 ) snic-env/1.0.0 3 ) craype-network-ofi 8 ) cray-dsmml/0.2.2 13 ) systemdefault/1.0.0 ( S ) 4 ) perftools-base/23.12.0 9 ) cray-mpich/8.1.28 5 ) xpmem/2.8.2-1.0_3.9__g84a27a5.shasta 10 ) cray-libsci/23.12.5 Where: S: Module is Sticky, requires --force to unload or purge bbrydsoe@login1:~> ml cray-python/3.11.5 bbrydsoe@login1:~> ml Currently Loaded Modules: 1 ) craype-x86-rome 6 ) cce/17.0.0 11 ) PrgEnv-cray/8.5.0 2 ) libfabric/1.20.1 7 ) craype/2.7.30 12 ) snic-env/1.0.0 3 ) craype-network-ofi 8 ) cray-dsmml/0.2.2 13 ) systemdefault/1.0.0 ( S ) 4 ) perftools-base/23.12.0 9 ) cray-mpich/8.1.28 14 ) cray-python/3.11.5 5 ) xpmem/2.8.2-1.0_3.9__g84a27a5.shasta 10 ) cray-libsci/23.12.5 Where: S: Module is Sticky, requires --force to unload or purge bbrydsoe@login1:~> ml purge The following modules were not unloaded: ( Use \"module --force purge\" to unload all ) : 1 ) systemdefault/1.0.0 bbrydsoe@login1:~> ml Currently Loaded Modules: 1 ) systemdefault/1.0.0 ( S ) Where: S: Module is Sticky, requires --force to unload or purge WARNING WARNING WARNING !!! Lots of modules got unloaded! Either logout and login again, or make sure you have saved a list of the system-modules so you can reload all of them (or use module collections - which we get to soon. Exercise Check how to load R at your centre. Pick a version. Does it have prerequisites at your centre? Load R for a specific version (but first load prerequisites if there are any). Run module list to see what modules got loaded. Was it more than you expected? Unload R (and prerequisites if there are any). See what happens. Do module list again.","title":"module purge"},{"location":"commands/#module__show","text":"This command shows commands in the module file (MODULE) and can be used to list information about modules. at centres with a \u201cflat\u201d structure this can be used on all modules since there are no prerequisites: UPPMAX, NSC at centres with a \u201chierarchial\u201d structure this can only be used on the modules that are currently available to load (and can be seen with module avail ): HPC2N, LUNARC, C3SE, PDC Example, HPC2N Let us look at CUDA: b-an01 [ ~ ] $ ml show CUDA/12.6.0 ---------------------------------------------------------------------------------------------------------------------- /hpc2n/eb/modules/all/Core/CUDA/12.6.0.lua: ---------------------------------------------------------------------------------------------------------------------- help ([[ Description =========== CUDA ( formerly Compute Unified Device Architecture ) is a parallel computing platform and programming model created by NVIDIA and implemented by the graphics processing units ( GPUs ) that they produce. CUDA gives developers access to the virtual instruction set and memory of the parallel computational elements in CUDA GPUs. More information ================ - Homepage: https://developer.nvidia.com/cuda-toolkit ]]) whatis ( \"Description: CUDA (formerly Compute Unified Device Architecture) is a parallel computing platform and programming model created by NVIDIA and implemented by the graphics processing units (GPUs) that they produce. CUDA gives developers access to the virtual instruction set and memory of the parallel computational elements in CUDA GPUs.\" ) whatis ( \"Homepage: https://developer.nvidia.com/cuda-toolkit\" ) whatis ( \"URL: https://developer.nvidia.com/cuda-toolkit\" ) conflict ( \"CUDA\" ) prepend_path ( \"CMAKE_PREFIX_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0\" ) prepend_path ( \"CPATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/include\" ) prepend_path ( \"CPATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/extras/CUPTI/include\" ) prepend_path ( \"CPATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/nvvm/include\" ) prepend_path ( \"LD_LIBRARY_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/lib\" ) prepend_path ( \"LD_LIBRARY_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/extras/CUPTI/lib64\" ) prepend_path ( \"LD_LIBRARY_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/nvvm/lib64\" ) prepend_path ( \"LIBRARY_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/lib\" ) prepend_path ( \"LIBRARY_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/extras/CUPTI/lib64\" ) prepend_path ( \"LIBRARY_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/nvvm/lib64\" ) prepend_path ( \"LIBRARY_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/stubs/lib64\" ) prepend_path ( \"PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/bin\" ) prepend_path ( \"PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/nvvm/bin\" ) prepend_path ( \"PKG_CONFIG_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0/pkgconfig\" ) prepend_path ( \"XDG_DATA_DIRS\" , \"/hpc2n/eb/software/CUDA/12.6.0/share\" ) setenv ( \"EBROOTCUDA\" , \"/hpc2n/eb/software/CUDA/12.6.0\" ) setenv ( \"EBVERSIONCUDA\" , \"12.6.0\" ) setenv ( \"EBDEVELCUDA\" , \"/hpc2n/eb/software/CUDA/12.6.0/easybuild/Core-CUDA-12.6.0-easybuild-devel\" ) setenv ( \"CUDA_HOME\" , \"/hpc2n/eb/software/CUDA/12.6.0\" ) setenv ( \"CUDA_ROOT\" , \"/hpc2n/eb/software/CUDA/12.6.0\" ) setenv ( \"CUDA_PATH\" , \"/hpc2n/eb/software/CUDA/12.6.0\" ) buildenv The most useful usage of module show is with the buildenv module. If you load a \u201ccompiler toolchain\u201d (see next section) and then the \u201cbuildenv\u201d module, you can do module show buildenv to see all the various useful environment variables that can now be accessed for linking with when you are building something. If you want to read more about this, you can check the buildenv - build environment section under \u201cEXTRA\u201d -> \u201cAdvanced module commands\u201d.","title":"module show"},{"location":"commands/#module__help","text":"This command prints the list of possible commands and can also be used to get the help message from module(s). at centres with a \u201cflat\u201d structure this can be used on all modules since there are no prerequisites: UPPMAX, NSC at centres with a \u201chierarchial\u201d structure this can only be used on the modules that are currently available to load (and can be seen with module avail ): HPC2N, LUNARC, C3SE, PDC Example, HPC2N Let us look at CUDA: b-an01 [ ~ ] $ module help CUDA/12.6.0 ----------------------------------------- Module Specific Help for \"CUDA/12.6.0\" ----------------------------------------- Description =========== CUDA ( formerly Compute Unified Device Architecture ) is a parallel computing platform and programming model created by NVIDIA and implemented by the graphics processing units ( GPUs ) that they produce. CUDA gives developers access to the virtual instruction set and memory of the parallel computational elements in CUDA GPUs. More information ================ - Homepage: https://developer.nvidia.com/cuda-toolkit","title":"module help"},{"location":"commands/#module__saverestore","text":"Module collections are used to load/unload a bunch of modules: module save <collection> and module restore <collection> . This can be useful if you often need to load the same several modules in specific versions, for instance.","title":"module save/restore"},{"location":"commands/#creating__a__module__collection","text":"Load the modules you need. Save the collection (you can name it as you want, here MYMODULES): module save MYMODULES Example Assuming we need pandas and matplotlib at HPC2N (very similar to LUNARC): Load the modules b-an01 [ ~ ] $ module load GCC/12.3.0 b-an01 [ ~ ] $ module load Python/3.11.3 b-an01 [ ~odule load OpenMPI/4.1.5 b-an01 [ ~ ] $ module load SciPy-bundle/2023.07 b-an01 [ ~ ] $ module load matplotlib/3.7.2 Save to a collection (here, \u201cmypython\u201d) b-an01 [ ~ ] $ module save mypython Saved current collection of modules to: \"mypython\" b-an01 [ ~ ] $ Then, maybe later you find you also need mpi4py so you load it and add it to the collection: b-an01 [ ~ ] $ ml mpi4py/3.1.4 b-an01 [ ~ ] $ module save mypython Saved current collection of modules to: \"mypython\" b-an01 [ ~ ] $ After you have been logged out and in again, or maybe unloaded/purged the modules, you can then restore it again: b-an01 [ ~ ] $ module restore mypython Restoring modules from user ' s mypython b-an01 [ ~ ] $ Warning If you are working on PDC\u2019s cluster Dardel, and are used to the command module purge then this is a good way of restoring the system-modules: Immediately after logging in (before loading or unloading anything) create a collection: module save pdcsystem (name as you want) Then, after you have done module purge , just do module restore pdcsystem and you are back to the correct system setup.","title":"Creating a module collection"},{"location":"commands/#workflow__-__module__collections","text":"Create a module collection Work with it Possibly unload all modules and load different ones to work with Then later restore the module collection again and keep working Possibly add more modules and save them to the collection Each time you have logged out and are logging in again, you can easily restore the modules you need Much safer than having it in your .bashrc since that is something easily forgotten about and then when you suddenly need to work with different modules or different versions, maybe months later, you are wondering why it is not working as it should and the reason is that you have auto-loaded things in your .bashrc ! Exercise Try loading some modules create a module collection do module list to see what you have unload the modules check with module list restore the module collection check with module list","title":"Workflow - module collections"},{"location":"commands/#hints","text":"Note How would you find, for instance, installed Python package modules for a specific Python version? Important At centres with prerequisites, you need to load, say, GCC instead of GCCcore in order to be able to access, for instance, SciPy-bundle!!! You also need to load a compatible OpenMPI in order to be sure to get all available installed Python package modules. Example, HPC2N (Very similar to LUNARC) First load the Python module and prerequisites, and OpenMPI b-an01 [ ~ ] $ module load GCC/12.3.0 b-an01 [ ~ ] $ module load Python/3.11.3 b-an01 [ ~ ] $ module load OpenMPI/4.1.5 Then you can check what Python package modules are installed (scroll down a bit): b-an01 [ ~ ] $ module avail ... ----------------------- This is a list of module extensions \"module --nx avail ...\" to not show. ------------------------ ( E ) fontBitstreamVera ( E ) ADGofTest ( E ) fontLiberation ( E ) AICcmodavg ( E ) fontawesome ( E ) ALDEx2 ( E ) fontquiver ( E ) ALL ( E ) fonttools ( E ) AMAPVox ( E ) forcats ( E ) ANCOMBC ( E ) foreach ( E ) ATACseqQC ( E ) forecast ( E ) AUC ( E ) foreign ( E ) AUCell ( E ) formatR ( E ) Aerial-Gym-Simulator ( E ) formula.tools ( E ) AgiMicroRna ( E ) formulaic ( E ) AlgDesign ( E ) fossil ( E ) Algorithm::Dependency ( E ) fpc ( E ) Algorithm::Diff ( E ) fpp ( E ) Alien::Base ( E ) fracdiff ( E ) Alien::Build::Plugin::Download::GitLab ( E ) fresh ( E ) Alien::Libxml2 ( E ) frozenlist ( E ) AlphaFold ( E ) fs ( E ) AlphaPulldown ( E ) fsc.export ( E ) ... The \u201cmodule extensions\u201d are things that are available as part of a modules. Sometimes several for each module. You can see for instance \u201cforeach\u201d R package is available (the list has everything available, not just Python packages). You can then do module spider foreach to see versions and then module spider foreach/1.5.2 to see where you find that extension. If you keep going further down on the list you got with \u201cmodule avail\u201d then you see that \u201cmpi4py\u201d is available and that \u201cpandas\u201d is available. Let us see how to load these. Doing b-an01 [ ~ ] $ module avail mpi4py tells us it can be loaded directly Doing b-an01 [ ~ ] $ module avail pandas gives some conflicting answer, so we try with module spider pandas and then module spider pandas/version to learn that it is part of SciPy-bundle. We can then load SciPy-bundle directly and get \u201cpandas\u201d available. Note Of course, you can always try doing module spider <software or package> and module avail <software or package> directly to see if you are lucky and get the name it is called.","title":"Hints"},{"location":"commands/#summary","text":"Note We learned about the following commands: load unload purge show help save/restore","title":"Summary"},{"location":"intro/","text":"Introduction to the module system \u00b6 Objectives Learn the basics of the module system which is used to access most of the software at the majority of the HPC centres in Sweden Learn about some of the most used commands for the module system Find existing modules Most programs are accessed by first loading them as a \u2018module\u2019. Thus, knowing about modules is necessary for you to be able to access the majority of the installed software at a centre! Modules are: used to set up your environment (paths to executables, libraries, etc.) for using a particular (set of) software package(s) a tool to help users manage their Unix/Linux shell environment, allowing groups of related environment-variable settings to be made or removed dynamically allows having multiple versions of a program or package available by just loading the proper module are installed in a hierarchial layout. This means that some modules are only available after loading a specific compiler and/or MPI version, etc. that is, the modules have prerequisites that needs to be loaded before they can be loaded. Whether or not modules have prerequisites vary by center. More on this later! Many of the centres in Sweden are using the Lmod module system. It is an environment module system that is Lua based. Many, but not all, of the centres in Sweden are using the EasyBuild framework for building and installing software modules. PDC also provides some software as containers, found in /pdc/software/sing_hub (or $PDC_SHUB ). singularity exec -B /cfs/klemming <sandbox folder> <myexe> LUMI has no modules and uses containers Important Take care not to use any system-installed versions of gcc , python , etc. Always use the module instead, when available! Always check if there is a module instead of just building the software/package yourself! Remember to check with different capitalization! If the center you are at have modules installed in a hierarchical fashion (LUNARC, HPC2N, PDC) you must use module spider to check if a software is installed, since module avail only lists what is available with what is currently loaded If there is a software missing that you need, then ask if it can be installed. Useful commands \u00b6 This is a list of some of the most useful commands for the module system. In the list below, MODULE is used as a stand-in for any software module. See which modules exists: module spider or ml spider See which versions exist of a specific module: module spider MODULE or ml spider MODULE This way is only recommended at HPC2N, LUNARC, (C3SE), and PDC See prerequisites and how to load a specfic version of a module: module spider MODULE/VERSION or ml spider MODULE/VERSION List modules depending only on what is currently loaded: module avail or ml av At UPPMAX and NSC (and C3SE) this will list all available modules! See which modules are currently loaded: module list or ml Loading a module: module load MODULE or ml MODULE Loading a specific version of a module: module load MODULE/VERSION or ml MODULE/VERSION Unload a module: module unload MODULE or ml -MODULE Get more information about the paths etc. of a module: ml show MODULE or module show MODULE Get information about what is in a module: module help MODULE or ml help MODULE Unload all modules except the \u2018sticky\u2019 modules: module purge or ml purge Module collections to load/unload a bunch of modules: module save <collection> and module restore <collection> Finding existing modules \u00b6 Warning This differs somewhat between centres. Some centres recommend using module avail while at others it is better to use module spider ! This is mainly to do with whether or not modules in general have prerequisite modules that needs loading before, or not. module spider : HPC2N, LUNARC, (C3SE), PDC module avail : UPPMAX, NSC, C3SE With module spider \u00b6 This is the recommended way to find existing software modules at HPC2N , LUNARC , ( C3SE ), and PDC . Hint module spider can be written in short form as ml spider Example, HPC2N b-an01 [ ~ ] $ module spider -------------------------------------------------------------------------------------------------------------- The following is a list of the modules and extensions currently available: -------------------------------------------------------------------------------------------------------------- : ( E ) ABRicate: ABRicate/1.0.0 Mass screening of contigs for antimicrobial and virulence genes ABySS: ABySS/2.2.5 Assembly By Short Sequences - a de novo, parallel, paired-end sequence assembler ACTC: ACTC/1.1 ACTC converts independent triangles into triangle strips or fans. ADGofTest: ADGofTest/0.3 ( E ) AICcmodavg: AICcmodavg/2.3-0 ( E ) , AICcmodavg/2.3-1 ( E ) , ... ALDEx2: ALDEx2/1.20.0 ( E ) , ALDEx2/1.26.0 ( E ) , ALDEx2/1.28.1 ( E ) , ... ALL: ALL/1.30.0 ( E ) , ALL/1.36.0 ( E ) , ALL/1.38.0 ( E ) , ... AMAPVox: AMAPVox/0.12.0 ( E ) , AMAPVox/1.0.0 ( E ) , AMAPVox/1.0.1 ( E ) , ... AMGX: AMGX/2.2.0-CUDA-11.3.1 Distributed multigrid linear solver library on GPU AMOS: AMOS/3.1.0 The AMOS consortium is committed to the development of open-source whole genome assembly software AMPtorch: AMPtorch/0.1 AMPtorch is a PyTorch implementation of the Atomistic Machine-learning Package ( AMP ) code that seeks to provide users with improved performance and flexibility as compared to the original code. The implementation does so by benefiting from state-of-the-art machine learning methods and techniques to be optimized in conjunction with high-throughput supercomputers. ANCOMBC: ANCOMBC/1.6.4 ( E ) , ANCOMBC/2.4.0 ( E ) , ANCOMBC/2.6.0 ( E ) ... Hint You can check if a specific software module is installed by trying module spider <SOFTWARE> Example, GROMACS at HPC2N (it works the same at LUNARC, C3SE, and PDC): b-an01 [ ~ ] $ module spider GROMACS -------------------------------------------------------------------------------------------------------------------- GROMACS: -------------------------------------------------------------------------------------------------------------------- Description: GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. Versions: GROMACS/3.3.3-cphmd-1.3 GROMACS/3.3.3-cphmd-1.3-1lpernode GROMACS/3.3.3-cphmd-1.4 GROMACS/4.0.7-ionstr GROMACS/5.1.4 GROMACS/2016.x-drude-20180214-g3f7439a GROMACS/2016.x-drude-20220117-g78fe3d1e GROMACS/2016.x-drude-20220120-ge35ae4e2 GROMACS/2016.4 GROMACS/2018.8 GROMACS/2019 GROMACS/2019.4-PLUMED-2.5.4 GROMACS/2021 GROMACS/2022.4 GROMACS/2023.1-CUDA-11.7.0 GROMACS/2023.1 GROMACS/2023.3-CUDA-12.1.1-PLUMED-2.9.0 GROMACS/2024.1 GROMACS/2024.3-CUDA-12.4.0 Other possible modules matches: GROMACS-LS -------------------------------------------------------------------------------------------------------------------- To find other possible module matches execute: $ module -r spider '.*GROMACS.*' -------------------------------------------------------------------------------------------------------------------- For detailed information about a specific \"GROMACS\" package ( including how to load the modules ) use the module ' s full name. Note that names that have a trailing ( E ) are extensions provided by other modules. For example: $ module spider GROMACS/2024.3-CUDA-12.4.0 -------------------------------------------------------------------------------------------------------------------- NOTE : Beware that you may have to try with different capitalization to find the software! With module avail \u00b6 This is the recommended way to find existing software modules at UPPMAX and NSC . It also works at C3SE . Hint module avail can be written in short form as ml av Example, UPPMAX (NSC works the same) [ bbrydsoe@rackham1 ~ ] $ module avail --------------------------------- /sw/mf/rackham/applications ---------------------------------- ABINIT/8.10.3 comsol/6.1 ALPS/2.3.0 comsol/6.2 ( D ) Amber/20 comsol/6.3 Ansys/19.1 conda/latest Ansys/19.5 coreutils/8.27 Ansys/2020R1 ( D ) coreutils/9.1 ( D ) BLAKE2/20230212-ed1974e cowsay/3.03 CDO/1.9.5 cp2k/4.1-gcc CDO/1.9.7.1-intel18.3 cp2k/6.1-gcc CDO/1.9.7.1 ( D ) cp2k/8.1-gcc ( D ) COIN-OR-OptimizationSuite/1.8.0 darsync/20240208-7ff09d9 CPLEXOptimizationStudio/12.9.0 desmond/2022-2 CPLEXOptimizationStudio/20.10 ( D ) doxygen/1.8.11 CST_Studio/2023.0 doxygen/1.9.6 ( D ) Cromwell/71 eLSA/20160907-febe2d7a57c8 Cromwell/86 ( D ) emacs/25.2 DBdeployer/latest emacs/27.2 DOCK/3.7 emacs/28.2 ( D ) FFmpeg/4.4 freesurfer/6.0.0 FFmpeg/5.1.2 ( D ) freesurfer/7.4.1 ( D ) GDAL/2.1.0 gamess/20170930 GDAL/3.1.0 gaussian/g09.d01 GDAL/3.6.2 gaussview/5.0.8 GDAL/3.7.2 ( D ) gawk/4.1.4 GOTM/5.3-221-gac7ec88d gdl/1.0.0-rc.1 GhostPDL/9.53.3 gnuplot/system GoogleCloudSDK/217.0.0 gnuplot/5.0.7 GoogleCloudSDK/447.0.0 gnuplot/5.2.7 ( D ) ... Hint You can check if a specific software module is installed by trying module avail <SOFTWARE> Example, GROMACS at NSC: [ x_birbr@tetralith3 ~ ] $ module avail GROMACS --------------------- /software/sse2/tetralith_el9/modules --------------------- GROMACS/recommendation ( D ) GROMACS/2021.3-PLUMED-nsc1-gcc-9.3.0-bare GROMACS/2022.2-nsc1-gcc-9.3.0-bare GROMACS/2023.4-gpu-hpc1-g9 GROMACS/2023.4-mpi+omp-hpc1-g9 GROMACS/2024.2-mpi+omp-hpc1-g11 GROMACS/2024.4-mpi+omp+double-cp2k-g11 Where: D: Default Module Warning If you do module avail at one of the centres that recommend module spider you will not get a full list of software, only those are available to load with no other prerequisites than are currently loaded . This is however, a good way to find compiler toolchains (more about that later). Example, HPC2N Here you only get what is available without loading anything else. Most modules have prerequisistes so this is not the way to find all modules! b-an01 [ ~ ] $ module avail ------------------------------------------- /hpc2n/eb/modules/all/Core ------------------------------------------- ATSAS/3.2.1-1_amd64 binutils/2.34 Advisor/2023.2.0 binutils/2.35 BLAST/2.11.0-Linux_x86_64 binutils/2.36.1 Bison/3.0.4 binutils/2.37 Bison/3.0.5 binutils/2.38 Bison/3.3.2 binutils/2.39 Bison/3.5.3 binutils/2.40 Bison/3.7.1 binutils/2.42 ( D ) Bison/3.7.6 biosoup/0.11.0 Bison/3.8.2 ( D ) code-server/4.97.2 CMake/3.18.4 cuDNN/8.0.4.30-CUDA-11.1.1 COMSOL/5.4.0.225 cuDNN/8.2.1.32-CUDA-11.3.1 COMSOL/5.6.0.401 cuDNN/8.2.2.26-CUDA-11.4.1 COMSOL/6.0.0.354 ( D ) cuDNN/8.4.1.50-CUDA-11.7.0 CUDA/8.0.61 cuDNN/8.9.2.26-CUDA-12.1.1 CUDA/10.1.105 cuDNN/9.1.1.17-CUDA-12.4.0 CUDA/10.1.243 cuDNN/9.2.0.82-CUDA-12.4.0 CUDA/11.3.1 cuDNN/9.5.0.50-CUDA-12.6.0 ( D ) CUDA/11.4.1 cuSPARSELt/0.6.0.6-CUDA-12.1.1 CUDA/11.5.0 cuTENSOR/1.2.2.5-CUDA-11.1.1 CUDA/11.6.0 cuTENSOR/2.0.1.2-CUDA-12.1.1 ( D ) CUDA/11.7.0 ffnvcodec/11.1.5.2 CUDA/12.0.0 ffnvcodec/12.0.16.0 CUDA/12.1.1 ffnvcodec/12.1.14.0 CUDA/12.4.0 ffnvcodec/12.2.72.0 ( D ) CUDA/12.5.0 flex/2.6.3 CUDA/12.6.0 ( D ) flex/2.6.4 ( D ) CUDAcore/11.0.2 foss/2019a CUDAcore/11.1.1 ( D ) foss/2019b Catch2/2.13.9 foss/2020a Cereal/1.3.2 foss/2020b CheckM-Database/2015_01_16 foss/2021a ChimeraX/1.1 foss/2021b ... Exercise Try listing the available modules. Use either module spider or module avail , depending on your centre. Try checking for a specific software module to see if it is installed: GROMACS Python VASP R What happens if you change the capitalization when you search for a module? Do you still find it? (Centre-dependent!) Summary \u00b6 Note We learned about some of the most useful commands We saw how to find which modules are available at a centre Using module spider Using module avail","title":"The module system"},{"location":"intro/#introduction__to__the__module__system","text":"Objectives Learn the basics of the module system which is used to access most of the software at the majority of the HPC centres in Sweden Learn about some of the most used commands for the module system Find existing modules Most programs are accessed by first loading them as a \u2018module\u2019. Thus, knowing about modules is necessary for you to be able to access the majority of the installed software at a centre! Modules are: used to set up your environment (paths to executables, libraries, etc.) for using a particular (set of) software package(s) a tool to help users manage their Unix/Linux shell environment, allowing groups of related environment-variable settings to be made or removed dynamically allows having multiple versions of a program or package available by just loading the proper module are installed in a hierarchial layout. This means that some modules are only available after loading a specific compiler and/or MPI version, etc. that is, the modules have prerequisites that needs to be loaded before they can be loaded. Whether or not modules have prerequisites vary by center. More on this later! Many of the centres in Sweden are using the Lmod module system. It is an environment module system that is Lua based. Many, but not all, of the centres in Sweden are using the EasyBuild framework for building and installing software modules. PDC also provides some software as containers, found in /pdc/software/sing_hub (or $PDC_SHUB ). singularity exec -B /cfs/klemming <sandbox folder> <myexe> LUMI has no modules and uses containers Important Take care not to use any system-installed versions of gcc , python , etc. Always use the module instead, when available! Always check if there is a module instead of just building the software/package yourself! Remember to check with different capitalization! If the center you are at have modules installed in a hierarchical fashion (LUNARC, HPC2N, PDC) you must use module spider to check if a software is installed, since module avail only lists what is available with what is currently loaded If there is a software missing that you need, then ask if it can be installed.","title":"Introduction to the module system"},{"location":"intro/#useful__commands","text":"This is a list of some of the most useful commands for the module system. In the list below, MODULE is used as a stand-in for any software module. See which modules exists: module spider or ml spider See which versions exist of a specific module: module spider MODULE or ml spider MODULE This way is only recommended at HPC2N, LUNARC, (C3SE), and PDC See prerequisites and how to load a specfic version of a module: module spider MODULE/VERSION or ml spider MODULE/VERSION List modules depending only on what is currently loaded: module avail or ml av At UPPMAX and NSC (and C3SE) this will list all available modules! See which modules are currently loaded: module list or ml Loading a module: module load MODULE or ml MODULE Loading a specific version of a module: module load MODULE/VERSION or ml MODULE/VERSION Unload a module: module unload MODULE or ml -MODULE Get more information about the paths etc. of a module: ml show MODULE or module show MODULE Get information about what is in a module: module help MODULE or ml help MODULE Unload all modules except the \u2018sticky\u2019 modules: module purge or ml purge Module collections to load/unload a bunch of modules: module save <collection> and module restore <collection>","title":"Useful commands"},{"location":"intro/#finding__existing__modules","text":"Warning This differs somewhat between centres. Some centres recommend using module avail while at others it is better to use module spider ! This is mainly to do with whether or not modules in general have prerequisite modules that needs loading before, or not. module spider : HPC2N, LUNARC, (C3SE), PDC module avail : UPPMAX, NSC, C3SE","title":"Finding existing modules"},{"location":"intro/#with__module__spider","text":"This is the recommended way to find existing software modules at HPC2N , LUNARC , ( C3SE ), and PDC . Hint module spider can be written in short form as ml spider Example, HPC2N b-an01 [ ~ ] $ module spider -------------------------------------------------------------------------------------------------------------- The following is a list of the modules and extensions currently available: -------------------------------------------------------------------------------------------------------------- : ( E ) ABRicate: ABRicate/1.0.0 Mass screening of contigs for antimicrobial and virulence genes ABySS: ABySS/2.2.5 Assembly By Short Sequences - a de novo, parallel, paired-end sequence assembler ACTC: ACTC/1.1 ACTC converts independent triangles into triangle strips or fans. ADGofTest: ADGofTest/0.3 ( E ) AICcmodavg: AICcmodavg/2.3-0 ( E ) , AICcmodavg/2.3-1 ( E ) , ... ALDEx2: ALDEx2/1.20.0 ( E ) , ALDEx2/1.26.0 ( E ) , ALDEx2/1.28.1 ( E ) , ... ALL: ALL/1.30.0 ( E ) , ALL/1.36.0 ( E ) , ALL/1.38.0 ( E ) , ... AMAPVox: AMAPVox/0.12.0 ( E ) , AMAPVox/1.0.0 ( E ) , AMAPVox/1.0.1 ( E ) , ... AMGX: AMGX/2.2.0-CUDA-11.3.1 Distributed multigrid linear solver library on GPU AMOS: AMOS/3.1.0 The AMOS consortium is committed to the development of open-source whole genome assembly software AMPtorch: AMPtorch/0.1 AMPtorch is a PyTorch implementation of the Atomistic Machine-learning Package ( AMP ) code that seeks to provide users with improved performance and flexibility as compared to the original code. The implementation does so by benefiting from state-of-the-art machine learning methods and techniques to be optimized in conjunction with high-throughput supercomputers. ANCOMBC: ANCOMBC/1.6.4 ( E ) , ANCOMBC/2.4.0 ( E ) , ANCOMBC/2.6.0 ( E ) ... Hint You can check if a specific software module is installed by trying module spider <SOFTWARE> Example, GROMACS at HPC2N (it works the same at LUNARC, C3SE, and PDC): b-an01 [ ~ ] $ module spider GROMACS -------------------------------------------------------------------------------------------------------------------- GROMACS: -------------------------------------------------------------------------------------------------------------------- Description: GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. Versions: GROMACS/3.3.3-cphmd-1.3 GROMACS/3.3.3-cphmd-1.3-1lpernode GROMACS/3.3.3-cphmd-1.4 GROMACS/4.0.7-ionstr GROMACS/5.1.4 GROMACS/2016.x-drude-20180214-g3f7439a GROMACS/2016.x-drude-20220117-g78fe3d1e GROMACS/2016.x-drude-20220120-ge35ae4e2 GROMACS/2016.4 GROMACS/2018.8 GROMACS/2019 GROMACS/2019.4-PLUMED-2.5.4 GROMACS/2021 GROMACS/2022.4 GROMACS/2023.1-CUDA-11.7.0 GROMACS/2023.1 GROMACS/2023.3-CUDA-12.1.1-PLUMED-2.9.0 GROMACS/2024.1 GROMACS/2024.3-CUDA-12.4.0 Other possible modules matches: GROMACS-LS -------------------------------------------------------------------------------------------------------------------- To find other possible module matches execute: $ module -r spider '.*GROMACS.*' -------------------------------------------------------------------------------------------------------------------- For detailed information about a specific \"GROMACS\" package ( including how to load the modules ) use the module ' s full name. Note that names that have a trailing ( E ) are extensions provided by other modules. For example: $ module spider GROMACS/2024.3-CUDA-12.4.0 -------------------------------------------------------------------------------------------------------------------- NOTE : Beware that you may have to try with different capitalization to find the software!","title":"With module spider"},{"location":"intro/#with__module__avail","text":"This is the recommended way to find existing software modules at UPPMAX and NSC . It also works at C3SE . Hint module avail can be written in short form as ml av Example, UPPMAX (NSC works the same) [ bbrydsoe@rackham1 ~ ] $ module avail --------------------------------- /sw/mf/rackham/applications ---------------------------------- ABINIT/8.10.3 comsol/6.1 ALPS/2.3.0 comsol/6.2 ( D ) Amber/20 comsol/6.3 Ansys/19.1 conda/latest Ansys/19.5 coreutils/8.27 Ansys/2020R1 ( D ) coreutils/9.1 ( D ) BLAKE2/20230212-ed1974e cowsay/3.03 CDO/1.9.5 cp2k/4.1-gcc CDO/1.9.7.1-intel18.3 cp2k/6.1-gcc CDO/1.9.7.1 ( D ) cp2k/8.1-gcc ( D ) COIN-OR-OptimizationSuite/1.8.0 darsync/20240208-7ff09d9 CPLEXOptimizationStudio/12.9.0 desmond/2022-2 CPLEXOptimizationStudio/20.10 ( D ) doxygen/1.8.11 CST_Studio/2023.0 doxygen/1.9.6 ( D ) Cromwell/71 eLSA/20160907-febe2d7a57c8 Cromwell/86 ( D ) emacs/25.2 DBdeployer/latest emacs/27.2 DOCK/3.7 emacs/28.2 ( D ) FFmpeg/4.4 freesurfer/6.0.0 FFmpeg/5.1.2 ( D ) freesurfer/7.4.1 ( D ) GDAL/2.1.0 gamess/20170930 GDAL/3.1.0 gaussian/g09.d01 GDAL/3.6.2 gaussview/5.0.8 GDAL/3.7.2 ( D ) gawk/4.1.4 GOTM/5.3-221-gac7ec88d gdl/1.0.0-rc.1 GhostPDL/9.53.3 gnuplot/system GoogleCloudSDK/217.0.0 gnuplot/5.0.7 GoogleCloudSDK/447.0.0 gnuplot/5.2.7 ( D ) ... Hint You can check if a specific software module is installed by trying module avail <SOFTWARE> Example, GROMACS at NSC: [ x_birbr@tetralith3 ~ ] $ module avail GROMACS --------------------- /software/sse2/tetralith_el9/modules --------------------- GROMACS/recommendation ( D ) GROMACS/2021.3-PLUMED-nsc1-gcc-9.3.0-bare GROMACS/2022.2-nsc1-gcc-9.3.0-bare GROMACS/2023.4-gpu-hpc1-g9 GROMACS/2023.4-mpi+omp-hpc1-g9 GROMACS/2024.2-mpi+omp-hpc1-g11 GROMACS/2024.4-mpi+omp+double-cp2k-g11 Where: D: Default Module Warning If you do module avail at one of the centres that recommend module spider you will not get a full list of software, only those are available to load with no other prerequisites than are currently loaded . This is however, a good way to find compiler toolchains (more about that later). Example, HPC2N Here you only get what is available without loading anything else. Most modules have prerequisistes so this is not the way to find all modules! b-an01 [ ~ ] $ module avail ------------------------------------------- /hpc2n/eb/modules/all/Core ------------------------------------------- ATSAS/3.2.1-1_amd64 binutils/2.34 Advisor/2023.2.0 binutils/2.35 BLAST/2.11.0-Linux_x86_64 binutils/2.36.1 Bison/3.0.4 binutils/2.37 Bison/3.0.5 binutils/2.38 Bison/3.3.2 binutils/2.39 Bison/3.5.3 binutils/2.40 Bison/3.7.1 binutils/2.42 ( D ) Bison/3.7.6 biosoup/0.11.0 Bison/3.8.2 ( D ) code-server/4.97.2 CMake/3.18.4 cuDNN/8.0.4.30-CUDA-11.1.1 COMSOL/5.4.0.225 cuDNN/8.2.1.32-CUDA-11.3.1 COMSOL/5.6.0.401 cuDNN/8.2.2.26-CUDA-11.4.1 COMSOL/6.0.0.354 ( D ) cuDNN/8.4.1.50-CUDA-11.7.0 CUDA/8.0.61 cuDNN/8.9.2.26-CUDA-12.1.1 CUDA/10.1.105 cuDNN/9.1.1.17-CUDA-12.4.0 CUDA/10.1.243 cuDNN/9.2.0.82-CUDA-12.4.0 CUDA/11.3.1 cuDNN/9.5.0.50-CUDA-12.6.0 ( D ) CUDA/11.4.1 cuSPARSELt/0.6.0.6-CUDA-12.1.1 CUDA/11.5.0 cuTENSOR/1.2.2.5-CUDA-11.1.1 CUDA/11.6.0 cuTENSOR/2.0.1.2-CUDA-12.1.1 ( D ) CUDA/11.7.0 ffnvcodec/11.1.5.2 CUDA/12.0.0 ffnvcodec/12.0.16.0 CUDA/12.1.1 ffnvcodec/12.1.14.0 CUDA/12.4.0 ffnvcodec/12.2.72.0 ( D ) CUDA/12.5.0 flex/2.6.3 CUDA/12.6.0 ( D ) flex/2.6.4 ( D ) CUDAcore/11.0.2 foss/2019a CUDAcore/11.1.1 ( D ) foss/2019b Catch2/2.13.9 foss/2020a Cereal/1.3.2 foss/2020b CheckM-Database/2015_01_16 foss/2021a ChimeraX/1.1 foss/2021b ... Exercise Try listing the available modules. Use either module spider or module avail , depending on your centre. Try checking for a specific software module to see if it is installed: GROMACS Python VASP R What happens if you change the capitalization when you search for a module? Do you still find it? (Centre-dependent!)","title":"With module avail"},{"location":"intro/#summary","text":"Note We learned about some of the most useful commands We saw how to find which modules are available at a centre Using module spider Using module avail","title":"Summary"},{"location":"programs/","text":"Examples \u00b6 Objectives Be able to find some typical software modules that are installed Learn how to load those software modules (and any prerequisites) Be able to find out if Python packages are installed as their own modules Learn how to find bundles of R packages installed as modules In the previous section we looked at toolchains, which are often used to install or build your own software. In this chapter we will look at some examples of how to find and load some of the typical software modules that are installed at many of the Swedish HPC centres. Loading modules works the same whether the modules are toolchains or standalone packages, with and without prerequisites. The procedure is usually some variation on the following: Use ml spider <package> to see whether a module is installed, and if so, view the available versions. (At facilities that do not hide packages depending on prerequisites, module avail <package> may be preferred.) Use ml spider <package>/<version> to view prerequisites for a specific version of the module, if any. Load the modules with ml <prerequisite>/<version> <package>/<version> . Most of the examples below use outputs from Cosmos, but the workflows will be similar at other institutions except where otherwise noted. Important Both R and Python packages often include many so-called extensions (dependent packages that are usually called modules when not dealing with LMOD modules) that are installed, but cannot be found with ml spider or ml avail . In these cases, if you have loaded at least the prerequisites of a standalone package containing the extension, you can use ml show <package> on the standalone package to view the Lua module file, which usually has a section on included extensions near the top. For example, NumPy, SciPy, and Pandas, among other packages, are all are included in SciPy-bundle . If you have at least loaded a GCC version, you can use ml show SciPy-bundle to view all of the included extensions (Python modules) in the compatible SciPy-bundle. Tip grep does not work directly on the outputs of module commands like ml show <module> . To search for an extension in a very long Lua module file, copy the full path of the .lua file from the ml show output, and use less /path/to/module.lua | grep <extension> . If there is no output, the extension is not present. Python-based packages \u00b6 It varies between centres how many packages are installed with the base Python packages, how many are installed as separate modules, what prerequsites are required (most centres apart from PDC are the same), and the available version numbers. Note HPC2N and C3SE: Little is installed with the Python module, but most of the common Python packages are available as extra modules (SciPy-bundle, Jupyter, mpi4py, matplotlib, tensorflow, PyTorch, Python-bundle-PyPi, \u2026) LUNARC: Little is installed with the Python module, but instead most of the common Python packages are available as extra modules (SciPy-bundle, Jupyter, mpi4py, matplotlib, tensorflow, PyTorch, Python-bundle-PyPi, \u2026). Anaconda3 bundles more into one module (SciPy, Pandas, Matplotlib, etc), but other modules loaded alongside it are typically not recognised. Additional modules must be installed in a custom environment. NSC: Little is installed with the Python module, but most of the common Python packages are available as extra modules (SciPy-bundle, matplotlib, mpi4py, PyTorch, Python-bundle-PyPi, Jupyter, \u2026). Most programs on Tetralith also have an extra prerequisite, buildtool-easybuild/4.X.X-hpc<version> that must be loaded before anything else. UPPMAX-Pelle: Little is installed with the Python module, but most of the common Python packages are available as extra modules (SciPy-bundle, matplotlib, mpi4py, Python-bundle-PyPi, Jupyter-lab, \u2026). No Prerequisites are needed! UPPMAX-Rackham: Very many packages are installed with the Python module. PDC: most modules included in SciPy-bundle (NumPy, SciPy, Pandas, etc.) are in cray-python modules, and these are compatible with a couple of the installed versions of matplotlib. Python modules that do not include the cray- prefix have very little installed in them and are not compatible with most other Python-adjacent modules; these are typically intended as bases for users to build their own environments. Most programs on Dardel also have an extra prerequisite, PDC/XX.XX or PDCOLD/XX.XX that must be loaded before anything else. Example 1: Matplotlib \u00b6 Matplotlib prerequisites vary significantly across HPC centres: some require none, some need one, some need more than one, and in some cases Matplotlib is only an extension of another module ( more info on how to find Matplotlib at different HPC centres here ). If you only want to see what Matplotlib depends on, a good starting point is to view the output of ml spider matplotlib (or ml avail matplotlib on NSC), pick an arbitrary version, and view ml spider matplotlib/<version> . All of the following code blocks in this example are taken from Cosmos. $ ml spider matplotlib ---------------------------------------------------------------------------- matplotlib: ---------------------------------------------------------------------------- Description: matplotlib is a python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. matplotlib can be used in python scripts, the python and ipython shell, web application servers, and six graphical user interface toolkits. Versions: matplotlib/2.2.5-Python-2.7.18 matplotlib/3.3.3 matplotlib/3.4.2 matplotlib/3.4.3 matplotlib/3.5.2 matplotlib/3.7.0 matplotlib/3.7.2 matplotlib/3.8.2 matplotlib/3.9.2 ---------------------------------------------------------------------------- If you try the above command at your local HPC centre and get a \u201cnot found\u201d error, that probably means Matplotlib is an extension of another module (e.g. on Rackham, there are versions that are part of the base Python module and versions that are part of python_ML_packages ). Let us look at matplotlib/3.8.2 , for example: $ ml spider matplotlib/3.8.2 --------------------------------------------------------------------------------- matplotlib: matplotlib/3.8.2 --------------------------------------------------------------------------------- Description: matplotlib is a python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. matplotlib can be used in python scripts, the python and ipython shell, web application servers, and six graphical user interface toolkits. You will need to load all module ( s ) on any one of the lines below before the \"mat plotlib/3.8.2\" module is available to load. GCC/13.2.0 This means that, on Cosmos at least, only GCC must be loaded before Matplotlib. However, Matplotlib is barely usable without the tools to read in or create the data arrays, so NumPy and/or Pandas are also needed. At most facilities, that means SciPy-bundle is required. Note that ml show matplotlib/<version> does not show which Python version is associated with that version of Matplotlib. If GCC is loaded, then you can use ml avail with Python , matplotlib , and/or SciPy-bundle to see which versions of these are available to load. The more typical scenario is that you want to move code developed on a personal laptop to the cluster. Then you will mainly be constrained to a range of Python versions Python/X.Y.Z , in which X absolutely must match what you used, Y should match but may be flexible by one or two versions, and Z is usually not that important. In a bash terminal, you can check your Python version with python --version . Let\u2019s say you built a script using Python 3.11.8 and a compatible version of Matplotlib on your own laptop. Glob patterns do not work to select subsets of ml spider or ml avail outputs, so one must view the full list with ml spider Python ( ml spider cray-python on Dardel). Here is the output on Cosmos: $ ml spider Python --------------------------------------------------------------------------------- Python: --------------------------------------------------------------------------------- Description: Python is a programming language that lets you work more quickly and integrate your systems more effectively. Versions: Python/2.7.18-bare Python/2.7.18 Python/3.8.6 Python/3.9.5-bare Python/3.9.5 Python/3.9.6-bare Python/3.9.6 Python/3.10.4-bare Python/3.10.4 Python/3.10.8-bare Python/3.10.8 Python/3.11.3 Python/3.11.5 Python/3.12.3 Other possible modules matches: Biopython GitPython IPython Python-bundle Python-bundle-PyPI bx-python flatbuffers-python graphviz-python meson-python ... The closest result is Python/3.11.5 (though probably anything from 3.10.x to 3.12.x would work). Let\u2019s check what that requires: $ ml spider Python/3.11.5 --------------------------------------------------------------------------------- Python: Python/3.11.5 --------------------------------------------------------------------------------- Description: Python is a programming language that lets you work more quickly and integrate your systems more effectively. You will need to load all module ( s ) on any one of the lines below before the \"Python/3.11.5\" module is available to load. GCCcore/13.2.0 Help: Description =========== Python is a programming language that lets you work more quickly and integrate your systems more effectively. More information ================ - Homepage: https://python.org/ Included extensions =================== flit_core-3.9.0, packaging-23.2, pip-23.2.1, setuptools-68.2.2, setuptools- scm-8.0.4, tomli-2.0.1, typing_extensions-4.8.0, wheel-0.41.2 On this cluster, the base Python module requires GCCcore, but we already saw that Matplotlib requires GCC (whch GCCcore is part of). In fact, nearly every other Python-based module apart from the bare Python itself requires GCC, so you may as well use GCC every time. On some facilities, each version of Matplotlib and SciPy-bundle is only be associated with one Python version, so you can load them all at once, using the GCC version to select for everything else, like this: ml GCC/13.2.0 Python matplotlib SciPy-bundle However, this is considered bad practice since sometimes additional versions are installed later. We should instead check ml avail to see what versions of Matplotlib and Scipy-bundle we can load: $ ml avail Scipy-bundle ----------------------------- /sw/easybuild_milan/modules/all/Compiler/GCC/13.2.0 ----------------------------- SciPy-bundle/2023.11 (Note: some output omitted for brevity) $ ml avail Matplotlib ----------------------------- /sw/easybuild_milan/modules/all/Compiler/GCC/13.2.0 ----------------------------- matplotlib/3.8.2 Then the one-line loading command should look like this: ml GCC/13.2.0 Python/3.11.5 matplotlib/3.8.2 SciPy-bundle/2023.11 If we check what was loaded with ml or module list , the output looks like this: $ ml Currently Loaded Modules: 1 ) SoftwareTree/Milan ( S ) 26 ) expat/2.5.0 2 ) GCCcore/13.2.0 27 ) util-linux/2.39 3 ) zlib/1.2.13 28 ) fontconfig/2.14.2 4 ) binutils/2.40 29 ) xorg-macros/1.20.0 5 ) GCC/13.2.0 30 ) libpciaccess/0.17 6 ) bzip2/1.0.8 31 ) X11/20231019 7 ) ncurses/6.4 32 ) Tk/8.6.13 8 ) libreadline/8.2 33 ) Tkinter/3.11.5 9 ) Tcl/8.6.13 34 ) NASM/2.16.01 10 ) SQLite/3.43.1 35 ) libjpeg-turbo/3.0.1 11 ) XZ/5.4.4 36 ) jbigkit/2.1 12 ) libffi/3.4.4 37 ) gzip/1.13 13 ) OpenSSL/1.1 38 ) lz4/1.9.4 14 ) Python/3.11.5 39 ) zstd/1.5.5 15 ) OpenBLAS/0.3.24 40 ) libdeflate/1.19 16 ) FlexiBLAS/3.3.1 41 ) LibTIFF/4.6.0 17 ) FFTW/3.3.10 42 ) giflib/5.2.1 18 ) cffi/1.15.1 43 ) libwebp/1.3.2 19 ) cryptography/41.0.5 44 ) OpenJPEG/2.5.0 20 ) virtualenv/20.24.6 45 ) LittleCMS/2.15 21 ) Python-bundle-PyPI/2023.10 46 ) Pillow/10.2.0 22 ) pybind11/2.11.1 47 ) Qhull/2020.2 23 ) libpng/1.6.40 48 ) matplotlib/3.8.2 24 ) Brotli/1.1.0 49 ) SciPy-bundle/2023.11 25 ) freetype/2.13.2 Where: S: Module is Sticky, requires --force to unload or purge If you are comfortable editing code in a basic text editor and running at the command-line, the modules used in the example above are all you need. For more information on choosing and loading IDEs to work with Matplotlib graphics interactively, we refer readers to this documentation from the Python for HPC course . Example 2: Check if a Python extension is loaded \u00b6 Extensions can be hard to find without knowing what includes them, but it is easy to check if modules that are already loaded added the extension silently. If you cannot find a package you want with ml avail , ml spider , or ml show <module> , you should also check pip list and grep for the package after loading the rest of your modules. For example, psutil is part of Python-bundle-PyPI, which is silently loaded with any SciPy-bundle. Here is the easiest way to find psutil : $ pip list | grep psutil psutil 5 .9.5 [ notice ] A new release of pip is available: 23 .1.2 -> 25 .1.1 [ notice ] To update, run: pip install --upgrade pip The pip list | grep approach is also helpful if you want to see the version of a package without having to open a Python interpreter. Tip The same list (and grep) approach works for Anaconda3. The only difference is that you should use conda list instead of pip list (although pip list usually still works). The Anaconda3 module file does not list the included extensions, so conda list | grep <package> is also the only way to see if a package is included without starting up a Python command line interface. R-based packages \u00b6 At most HPC centres, the base R module usually contains relatively few extensions. Most of the popular packages are in additional bundles like R-bundle-CRAN and R-bundle-Bioconductor . Most HPC centres have prerequisites for R, but at a few, like Alvis, R can be loaded directly. Always check the prerequisites with ml spider or ml avail . Note HPC2N: Little is installed with the basic R module, but most common packages are available as extensions of R-bundle-CRAN, R-bundle-CRAN-extra, or R-bundle-Bioconductor. RStudio is a separate module and only runs on the login nodes via Thinlinc, so it should be used sparingly. LUNARC: Little is installed with the basic R module, but most common packages are available as extensions of R-bundle-CRAN or R-bundle-Bioconductor. RStudio is also a separate module, and is available as an On-Demand application that automatically loads R and various bundles at start-up. UPPMAX (Pelle): Little is installed with the basic R module, but most common packages are available as extensions of R-bundle-CRAN or R-bundle-Bioconductor. RStudio installed soon. UPPMAX (Rackham) and C3SE (Alvis): R can be loaded directly, but has few installed packages. More common modules are available as extensions with the R_packages module. RStudio is also a separate module. NSC (Tetralith): R can be loaded directly, but contains few installed packages, and there are no bundles to provide more. Users are typically expected to install their own extension libraries. RStudio is included in the base R module, however. PDC (Dardel): Like most programs on Dardel, R also has the prerequisite PDC/XX.XX or PDCOLD/XX.XX , but the compiler and MPI library are chosen for you. There are about 250 packages available in the basic R module, and there are no additional bundles to provide more packages. Users are typically expected to install their own extension libraries. Important Most facilities have only built a handful of R releases, so many of the dependent modules are adapted for multiple versions. The version of such any dependent package should always be specified to ensure reproducibility. If the version number is omitted, the latest will be loaded by default, and that version may change without warning. Example 1: Bioconductor \u00b6 Many R-packages conveniently specify the version of R they are compatible with in the module name. One example of this is Bioconductor. $ ml spider bioconductor --------------------------------------------------------------------------------- R-bundle-Bioconductor: --------------------------------------------------------------------------------- Description: Bioconductor provides tools for the analysis and coprehension of high-throughput genomic data. Versions: R-bundle-Bioconductor/3.15-R-4.2.1 R-bundle-Bioconductor/3.18-R-4.3.2 R-bundle-Bioconductor/3.18-R-4.4.1 R-bundle-Bioconductor/3.19-R-4.4.1 --------------------------------------------------------------------------------- For detailed information about a specific \"R-bundle-Bioconductor\" package ( includin g how to load the modules ) use the module ' s full name. Note that names that have a trailing ( E ) are extensions provided by other modules. For example: $ module spider R-bundle-Bioconductor/3.19-R-4.4.1 --------------------------------------------------------------------------------- Notice that in this case, there are 2 versions of the Bioconductor bundle associated with R/4.4.1 , and that there are 2 versions of R associated with R-bundle-Bioconductor/3.18 . Do not rely on the prerequisites to set which version of R-bundle-Bioconductor gets loaded. To check the prerequisites with ml spider , the specific version number must be included anyway, for all software. $ ml spider R-bundle-Bioconductor/3.18-R-4.4.1 --------------------------------------------------------------------------------- R-bundle-Bioconductor: R-bundle-Bioconductor/3.18-R-4.4.1 --------------------------------------------------------------------------------- Description: Bioconductor provides tools for the analysis and coprehension of high-throughput genomic data. You will need to load all module ( s ) on any one of the lines below before the \"R-b undle-Bioconductor/3.18-R-4.4.1\" module is available to load. GCC/12.3.0 OpenMPI/4.1.5 Help: Description =========== Bioconductor provides tools for the analysis and coprehension of high-throughput genomic data. More information ================ - Homepage: https://bioconductor.org Included extensions =================== affxparser-1.74.0, affy-1.80.0, affycoretools-1.74.0, affyio-1.72.0, AgiMicroRna-2.52.0, agricolae-1.3-7, ALDEx2-1.34.0, ALL-1.44.0, ANCOMBC-2.4.0, annaffy-1.74.0, annotate-1.80.0, AnnotationDbi-1.64.1, AnnotationFilter-1.26.0, AnnotationForge-1.44.0, AnnotationHub-3.10.0, anytime-0.3.9, aroma.affymetrix-3.2.1, aroma.apd-0.7.0, aroma.core-3.3.0, aroma.light-3.32.0, ash-1.0-15, ATACseqQC-1.26.0, AUCell-1.24.0, aws.s3-0.3.21, aws.signature-0.6.0, babelgene-22.9, ballgown-2.34.0, basilisk-1.14.2, basilisk.utils-1.14.1, batchelor-1.18.1, baySeq-2.36.0, beachmat-2.18.0, BH-1.84.0-0, Biobase-2.62.0, BiocBaseUtils-1.4.0, ... The list of extensions is too long to copy here, but some popular extensions included in this module are: DeSeq2, GenomeInfoDb, MStats, Seurat, Rsamtools, and more. The above prerequisites and the main package can be loaded either one at a time or all at once with, $ ml GCC/12.3.0 OpenMPI/4.1.5 R-bundle-Bioconductor/3.18-R-4.4.1 In this case, R-bundle-Bioconductor loads the version of R that it is based on automatically (along with about 130 other modules!). That is not the case for all R-bundles at all HPC centres, so pay attention to the prerequisites. Matlab \u00b6 At most HPC centres, Matlab can be loaded directly, but PDC requires the usual prerequisite PDC/XX.XX or PDCOLD/XX.XX . Capitalisation and other naming conventions also vary between HPC centres; for more information, refer to this section of the R, Matlab, and Julia for HPC course . All Add-Ons and Toolboxes should be available through the Matlab GUI. Important The Matlab GUI is prone to hogging resources if not launched carefully, which makes it risky to run on a login node. In general, the GUI should only be run via either Desktop On Demand or after booking interactive allocations on compute nodes with salloc or interactive . For more particulars on running Matlab, see the relevant page of the R, Matlab, and Julia for HPC course materials . Example: Matlab on Tetralith (NSC) \u00b6 At most centres, where modules are hidden if prerequisites are not loaded, it is better to use ml spider to see what versions are available before accounting for preconditions. At centres where all modules are searchable without loading prerequisites, it is better to use ml avail to avoid listing modules that only exist as extensions or aliases of other modules, as in the case of Tetralith at NSC: $ ml avail matlab --------------------- /software/sse2/tetralith_el9/modules --------------------- MATLAB/recommendation ( D ) MATLAB/2024a-hpc1-bdist MATLAB/2023a-bdist MATLAB/2025a-hpc1-bdist MATLAB/2023b-bdist Where: D: Default Module Once you have chosen a specific version, use ml spider to check if there are prerequisites, like so: $ ml spider MATLAB/2024a-hpc1-bdist The full output is too verbose to reprint in full here, but the one important line reads: This module can be loaded directly: module load MATLAB/2024a-hpc1-bdist The command after the colon (:) can be copied, pasted, and entered directly into the bash prompt to load the module, or you can type the short version as follows: $ ml MATLAB/2024a-hpc1-bdist Specialised Applications \u00b6 For most specialised packages (Amber, GROMACS, Nextflow, VASP, etc), unless there is reason to believe it is included in a larger package or you include a spurious non-alphanumeric character, ml spider will tell you whether it is installed or not. If the full name of a module includes CUDA , then the relevant CUDA version will typically be loaded automatically, without the need to choose a CUDA-containing toolchain. Important Some specialised modules (e.g., Abaqus, Gaussian, and VASP) are license-restricted, so they may not load, or may load but refuse to run, if you are not part of the licensed user group. If you run ml spider on a specific version of licensed software, the description may (as with VASP) or may not (as with Gaussian) specify that a license is required. It is encumbant on users to determine the licensing requirements of specialised software packages. Example: OpenFOAM \u00b6 As usual, we start by checking the versions available with ml spider OpenFOAM (or ml avail OpenFOAM at a facility like NSC where all modules are visible regardless of the presence of prerequisites). An example output might look like this (from Cosmos): $ ml spider OpenFOAM -------------------------------------------------------------------------------------- OpenFOAM: -------------------------------------------------------------------------------------- Description: OpenFOAM is a free, open source CFD software package. OpenFOAM has an extensive range of features to solve anything from complex fluid flows involving chemical reactions, turbulence and heat transfer, to solid dynamics and electromagnetics. Versions: OpenFOAM/v2112 OpenFOAM/v2206 OpenFOAM/v2306 OpenFOAM/v2406 OpenFOAM/7-20200508 OpenFOAM/9 OpenFOAM/10 OpenFOAM/11 -------------------------------------------------------------------------------------- For detailed information about a specific \"OpenFOAM\" package ( including how to load the modules ) use the module ' s full name. Note that names that have a trailing ( E ) are extensions provided by other modules. For example: $ module spider OpenFOAM/11 -------------------------------------------------------------------------------------- Let us look at a recent version: $ ml spider OpenFOAM/11 -------------------------------------------------------------------------------------- OpenFOAM: OpenFOAM/11 -------------------------------------------------------------------------------------- Description: OpenFOAM is a free, open source CFD software package. OpenFOAM has an extensive range of features to solve anything from complex fluid flows involving chemical reactions, turbulence and heat transfer, to solid dynamics and electromagnetics. You will need to load all module ( s ) on any one of the lines below before the \"OpenFOAM /11\" module is available to load. GCC/11.3.0 OpenMPI/4.1.4 Help: Description =========== OpenFOAM is a free, open source CFD software package. OpenFOAM has an extensive range of features to solve anything from complex fluid flows involving chemical reactions, turbulence and heat transfer, to solid dynamics and electromagnetics. More information ================ - Homepage: https://www.openfoam.org/ On this system, GCC and OpenMPI must be loaded first, but this is not true for every system. Indeed, some versions on some systems (e.g. at NSC) load and use the compilers, MPI libraries, and mathematics libraries from Intel toolchains. Now we can load everything all at once like so: $ ml GCC/11.3.0 OpenMPI/4.1.4 OpenFOAM/11 or load each one at a time. The above command loads almost 90 modules, including several Python packages and visualisation libraries, all of which can be viewed by entering ml .","title":"Software module examples"},{"location":"programs/#examples","text":"Objectives Be able to find some typical software modules that are installed Learn how to load those software modules (and any prerequisites) Be able to find out if Python packages are installed as their own modules Learn how to find bundles of R packages installed as modules In the previous section we looked at toolchains, which are often used to install or build your own software. In this chapter we will look at some examples of how to find and load some of the typical software modules that are installed at many of the Swedish HPC centres. Loading modules works the same whether the modules are toolchains or standalone packages, with and without prerequisites. The procedure is usually some variation on the following: Use ml spider <package> to see whether a module is installed, and if so, view the available versions. (At facilities that do not hide packages depending on prerequisites, module avail <package> may be preferred.) Use ml spider <package>/<version> to view prerequisites for a specific version of the module, if any. Load the modules with ml <prerequisite>/<version> <package>/<version> . Most of the examples below use outputs from Cosmos, but the workflows will be similar at other institutions except where otherwise noted. Important Both R and Python packages often include many so-called extensions (dependent packages that are usually called modules when not dealing with LMOD modules) that are installed, but cannot be found with ml spider or ml avail . In these cases, if you have loaded at least the prerequisites of a standalone package containing the extension, you can use ml show <package> on the standalone package to view the Lua module file, which usually has a section on included extensions near the top. For example, NumPy, SciPy, and Pandas, among other packages, are all are included in SciPy-bundle . If you have at least loaded a GCC version, you can use ml show SciPy-bundle to view all of the included extensions (Python modules) in the compatible SciPy-bundle. Tip grep does not work directly on the outputs of module commands like ml show <module> . To search for an extension in a very long Lua module file, copy the full path of the .lua file from the ml show output, and use less /path/to/module.lua | grep <extension> . If there is no output, the extension is not present.","title":"Examples"},{"location":"programs/#python-based__packages","text":"It varies between centres how many packages are installed with the base Python packages, how many are installed as separate modules, what prerequsites are required (most centres apart from PDC are the same), and the available version numbers. Note HPC2N and C3SE: Little is installed with the Python module, but most of the common Python packages are available as extra modules (SciPy-bundle, Jupyter, mpi4py, matplotlib, tensorflow, PyTorch, Python-bundle-PyPi, \u2026) LUNARC: Little is installed with the Python module, but instead most of the common Python packages are available as extra modules (SciPy-bundle, Jupyter, mpi4py, matplotlib, tensorflow, PyTorch, Python-bundle-PyPi, \u2026). Anaconda3 bundles more into one module (SciPy, Pandas, Matplotlib, etc), but other modules loaded alongside it are typically not recognised. Additional modules must be installed in a custom environment. NSC: Little is installed with the Python module, but most of the common Python packages are available as extra modules (SciPy-bundle, matplotlib, mpi4py, PyTorch, Python-bundle-PyPi, Jupyter, \u2026). Most programs on Tetralith also have an extra prerequisite, buildtool-easybuild/4.X.X-hpc<version> that must be loaded before anything else. UPPMAX-Pelle: Little is installed with the Python module, but most of the common Python packages are available as extra modules (SciPy-bundle, matplotlib, mpi4py, Python-bundle-PyPi, Jupyter-lab, \u2026). No Prerequisites are needed! UPPMAX-Rackham: Very many packages are installed with the Python module. PDC: most modules included in SciPy-bundle (NumPy, SciPy, Pandas, etc.) are in cray-python modules, and these are compatible with a couple of the installed versions of matplotlib. Python modules that do not include the cray- prefix have very little installed in them and are not compatible with most other Python-adjacent modules; these are typically intended as bases for users to build their own environments. Most programs on Dardel also have an extra prerequisite, PDC/XX.XX or PDCOLD/XX.XX that must be loaded before anything else.","title":"Python-based packages"},{"location":"programs/#example__1__matplotlib","text":"Matplotlib prerequisites vary significantly across HPC centres: some require none, some need one, some need more than one, and in some cases Matplotlib is only an extension of another module ( more info on how to find Matplotlib at different HPC centres here ). If you only want to see what Matplotlib depends on, a good starting point is to view the output of ml spider matplotlib (or ml avail matplotlib on NSC), pick an arbitrary version, and view ml spider matplotlib/<version> . All of the following code blocks in this example are taken from Cosmos. $ ml spider matplotlib ---------------------------------------------------------------------------- matplotlib: ---------------------------------------------------------------------------- Description: matplotlib is a python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. matplotlib can be used in python scripts, the python and ipython shell, web application servers, and six graphical user interface toolkits. Versions: matplotlib/2.2.5-Python-2.7.18 matplotlib/3.3.3 matplotlib/3.4.2 matplotlib/3.4.3 matplotlib/3.5.2 matplotlib/3.7.0 matplotlib/3.7.2 matplotlib/3.8.2 matplotlib/3.9.2 ---------------------------------------------------------------------------- If you try the above command at your local HPC centre and get a \u201cnot found\u201d error, that probably means Matplotlib is an extension of another module (e.g. on Rackham, there are versions that are part of the base Python module and versions that are part of python_ML_packages ). Let us look at matplotlib/3.8.2 , for example: $ ml spider matplotlib/3.8.2 --------------------------------------------------------------------------------- matplotlib: matplotlib/3.8.2 --------------------------------------------------------------------------------- Description: matplotlib is a python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. matplotlib can be used in python scripts, the python and ipython shell, web application servers, and six graphical user interface toolkits. You will need to load all module ( s ) on any one of the lines below before the \"mat plotlib/3.8.2\" module is available to load. GCC/13.2.0 This means that, on Cosmos at least, only GCC must be loaded before Matplotlib. However, Matplotlib is barely usable without the tools to read in or create the data arrays, so NumPy and/or Pandas are also needed. At most facilities, that means SciPy-bundle is required. Note that ml show matplotlib/<version> does not show which Python version is associated with that version of Matplotlib. If GCC is loaded, then you can use ml avail with Python , matplotlib , and/or SciPy-bundle to see which versions of these are available to load. The more typical scenario is that you want to move code developed on a personal laptop to the cluster. Then you will mainly be constrained to a range of Python versions Python/X.Y.Z , in which X absolutely must match what you used, Y should match but may be flexible by one or two versions, and Z is usually not that important. In a bash terminal, you can check your Python version with python --version . Let\u2019s say you built a script using Python 3.11.8 and a compatible version of Matplotlib on your own laptop. Glob patterns do not work to select subsets of ml spider or ml avail outputs, so one must view the full list with ml spider Python ( ml spider cray-python on Dardel). Here is the output on Cosmos: $ ml spider Python --------------------------------------------------------------------------------- Python: --------------------------------------------------------------------------------- Description: Python is a programming language that lets you work more quickly and integrate your systems more effectively. Versions: Python/2.7.18-bare Python/2.7.18 Python/3.8.6 Python/3.9.5-bare Python/3.9.5 Python/3.9.6-bare Python/3.9.6 Python/3.10.4-bare Python/3.10.4 Python/3.10.8-bare Python/3.10.8 Python/3.11.3 Python/3.11.5 Python/3.12.3 Other possible modules matches: Biopython GitPython IPython Python-bundle Python-bundle-PyPI bx-python flatbuffers-python graphviz-python meson-python ... The closest result is Python/3.11.5 (though probably anything from 3.10.x to 3.12.x would work). Let\u2019s check what that requires: $ ml spider Python/3.11.5 --------------------------------------------------------------------------------- Python: Python/3.11.5 --------------------------------------------------------------------------------- Description: Python is a programming language that lets you work more quickly and integrate your systems more effectively. You will need to load all module ( s ) on any one of the lines below before the \"Python/3.11.5\" module is available to load. GCCcore/13.2.0 Help: Description =========== Python is a programming language that lets you work more quickly and integrate your systems more effectively. More information ================ - Homepage: https://python.org/ Included extensions =================== flit_core-3.9.0, packaging-23.2, pip-23.2.1, setuptools-68.2.2, setuptools- scm-8.0.4, tomli-2.0.1, typing_extensions-4.8.0, wheel-0.41.2 On this cluster, the base Python module requires GCCcore, but we already saw that Matplotlib requires GCC (whch GCCcore is part of). In fact, nearly every other Python-based module apart from the bare Python itself requires GCC, so you may as well use GCC every time. On some facilities, each version of Matplotlib and SciPy-bundle is only be associated with one Python version, so you can load them all at once, using the GCC version to select for everything else, like this: ml GCC/13.2.0 Python matplotlib SciPy-bundle However, this is considered bad practice since sometimes additional versions are installed later. We should instead check ml avail to see what versions of Matplotlib and Scipy-bundle we can load: $ ml avail Scipy-bundle ----------------------------- /sw/easybuild_milan/modules/all/Compiler/GCC/13.2.0 ----------------------------- SciPy-bundle/2023.11 (Note: some output omitted for brevity) $ ml avail Matplotlib ----------------------------- /sw/easybuild_milan/modules/all/Compiler/GCC/13.2.0 ----------------------------- matplotlib/3.8.2 Then the one-line loading command should look like this: ml GCC/13.2.0 Python/3.11.5 matplotlib/3.8.2 SciPy-bundle/2023.11 If we check what was loaded with ml or module list , the output looks like this: $ ml Currently Loaded Modules: 1 ) SoftwareTree/Milan ( S ) 26 ) expat/2.5.0 2 ) GCCcore/13.2.0 27 ) util-linux/2.39 3 ) zlib/1.2.13 28 ) fontconfig/2.14.2 4 ) binutils/2.40 29 ) xorg-macros/1.20.0 5 ) GCC/13.2.0 30 ) libpciaccess/0.17 6 ) bzip2/1.0.8 31 ) X11/20231019 7 ) ncurses/6.4 32 ) Tk/8.6.13 8 ) libreadline/8.2 33 ) Tkinter/3.11.5 9 ) Tcl/8.6.13 34 ) NASM/2.16.01 10 ) SQLite/3.43.1 35 ) libjpeg-turbo/3.0.1 11 ) XZ/5.4.4 36 ) jbigkit/2.1 12 ) libffi/3.4.4 37 ) gzip/1.13 13 ) OpenSSL/1.1 38 ) lz4/1.9.4 14 ) Python/3.11.5 39 ) zstd/1.5.5 15 ) OpenBLAS/0.3.24 40 ) libdeflate/1.19 16 ) FlexiBLAS/3.3.1 41 ) LibTIFF/4.6.0 17 ) FFTW/3.3.10 42 ) giflib/5.2.1 18 ) cffi/1.15.1 43 ) libwebp/1.3.2 19 ) cryptography/41.0.5 44 ) OpenJPEG/2.5.0 20 ) virtualenv/20.24.6 45 ) LittleCMS/2.15 21 ) Python-bundle-PyPI/2023.10 46 ) Pillow/10.2.0 22 ) pybind11/2.11.1 47 ) Qhull/2020.2 23 ) libpng/1.6.40 48 ) matplotlib/3.8.2 24 ) Brotli/1.1.0 49 ) SciPy-bundle/2023.11 25 ) freetype/2.13.2 Where: S: Module is Sticky, requires --force to unload or purge If you are comfortable editing code in a basic text editor and running at the command-line, the modules used in the example above are all you need. For more information on choosing and loading IDEs to work with Matplotlib graphics interactively, we refer readers to this documentation from the Python for HPC course .","title":"Example 1: Matplotlib"},{"location":"programs/#example__2__check__if__a__python__extension__is__loaded","text":"Extensions can be hard to find without knowing what includes them, but it is easy to check if modules that are already loaded added the extension silently. If you cannot find a package you want with ml avail , ml spider , or ml show <module> , you should also check pip list and grep for the package after loading the rest of your modules. For example, psutil is part of Python-bundle-PyPI, which is silently loaded with any SciPy-bundle. Here is the easiest way to find psutil : $ pip list | grep psutil psutil 5 .9.5 [ notice ] A new release of pip is available: 23 .1.2 -> 25 .1.1 [ notice ] To update, run: pip install --upgrade pip The pip list | grep approach is also helpful if you want to see the version of a package without having to open a Python interpreter. Tip The same list (and grep) approach works for Anaconda3. The only difference is that you should use conda list instead of pip list (although pip list usually still works). The Anaconda3 module file does not list the included extensions, so conda list | grep <package> is also the only way to see if a package is included without starting up a Python command line interface.","title":"Example 2: Check if a Python extension is loaded"},{"location":"programs/#r-based__packages","text":"At most HPC centres, the base R module usually contains relatively few extensions. Most of the popular packages are in additional bundles like R-bundle-CRAN and R-bundle-Bioconductor . Most HPC centres have prerequisites for R, but at a few, like Alvis, R can be loaded directly. Always check the prerequisites with ml spider or ml avail . Note HPC2N: Little is installed with the basic R module, but most common packages are available as extensions of R-bundle-CRAN, R-bundle-CRAN-extra, or R-bundle-Bioconductor. RStudio is a separate module and only runs on the login nodes via Thinlinc, so it should be used sparingly. LUNARC: Little is installed with the basic R module, but most common packages are available as extensions of R-bundle-CRAN or R-bundle-Bioconductor. RStudio is also a separate module, and is available as an On-Demand application that automatically loads R and various bundles at start-up. UPPMAX (Pelle): Little is installed with the basic R module, but most common packages are available as extensions of R-bundle-CRAN or R-bundle-Bioconductor. RStudio installed soon. UPPMAX (Rackham) and C3SE (Alvis): R can be loaded directly, but has few installed packages. More common modules are available as extensions with the R_packages module. RStudio is also a separate module. NSC (Tetralith): R can be loaded directly, but contains few installed packages, and there are no bundles to provide more. Users are typically expected to install their own extension libraries. RStudio is included in the base R module, however. PDC (Dardel): Like most programs on Dardel, R also has the prerequisite PDC/XX.XX or PDCOLD/XX.XX , but the compiler and MPI library are chosen for you. There are about 250 packages available in the basic R module, and there are no additional bundles to provide more packages. Users are typically expected to install their own extension libraries. Important Most facilities have only built a handful of R releases, so many of the dependent modules are adapted for multiple versions. The version of such any dependent package should always be specified to ensure reproducibility. If the version number is omitted, the latest will be loaded by default, and that version may change without warning.","title":"R-based packages"},{"location":"programs/#example__1__bioconductor","text":"Many R-packages conveniently specify the version of R they are compatible with in the module name. One example of this is Bioconductor. $ ml spider bioconductor --------------------------------------------------------------------------------- R-bundle-Bioconductor: --------------------------------------------------------------------------------- Description: Bioconductor provides tools for the analysis and coprehension of high-throughput genomic data. Versions: R-bundle-Bioconductor/3.15-R-4.2.1 R-bundle-Bioconductor/3.18-R-4.3.2 R-bundle-Bioconductor/3.18-R-4.4.1 R-bundle-Bioconductor/3.19-R-4.4.1 --------------------------------------------------------------------------------- For detailed information about a specific \"R-bundle-Bioconductor\" package ( includin g how to load the modules ) use the module ' s full name. Note that names that have a trailing ( E ) are extensions provided by other modules. For example: $ module spider R-bundle-Bioconductor/3.19-R-4.4.1 --------------------------------------------------------------------------------- Notice that in this case, there are 2 versions of the Bioconductor bundle associated with R/4.4.1 , and that there are 2 versions of R associated with R-bundle-Bioconductor/3.18 . Do not rely on the prerequisites to set which version of R-bundle-Bioconductor gets loaded. To check the prerequisites with ml spider , the specific version number must be included anyway, for all software. $ ml spider R-bundle-Bioconductor/3.18-R-4.4.1 --------------------------------------------------------------------------------- R-bundle-Bioconductor: R-bundle-Bioconductor/3.18-R-4.4.1 --------------------------------------------------------------------------------- Description: Bioconductor provides tools for the analysis and coprehension of high-throughput genomic data. You will need to load all module ( s ) on any one of the lines below before the \"R-b undle-Bioconductor/3.18-R-4.4.1\" module is available to load. GCC/12.3.0 OpenMPI/4.1.5 Help: Description =========== Bioconductor provides tools for the analysis and coprehension of high-throughput genomic data. More information ================ - Homepage: https://bioconductor.org Included extensions =================== affxparser-1.74.0, affy-1.80.0, affycoretools-1.74.0, affyio-1.72.0, AgiMicroRna-2.52.0, agricolae-1.3-7, ALDEx2-1.34.0, ALL-1.44.0, ANCOMBC-2.4.0, annaffy-1.74.0, annotate-1.80.0, AnnotationDbi-1.64.1, AnnotationFilter-1.26.0, AnnotationForge-1.44.0, AnnotationHub-3.10.0, anytime-0.3.9, aroma.affymetrix-3.2.1, aroma.apd-0.7.0, aroma.core-3.3.0, aroma.light-3.32.0, ash-1.0-15, ATACseqQC-1.26.0, AUCell-1.24.0, aws.s3-0.3.21, aws.signature-0.6.0, babelgene-22.9, ballgown-2.34.0, basilisk-1.14.2, basilisk.utils-1.14.1, batchelor-1.18.1, baySeq-2.36.0, beachmat-2.18.0, BH-1.84.0-0, Biobase-2.62.0, BiocBaseUtils-1.4.0, ... The list of extensions is too long to copy here, but some popular extensions included in this module are: DeSeq2, GenomeInfoDb, MStats, Seurat, Rsamtools, and more. The above prerequisites and the main package can be loaded either one at a time or all at once with, $ ml GCC/12.3.0 OpenMPI/4.1.5 R-bundle-Bioconductor/3.18-R-4.4.1 In this case, R-bundle-Bioconductor loads the version of R that it is based on automatically (along with about 130 other modules!). That is not the case for all R-bundles at all HPC centres, so pay attention to the prerequisites.","title":"Example 1: Bioconductor"},{"location":"programs/#matlab","text":"At most HPC centres, Matlab can be loaded directly, but PDC requires the usual prerequisite PDC/XX.XX or PDCOLD/XX.XX . Capitalisation and other naming conventions also vary between HPC centres; for more information, refer to this section of the R, Matlab, and Julia for HPC course . All Add-Ons and Toolboxes should be available through the Matlab GUI. Important The Matlab GUI is prone to hogging resources if not launched carefully, which makes it risky to run on a login node. In general, the GUI should only be run via either Desktop On Demand or after booking interactive allocations on compute nodes with salloc or interactive . For more particulars on running Matlab, see the relevant page of the R, Matlab, and Julia for HPC course materials .","title":"Matlab"},{"location":"programs/#example__matlab__on__tetralith__nsc","text":"At most centres, where modules are hidden if prerequisites are not loaded, it is better to use ml spider to see what versions are available before accounting for preconditions. At centres where all modules are searchable without loading prerequisites, it is better to use ml avail to avoid listing modules that only exist as extensions or aliases of other modules, as in the case of Tetralith at NSC: $ ml avail matlab --------------------- /software/sse2/tetralith_el9/modules --------------------- MATLAB/recommendation ( D ) MATLAB/2024a-hpc1-bdist MATLAB/2023a-bdist MATLAB/2025a-hpc1-bdist MATLAB/2023b-bdist Where: D: Default Module Once you have chosen a specific version, use ml spider to check if there are prerequisites, like so: $ ml spider MATLAB/2024a-hpc1-bdist The full output is too verbose to reprint in full here, but the one important line reads: This module can be loaded directly: module load MATLAB/2024a-hpc1-bdist The command after the colon (:) can be copied, pasted, and entered directly into the bash prompt to load the module, or you can type the short version as follows: $ ml MATLAB/2024a-hpc1-bdist","title":"Example: Matlab on Tetralith (NSC)"},{"location":"programs/#specialised__applications","text":"For most specialised packages (Amber, GROMACS, Nextflow, VASP, etc), unless there is reason to believe it is included in a larger package or you include a spurious non-alphanumeric character, ml spider will tell you whether it is installed or not. If the full name of a module includes CUDA , then the relevant CUDA version will typically be loaded automatically, without the need to choose a CUDA-containing toolchain. Important Some specialised modules (e.g., Abaqus, Gaussian, and VASP) are license-restricted, so they may not load, or may load but refuse to run, if you are not part of the licensed user group. If you run ml spider on a specific version of licensed software, the description may (as with VASP) or may not (as with Gaussian) specify that a license is required. It is encumbant on users to determine the licensing requirements of specialised software packages.","title":"Specialised Applications"},{"location":"programs/#example__openfoam","text":"As usual, we start by checking the versions available with ml spider OpenFOAM (or ml avail OpenFOAM at a facility like NSC where all modules are visible regardless of the presence of prerequisites). An example output might look like this (from Cosmos): $ ml spider OpenFOAM -------------------------------------------------------------------------------------- OpenFOAM: -------------------------------------------------------------------------------------- Description: OpenFOAM is a free, open source CFD software package. OpenFOAM has an extensive range of features to solve anything from complex fluid flows involving chemical reactions, turbulence and heat transfer, to solid dynamics and electromagnetics. Versions: OpenFOAM/v2112 OpenFOAM/v2206 OpenFOAM/v2306 OpenFOAM/v2406 OpenFOAM/7-20200508 OpenFOAM/9 OpenFOAM/10 OpenFOAM/11 -------------------------------------------------------------------------------------- For detailed information about a specific \"OpenFOAM\" package ( including how to load the modules ) use the module ' s full name. Note that names that have a trailing ( E ) are extensions provided by other modules. For example: $ module spider OpenFOAM/11 -------------------------------------------------------------------------------------- Let us look at a recent version: $ ml spider OpenFOAM/11 -------------------------------------------------------------------------------------- OpenFOAM: OpenFOAM/11 -------------------------------------------------------------------------------------- Description: OpenFOAM is a free, open source CFD software package. OpenFOAM has an extensive range of features to solve anything from complex fluid flows involving chemical reactions, turbulence and heat transfer, to solid dynamics and electromagnetics. You will need to load all module ( s ) on any one of the lines below before the \"OpenFOAM /11\" module is available to load. GCC/11.3.0 OpenMPI/4.1.4 Help: Description =========== OpenFOAM is a free, open source CFD software package. OpenFOAM has an extensive range of features to solve anything from complex fluid flows involving chemical reactions, turbulence and heat transfer, to solid dynamics and electromagnetics. More information ================ - Homepage: https://www.openfoam.org/ On this system, GCC and OpenMPI must be loaded first, but this is not true for every system. Indeed, some versions on some systems (e.g. at NSC) load and use the compilers, MPI libraries, and mathematics libraries from Intel toolchains. Now we can load everything all at once like so: $ ml GCC/11.3.0 OpenMPI/4.1.4 OpenFOAM/11 or load each one at a time. The above command loads almost 90 modules, including several Python packages and visualisation libraries, all of which can be viewed by entering ml .","title":"Example: OpenFOAM"},{"location":"summary/","text":"Summary \u00b6 Keypoints We learned about what a module system is we covered some of the basic commands to module: spider avail list load unload purge save/restore collection We learned about compiler toolchains and how to find and load them we looked at some software module examples Python R MATLAB We looked at how modules are used in batch scripts Questions Ask the instructors now! Send questions to support: https://supr.naiss.se/support/ More information about modules Documentation about selecting modules at some of the Swedish HPC centres HPC2N: https://docs.hpc2n.umu.se/software/modules/ UPPMAX: https://docs.uppmax.uu.se/cluster_guides/modules/ LUNARC: https://lunarc-documentation.readthedocs.io/en/latest/manual/manual_modules/ PDC: https://support.pdc.kth.se/doc/basics/quickstart/#the-lmod-module-system NSC: https://www.nsc.liu.se/software/modules/ C3SE: https://www.c3se.chalmers.se/documentation/module_system/ Other About the EasyBuild software build and framework: https://easybuild.io/ Evaluation survey Please help us improve this course by filling the evaluation survey: https://forms.office.com/e/HvhGtn5XCm","title":"Summary"},{"location":"summary/#summary","text":"Keypoints We learned about what a module system is we covered some of the basic commands to module: spider avail list load unload purge save/restore collection We learned about compiler toolchains and how to find and load them we looked at some software module examples Python R MATLAB We looked at how modules are used in batch scripts Questions Ask the instructors now! Send questions to support: https://supr.naiss.se/support/ More information about modules Documentation about selecting modules at some of the Swedish HPC centres HPC2N: https://docs.hpc2n.umu.se/software/modules/ UPPMAX: https://docs.uppmax.uu.se/cluster_guides/modules/ LUNARC: https://lunarc-documentation.readthedocs.io/en/latest/manual/manual_modules/ PDC: https://support.pdc.kth.se/doc/basics/quickstart/#the-lmod-module-system NSC: https://www.nsc.liu.se/software/modules/ C3SE: https://www.c3se.chalmers.se/documentation/module_system/ Other About the EasyBuild software build and framework: https://easybuild.io/ Evaluation survey Please help us improve this course by filling the evaluation survey: https://forms.office.com/e/HvhGtn5XCm","title":"Summary"},{"location":"toolchains/","text":"Compiler toolchains \u00b6 Objectives Learn what compiler toolchains are and why they are used Be able to find which compiler toolchains are installed Be able load the compiler toolchain you want At many Swedish (and other European) HPC centres, software is built using the EasyBuild deployment framework. Under this framework, software is built around \u201c toolchains \u201d: compatible groups of C and Fortran compilers, MPI libraries, linear algebra libraries, and other fundamental programs used internally by more familiar packages that users work with directly (e.g., Python, R, GROMACS, etc.). If you can think of familiar software packages like cars, then toolchains can be thought of like car platforms : similarly-sized cars from several brands often use standardized engine components, power steering systems, wheel axles, and other parts from the same manufacturer. Most HPC centers recommend using toolchains to build and compile software, whether you use EasyBuild not, to keep software versions consistent and reproducible. Available Toolchains by HPC Center \u00b6 Toolchains for regular CPU nodes \u00b6 For most of the following toolchains, multiple versions are available on each of the specified clusters. Use ml spider <toolchain> to determine which versions are available and what modules are required as prerequisites to load them, if any. HPC2N (Kebnekaise) LUNARC (Cosmos) NSC (Tetralith) UPPMAX (Pelle) UPPMAX (Rackham/Bianca) PDC (Dardel) GCC Compiler Toolchains GCC : GCC compiler only foss : GCC, OpenMPI, OpenBLAS, FFTW, BLACS, ScaLAPACK gompi : GCC, OpenMPI gomkl : GCC, OpenMPI, MKL gfbf : GCC, FlexiBLAS, FFTW (no MPI) Intel Compiler Toolchains intel : icc, ifort, Intel MPI, MKL intel-compilers : icc, icpc, ifort, icx, icpx, ifx (no MPI or MKL) iimpi : icc, ifort, Intel MPI GCC Compiler Toolchains GCC : GCC compiler only foss : GCC, OpenMPI, OpenBLAS, FFTW, BLACS, ScaLAPACK gompi : GCC, OpenMPI gomkl : GCC, OpenMPI, MKL gfbf : GCC, FlexiBLAS, FFTW (no MPI) Intel Compiler Toolchains intel : icc, ifort, Intel MPI, MKL intel-compilers : icc, icpc, ifort, icx, icpx, ifx (no MPI or MKL) iimpi : icc, ifort, Intel MPI Note that unlike most clusters, on Tetralith, users must load a module of the form buildtool-easybuild/<version> before loading any of the toolchains below. After loading that prerequisite, users should check the available toolchains with ml avail <toolchain> instead of ml spider <toolchain> . GCC Compiler Toolchains GCC : GCC compiler only foss : GCC, OpenMPI, OpenBLAS, FFTW, BLACS, ScaLAPACK gfbf : GCC, FlexiBLAS, FFTW (no MPI) Intel Compiler Toolchains intel : icc, ifort, Intel MPI, MKL intel-compilers : icc, icpc, ifort, icx, icpx, ifx (no MPI or MKL) GCC Compiler Toolchains GCC : GCC compiler only foss : GCC, OpenMPI, OpenBLAS, FFTW, BLACS, ScaLAPACK gfbf : GCC, FlexiBLAS, FFTW (no MPI) Intel Compiler Toolchains intel : icc, ifort, Intel MPI, MKL intel-compilers : icc, icpc, ifort, icx, icpx, ifx (no MPI or MKL) iimpi : icc, ifort, Intel MPI Toolchains are less visible than on other clusters. Most software was built manually without EasyBuild. Expect to load compilers, MPI libraries, math libraries, and other modules individually, taking common EasyBuild toolchains as inspiration. Need only a compiler? Search for available GCC or intel modules. Need math libraries, like OpenBLAS? Search for that and GCC or intel will be a dependency. Need MPI? See UPPMAX documentation about combinations of compilers and MPI libraries The EasyBuild toolchains below may be found for some tools in their names and dependencies, but are mainly intended to show which libraries go together. Use ml avail <toolchain> instead of ml spider <toolchain> to see if they are available: GCC Compiler Toolchains GCC : GCC compiler only foss : GCC, OpenMPI, OpenBLAS, FFTW, BLACS, ScaLAPACK gompi : GCC, OpenMPI Intel Compiler Toolchains intel : icc, ifort, Intel MPI, MKL iimpi : icc, ifort, Intel MPI On Dardel, nearly all software packages have a prerequisite called something like PDC/xx.xx or PDCOLD/xx.xx that will have to be loaded first. If you load the wrong one, use ml unload ! Do not purge! Toolchains at PDC bear little resemblance to any other cluster covered here because PDC uses different hardware architecture and the Cray Programming Environment (CPE). On Dardel, PrgEnv-cray and cray-libsci are loaded by default, and provide the compiler and linear algebra libraries, respectively. Loading cpe/YY.XX adds cray-mpich as the MPI library, and modifies PrgEnv-cray and cray-libsci if needed to maintain compatibility. The FFT library, cray-fftw , must be loaded separately. Alternative compilers are provided by PrgEnv-gnu (loads the GNU compiler suite) and PrgEnv-aocc (loads the AMD AOCC compilers). For software built or intended to be built with EasyBuild, there are 3 toolchains that help to assemble the appropriate combinations of the modules mentioned above, among other tools to support parallel programming. cpeCRAY: based on PrgEnv-cray cpeAMD: based on PrgEnv-gnu cpeGNU: based on PrgEnv-aocc In the interest of time, we refer readers to this page on the CPE and this page on CPE-based toolchains . CUDA based toolchains for GPU nodes \u00b6 HPC2N (Kebnekaise) LUNARC (Cosmos) NSC (Tetralith) UPPMAX (Pelle) UPPMAX (Rackham) GCC Compiler Toolchains for GPU gcccuda : GCC, CUDA fosscuda : GCC, CUDA, OpenMPI, OpenBLAS, FFTW, ScaLAPACK Intel Compiler Toolchains for GPU iccifortcuda : icc, ifort, CUDA (2019 releases only) iimpic : icc, ifort, CUDA, Intel MPI (2019 releases only) intelcuda : icc, ifort, CUDA, Intel MPI, MKL GCC Compiler Toolchains for GPU gcccuda : GCC, CUDA fosscuda : GCC, CUDA, OpenMPI, OpenBLAS, FFTW, ScaLAPACK Intel Compiler Toolchains for GPU iccifortcuda : icc, ifort, CUDA iimpic : icc, ifort, CUDA, Intel MPI intelcuda : icc, ifort, CUDA, Intel MPI, MKL GCC Compiler Toolchains for GPU buildenv-gcccuda : GCC, CUDA, OpenMPI, OpenBLAS, FFTW, ScaLAPACK As of today you load GCC and CUDA separately. New tools are typically build with the latest versions of both. Important Rackham only has GPUs on the login nodes. You will need an account on Snowy to use GPUs intensively. GCC Compiler Toolchains for GPU gcccuda : GCC, CUDA fosscuda : GCC, CUDA, OpenMPI, OpenBLAS, FFTW, ScaLAPACK Selecting a toolchain \u00b6 The above toolchain choices can be a bit overwhelming, especially for new users. Good choices for general use are the toolchains: foss , to use the GCC compiler suite intel , to use the Intel compiler suite gomkl , to use the GCC compiler suite with Intel\u2019s Math Kernel Library (MKL) Example: To check the foss versions available, use module avail foss and you will get an output similar to this example on COSMOS: ----------------- /sw/easybuild_milan/modules/all/Core ------------------ foss/2020b foss/2022a foss/2023b fosscuda/2020b foss/2021a foss/2022b foss/2024a foss/2021b foss/2023a foss/2024.05 ( D ) Where: D: Default Module If the avail list is too long consider trying: \"module --default avail\" or \"ml -d av\" to just list the default modules. \"module overview\" or \"ml ov\" to display the number of modules for each name. Use \"module spider\" to find all possible modules and extensions. Use \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\" . The version numbers indicate roughly when each version was released. Version 2023a was released at the beginning of 2023, 2023b in the middle of 2023, and 2024a at the start of 2024. If you load e.g. the foss/2024a module as shown below, module load foss/2024a It will load several modules for you, including the compiler, libraries, and other utilities. The command module list , or ml for short, can then show you what modules are now loaded and available for use. Below is the output of ml after loading foss/2024a on COSMOS: Currently Loaded Modules: 1 ) SoftwareTree/Milan ( S ) 13 ) UCX/1.16.0 2 ) GCCcore/13.3.0 14 ) libfabric/1.21.0 3 ) zlib/1.3.1 15 ) PMIx/5.0.2 4 ) binutils/2.42 16 ) PRRTE/3.0.5 5 ) GCC/13.3.0 17 ) UCC/1.3.0 6 ) numactl/2.0.18 18 ) OpenMPI/5.0.3 7 ) XZ/5.4.5 19 ) OpenBLAS/0.3.27 8 ) libxml2/2.12.7 20 ) FlexiBLAS/3.4.4 9 ) libpciaccess/0.18.1 21 ) FFTW/3.3.10 10 ) hwloc/2.10.0 22 ) FFTW.MPI/3.3.10 11 ) OpenSSL/3 23 ) ScaLAPACK/2.2.0-fb 12 ) libevent/2.1.12 24 ) foss/2024a Where: S: Module is Sticky, requires --force to unload or purge After loading a toolchain, many new modules become available, each reliant on the specific versions of the modules included in the toolchain. Use ml avail to see what modules you can load given the toolchain you\u2019ve loaded. For some packages with very long or very short release intervals, there may be multiple versions of a software package available for your chosen toolchain. The version that loads by default if no version number is given will have a (D) to the right of it when listed using ml avail . This default version is subject to change, so it is recommended to always provide version numbers. Not all modules have a version associated with your choice of toolchain. If you switch toolchains, keep the following in mind: The module system will attempt to upgrade or downgrade any previously loaded modules to match the new choice of toolchain. If one or more modules loaded with the previous choice of toolchain do not have a version installed that is compatible with the new toolchain, then the module system will raise an error. For some packages (e.g., Python, Perl, etc.) there is a system version built into the operating system that runs without loading any module or toolchain. These should be avoided since they are subject to change. Compiling serial code using a toolchain \u00b6 If you have loaded a toolchain, choose your compiler from the following table based on your coding language and toolchain choice. Note that there are 2 Intel versions per language; versions ending with x are newer OneAPI versions supported from 2023 onward. Coding Language If GCC Toolchain If Intel Toolchain C gcc icc, icx C++ g++ icpc, icpx Fortran gfortran ifort, ifx For some open-source toolchains, there may be no difference between compiling serial code with a toolchain and using a built-in compiler. The differences are more visible when using an Intel toolchain or when using MPI. Toolchains using MPI \u00b6 The table below shows which MPI compiler to use given your choices of toolchain and coding language: Coding Language If Toolchain with OpenMPI If Intel Toolchain C mpicc mpiicc C++ mpicxx mpiicpc Fortran mpifort mpiifort Inside your job script, executables built with OpenMPI need to be run using the mpirun command. For OpenMPI jobs not using threads, we recommend task binding (i.e., use the mpirun option --bind-to core ) For Intel-based MPI scripts, the script should be run with srun command. Here is a template for a script using OpenMPI (adapted from LUNARC documentation): #!/bin/sh #SBATCH -N 3 # number of nodes (arbitrary number >1) #SBATCH --ntasks-per-node=16 # adapt for your needs #SBATCH --exclusive # reserve whole nodes #SBATCH -t 0:60:0 # run time #SBATCH -J my_mpi_job # job name in queue #SBATCH -o result_%j.out # output file #SBATCH -e result_%j.err # error file #SBATCH -A <project-ID> # replace with your project ID cat $0 # module load statement(s) - adapt for your package(s) module load foss/2023a # run the jobs - here we assume an executable name: my_program mpirun --bind-to core my_program # for intel toolchains, the command is srun","title":"Compiler toolchains"},{"location":"toolchains/#compiler__toolchains","text":"Objectives Learn what compiler toolchains are and why they are used Be able to find which compiler toolchains are installed Be able load the compiler toolchain you want At many Swedish (and other European) HPC centres, software is built using the EasyBuild deployment framework. Under this framework, software is built around \u201c toolchains \u201d: compatible groups of C and Fortran compilers, MPI libraries, linear algebra libraries, and other fundamental programs used internally by more familiar packages that users work with directly (e.g., Python, R, GROMACS, etc.). If you can think of familiar software packages like cars, then toolchains can be thought of like car platforms : similarly-sized cars from several brands often use standardized engine components, power steering systems, wheel axles, and other parts from the same manufacturer. Most HPC centers recommend using toolchains to build and compile software, whether you use EasyBuild not, to keep software versions consistent and reproducible.","title":"Compiler toolchains"},{"location":"toolchains/#available__toolchains__by__hpc__center","text":"","title":"Available Toolchains by HPC Center"},{"location":"toolchains/#toolchains__for__regular__cpu__nodes","text":"For most of the following toolchains, multiple versions are available on each of the specified clusters. Use ml spider <toolchain> to determine which versions are available and what modules are required as prerequisites to load them, if any. HPC2N (Kebnekaise) LUNARC (Cosmos) NSC (Tetralith) UPPMAX (Pelle) UPPMAX (Rackham/Bianca) PDC (Dardel) GCC Compiler Toolchains GCC : GCC compiler only foss : GCC, OpenMPI, OpenBLAS, FFTW, BLACS, ScaLAPACK gompi : GCC, OpenMPI gomkl : GCC, OpenMPI, MKL gfbf : GCC, FlexiBLAS, FFTW (no MPI) Intel Compiler Toolchains intel : icc, ifort, Intel MPI, MKL intel-compilers : icc, icpc, ifort, icx, icpx, ifx (no MPI or MKL) iimpi : icc, ifort, Intel MPI GCC Compiler Toolchains GCC : GCC compiler only foss : GCC, OpenMPI, OpenBLAS, FFTW, BLACS, ScaLAPACK gompi : GCC, OpenMPI gomkl : GCC, OpenMPI, MKL gfbf : GCC, FlexiBLAS, FFTW (no MPI) Intel Compiler Toolchains intel : icc, ifort, Intel MPI, MKL intel-compilers : icc, icpc, ifort, icx, icpx, ifx (no MPI or MKL) iimpi : icc, ifort, Intel MPI Note that unlike most clusters, on Tetralith, users must load a module of the form buildtool-easybuild/<version> before loading any of the toolchains below. After loading that prerequisite, users should check the available toolchains with ml avail <toolchain> instead of ml spider <toolchain> . GCC Compiler Toolchains GCC : GCC compiler only foss : GCC, OpenMPI, OpenBLAS, FFTW, BLACS, ScaLAPACK gfbf : GCC, FlexiBLAS, FFTW (no MPI) Intel Compiler Toolchains intel : icc, ifort, Intel MPI, MKL intel-compilers : icc, icpc, ifort, icx, icpx, ifx (no MPI or MKL) GCC Compiler Toolchains GCC : GCC compiler only foss : GCC, OpenMPI, OpenBLAS, FFTW, BLACS, ScaLAPACK gfbf : GCC, FlexiBLAS, FFTW (no MPI) Intel Compiler Toolchains intel : icc, ifort, Intel MPI, MKL intel-compilers : icc, icpc, ifort, icx, icpx, ifx (no MPI or MKL) iimpi : icc, ifort, Intel MPI Toolchains are less visible than on other clusters. Most software was built manually without EasyBuild. Expect to load compilers, MPI libraries, math libraries, and other modules individually, taking common EasyBuild toolchains as inspiration. Need only a compiler? Search for available GCC or intel modules. Need math libraries, like OpenBLAS? Search for that and GCC or intel will be a dependency. Need MPI? See UPPMAX documentation about combinations of compilers and MPI libraries The EasyBuild toolchains below may be found for some tools in their names and dependencies, but are mainly intended to show which libraries go together. Use ml avail <toolchain> instead of ml spider <toolchain> to see if they are available: GCC Compiler Toolchains GCC : GCC compiler only foss : GCC, OpenMPI, OpenBLAS, FFTW, BLACS, ScaLAPACK gompi : GCC, OpenMPI Intel Compiler Toolchains intel : icc, ifort, Intel MPI, MKL iimpi : icc, ifort, Intel MPI On Dardel, nearly all software packages have a prerequisite called something like PDC/xx.xx or PDCOLD/xx.xx that will have to be loaded first. If you load the wrong one, use ml unload ! Do not purge! Toolchains at PDC bear little resemblance to any other cluster covered here because PDC uses different hardware architecture and the Cray Programming Environment (CPE). On Dardel, PrgEnv-cray and cray-libsci are loaded by default, and provide the compiler and linear algebra libraries, respectively. Loading cpe/YY.XX adds cray-mpich as the MPI library, and modifies PrgEnv-cray and cray-libsci if needed to maintain compatibility. The FFT library, cray-fftw , must be loaded separately. Alternative compilers are provided by PrgEnv-gnu (loads the GNU compiler suite) and PrgEnv-aocc (loads the AMD AOCC compilers). For software built or intended to be built with EasyBuild, there are 3 toolchains that help to assemble the appropriate combinations of the modules mentioned above, among other tools to support parallel programming. cpeCRAY: based on PrgEnv-cray cpeAMD: based on PrgEnv-gnu cpeGNU: based on PrgEnv-aocc In the interest of time, we refer readers to this page on the CPE and this page on CPE-based toolchains .","title":"Toolchains for regular CPU nodes"},{"location":"toolchains/#cuda__based__toolchains__for__gpu__nodes","text":"HPC2N (Kebnekaise) LUNARC (Cosmos) NSC (Tetralith) UPPMAX (Pelle) UPPMAX (Rackham) GCC Compiler Toolchains for GPU gcccuda : GCC, CUDA fosscuda : GCC, CUDA, OpenMPI, OpenBLAS, FFTW, ScaLAPACK Intel Compiler Toolchains for GPU iccifortcuda : icc, ifort, CUDA (2019 releases only) iimpic : icc, ifort, CUDA, Intel MPI (2019 releases only) intelcuda : icc, ifort, CUDA, Intel MPI, MKL GCC Compiler Toolchains for GPU gcccuda : GCC, CUDA fosscuda : GCC, CUDA, OpenMPI, OpenBLAS, FFTW, ScaLAPACK Intel Compiler Toolchains for GPU iccifortcuda : icc, ifort, CUDA iimpic : icc, ifort, CUDA, Intel MPI intelcuda : icc, ifort, CUDA, Intel MPI, MKL GCC Compiler Toolchains for GPU buildenv-gcccuda : GCC, CUDA, OpenMPI, OpenBLAS, FFTW, ScaLAPACK As of today you load GCC and CUDA separately. New tools are typically build with the latest versions of both. Important Rackham only has GPUs on the login nodes. You will need an account on Snowy to use GPUs intensively. GCC Compiler Toolchains for GPU gcccuda : GCC, CUDA fosscuda : GCC, CUDA, OpenMPI, OpenBLAS, FFTW, ScaLAPACK","title":"CUDA based toolchains for GPU nodes"},{"location":"toolchains/#selecting__a__toolchain","text":"The above toolchain choices can be a bit overwhelming, especially for new users. Good choices for general use are the toolchains: foss , to use the GCC compiler suite intel , to use the Intel compiler suite gomkl , to use the GCC compiler suite with Intel\u2019s Math Kernel Library (MKL) Example: To check the foss versions available, use module avail foss and you will get an output similar to this example on COSMOS: ----------------- /sw/easybuild_milan/modules/all/Core ------------------ foss/2020b foss/2022a foss/2023b fosscuda/2020b foss/2021a foss/2022b foss/2024a foss/2021b foss/2023a foss/2024.05 ( D ) Where: D: Default Module If the avail list is too long consider trying: \"module --default avail\" or \"ml -d av\" to just list the default modules. \"module overview\" or \"ml ov\" to display the number of modules for each name. Use \"module spider\" to find all possible modules and extensions. Use \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\" . The version numbers indicate roughly when each version was released. Version 2023a was released at the beginning of 2023, 2023b in the middle of 2023, and 2024a at the start of 2024. If you load e.g. the foss/2024a module as shown below, module load foss/2024a It will load several modules for you, including the compiler, libraries, and other utilities. The command module list , or ml for short, can then show you what modules are now loaded and available for use. Below is the output of ml after loading foss/2024a on COSMOS: Currently Loaded Modules: 1 ) SoftwareTree/Milan ( S ) 13 ) UCX/1.16.0 2 ) GCCcore/13.3.0 14 ) libfabric/1.21.0 3 ) zlib/1.3.1 15 ) PMIx/5.0.2 4 ) binutils/2.42 16 ) PRRTE/3.0.5 5 ) GCC/13.3.0 17 ) UCC/1.3.0 6 ) numactl/2.0.18 18 ) OpenMPI/5.0.3 7 ) XZ/5.4.5 19 ) OpenBLAS/0.3.27 8 ) libxml2/2.12.7 20 ) FlexiBLAS/3.4.4 9 ) libpciaccess/0.18.1 21 ) FFTW/3.3.10 10 ) hwloc/2.10.0 22 ) FFTW.MPI/3.3.10 11 ) OpenSSL/3 23 ) ScaLAPACK/2.2.0-fb 12 ) libevent/2.1.12 24 ) foss/2024a Where: S: Module is Sticky, requires --force to unload or purge After loading a toolchain, many new modules become available, each reliant on the specific versions of the modules included in the toolchain. Use ml avail to see what modules you can load given the toolchain you\u2019ve loaded. For some packages with very long or very short release intervals, there may be multiple versions of a software package available for your chosen toolchain. The version that loads by default if no version number is given will have a (D) to the right of it when listed using ml avail . This default version is subject to change, so it is recommended to always provide version numbers. Not all modules have a version associated with your choice of toolchain. If you switch toolchains, keep the following in mind: The module system will attempt to upgrade or downgrade any previously loaded modules to match the new choice of toolchain. If one or more modules loaded with the previous choice of toolchain do not have a version installed that is compatible with the new toolchain, then the module system will raise an error. For some packages (e.g., Python, Perl, etc.) there is a system version built into the operating system that runs without loading any module or toolchain. These should be avoided since they are subject to change.","title":"Selecting a toolchain"},{"location":"toolchains/#compiling__serial__code__using__a__toolchain","text":"If you have loaded a toolchain, choose your compiler from the following table based on your coding language and toolchain choice. Note that there are 2 Intel versions per language; versions ending with x are newer OneAPI versions supported from 2023 onward. Coding Language If GCC Toolchain If Intel Toolchain C gcc icc, icx C++ g++ icpc, icpx Fortran gfortran ifort, ifx For some open-source toolchains, there may be no difference between compiling serial code with a toolchain and using a built-in compiler. The differences are more visible when using an Intel toolchain or when using MPI.","title":"Compiling serial code using a toolchain"},{"location":"toolchains/#toolchains__using__mpi","text":"The table below shows which MPI compiler to use given your choices of toolchain and coding language: Coding Language If Toolchain with OpenMPI If Intel Toolchain C mpicc mpiicc C++ mpicxx mpiicpc Fortran mpifort mpiifort Inside your job script, executables built with OpenMPI need to be run using the mpirun command. For OpenMPI jobs not using threads, we recommend task binding (i.e., use the mpirun option --bind-to core ) For Intel-based MPI scripts, the script should be run with srun command. Here is a template for a script using OpenMPI (adapted from LUNARC documentation): #!/bin/sh #SBATCH -N 3 # number of nodes (arbitrary number >1) #SBATCH --ntasks-per-node=16 # adapt for your needs #SBATCH --exclusive # reserve whole nodes #SBATCH -t 0:60:0 # run time #SBATCH -J my_mpi_job # job name in queue #SBATCH -o result_%j.out # output file #SBATCH -e result_%j.err # error file #SBATCH -A <project-ID> # replace with your project ID cat $0 # module load statement(s) - adapt for your package(s) module load foss/2023a # run the jobs - here we assume an executable name: my_program mpirun --bind-to core my_program # for intel toolchains, the command is srun","title":"Toolchains using MPI"}]}